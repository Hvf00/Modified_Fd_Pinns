{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "08d6077a-aa22-424c-9549-47c29ee0bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03155e44-31ba-4c2d-907b-f319fa149e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,num_input=2,layers=[128, 128, 128, 128],num_output=3):\n",
    "        super(Network,self).__init__()\n",
    "        self.input_layer=nn.Linear(num_input,layers[0])\n",
    "        self.hidden_layer=nn.ModuleList()\n",
    "        for i in range(len(layers)-1):\n",
    "            self.hidden_layer.append(nn.Linear(layers[i],layers[i+1]))\n",
    "        self.output_layer=nn.Linear(layers[-1],num_output)\n",
    "    def forward(self,out):\n",
    "        out=torch.tanh(self.input_layer(out))\n",
    "        for layer in self.hidden_layer:\n",
    "            out=torch.tanh(layer(out))\n",
    "        out=self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6248df96-78f8-4c78-b33a-66a325d998b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pinns:\n",
    "    def __init__(self):\n",
    "        # Transfer to GPU if it is possible\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.network = Network().to(self.device)\n",
    "        print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "        # Problem parameters\n",
    "        self.Re = 800.0\n",
    "        self.L = 10.0\n",
    "        self.H = 1.0\n",
    "        self.step_height = 0.0\n",
    "        self.step_length = 2.0\n",
    "\n",
    "        # Domain_Definition\n",
    "        self.nx=350.0\n",
    "        self.ny=35.0\n",
    "        dx=self.L/self.nx\n",
    "        dy=self.H/self.ny\n",
    "        self.x=torch.arange(0,self.L+dx,dx)\n",
    "        self.y=torch.arange(-self.H/2.0,self.H/2.0+dy,dy)\n",
    "        self.X = torch.stack(torch.meshgrid(self.x,self.y)).reshape(2,-1).T\n",
    "        self.X.requires_grad = True\n",
    "\n",
    "        # Boundary_condition_input\n",
    "        dx_b=self.L/3500.0\n",
    "        dy_b=self.H/350.0\n",
    "        self.x_b = torch.arange(0,self.L+dx_b,dx_b)\n",
    "        self.y_b = torch.arange(-self.H/2.0,self.H/2.0+dy_b,dy_b)\n",
    "        self.lw_inlet = torch.stack(torch.meshgrid(self.x_b[0],self.y_b[len(self.y_b)//2:])).reshape(2,-1).T\n",
    "        self.lw_wall = torch.stack(torch.meshgrid(self.x_b[0],self.y_b[:len(self.y_b)//2])).reshape(2,-1).T\n",
    "        self.uw = torch.stack(torch.meshgrid(self.x_b,self.y_b[-1])).reshape(2,-1).T\n",
    "        self.dw = torch.stack(torch.meshgrid(self.x_b,self.y_b[0])).reshape(2,-1).T\n",
    "        self.X_train = torch.cat([self.lw_inlet, self.lw_wall, self.uw,  self.dw])\n",
    "\n",
    "\n",
    "        # Boundary_condition_output\n",
    "        y1 = self.y_b[len(self.y_b)//2:]\n",
    "        y2 = self.y_b[:len(self.y_b)//2]\n",
    "        self.u_profile = 24 * y1 * (0.5 - y1)\n",
    "        self.uv_lw_inlet = torch.stack(torch.meshgrid(self.u_profile,self.x_b[0])).reshape(2,-1).T\n",
    "        self.uv_lw_wall = torch.stack(torch.meshgrid(torch.zeros_like(y2),self.x_b[0])).reshape(2,-1).T\n",
    "        self.uv_uw = torch.stack(torch.meshgrid(self.x_b[0],torch.zeros_like(self.x_b))).reshape(2,-1).T\n",
    "        self.uv_dw = torch.stack(torch.meshgrid(self.x_b[0],torch.zeros_like(self.x_b))).reshape(2,-1).T\n",
    "        self.uv_train = torch.cat([self.uv_lw_inlet, self.uv_lw_wall, self.uv_uw,  self.uv_dw])\n",
    "        # Transfer tensor to GPU\n",
    "        self.uv_train = self.uv_train.to(self.device)\n",
    "        self.X_train = self.X_train.to(self.device)\n",
    "        self.X = self.X.to(self.device)\n",
    "\n",
    "        # Error criterion Definition\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        # Optimizer setting\n",
    "        self.adam = torch.optim.Adam(self.network.parameters(), lr=1e-4)\n",
    "        # , lr=1e-4\n",
    "        # Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS)\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "        self.network.parameters(),\n",
    "            lr=0.01,\n",
    "            max_iter = 2000,\n",
    "            max_eval = 2000,\n",
    "            history_size = 50,\n",
    "            tolerance_grad = 1e-8,\n",
    "            tolerance_change = 1.0* np.finfo(float).eps,\n",
    "            line_search_fn =\"strong_wolfe\"\n",
    "        )\n",
    "        self.loss_history = []\n",
    "\n",
    "        \n",
    "    #compute derivations\n",
    "    def gradient(self,input,index):\n",
    "        output = torch.autograd.grad(\n",
    "            input,\n",
    "            self.X,\n",
    "            grad_outputs=torch.ones_like(input),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        return output[:,index]\n",
    "\n",
    "    def loss_f(self):\n",
    "        #Restart Optimizer\n",
    "        self.adam.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        #output of NN for boundary\n",
    "        self.uv_P_b = self.network(self.X_train)\n",
    "        self.u_P_b = self.uv_P_b[:,0]\n",
    "        self.v_P_b = self.uv_P_b[:,1]\n",
    "\n",
    "        #loss data definition\n",
    "        self.loss_data = self.criterion(self.u_P_b,self.uv_train[:,0])+self.criterion(self.v_P_b,self.uv_train[:,1])\n",
    "\n",
    "        #output of NN\n",
    "        self.uvp_P = self.network(self.X)\n",
    "        self.u_P = self.uvp_P[:,0]\n",
    "        self.v_P = self.uvp_P[:,1]\n",
    "        self.p_P = self.uvp_P[:,2]\n",
    "\n",
    "        #compute derivations\n",
    "        self.du_dx = self.gradient(self.u_P,0)\n",
    "        self.du_dy = self.gradient(self.u_P,1)\n",
    "        self.du_dxx= self.gradient(self.du_dx,0)\n",
    "        self.du_dyy= self.gradient(self.du_dy,1)\n",
    "        self.dv_dx = self.gradient(self.v_P,0)\n",
    "        self.dv_dy = self.gradient(self.v_P,1)\n",
    "        self.dv_dxx= self.gradient(self.dv_dx,0)\n",
    "        self.dv_dyy= self.gradient(self.dv_dy,1)\n",
    "        self.dp_dx = self.gradient(self.p_P,0)\n",
    "        self.dp_dy = self.gradient(self.p_P,1)\n",
    "\n",
    "        # Navier-Stokes equations residuals\n",
    "        continuity = self.du_dx + self.dv_dy\n",
    "        momentum_x = self.u_P * self.du_dx + self.v_P * self.du_dy + self.dp_dx - (1/self.Re) * (self.du_dxx + self.du_dyy)\n",
    "        momentum_y = self.u_P * self.dv_dx + self.v_P * self.dv_dy + self.dp_dy - (1/self.Re) * (self.dv_dxx + self.dv_dyy)\n",
    "\n",
    "        # Only PDE loss (no BC loss since we use hard BC)\n",
    "\n",
    "        self.loss_pde = self.criterion(continuity, torch.zeros_like(continuity)) + \\\n",
    "                self.criterion(momentum_x, torch.zeros_like(momentum_x)) + \\\n",
    "                self.criterion(momentum_y, torch.zeros_like(momentum_y))\n",
    "\n",
    "        #loss function definition\n",
    "        lambda_bc = 1.0\n",
    "        lambda_pde = 1.0\n",
    "        self.loss = lambda_bc * self.loss_data + lambda_pde * self.loss_pde\n",
    "        self.loss.backward()\n",
    "        return self.loss\n",
    "    def train(self, num_epochs=1):\n",
    "        self.network.train()\n",
    "        for i in range(num_epochs):\n",
    "            loss = self.loss_f()\n",
    "            self.loss_history.append(loss.item())\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Iteration {i}, Loss: {self.loss.item():.9f}\")\n",
    "            if i % 100 == 0:\n",
    "                torch.save(self.network.state_dict(), r'C:/Users/hossein/Result/Backward-facing step/Ra=800/1-PINNs/model')\n",
    "            self.adam.step(self.loss_f)\n",
    "        self.optimizer.step(self.loss_f)\n",
    "        torch.save(self.network.state_dict(), r'C:/Users/hossein/Result/Backward-facing step/Ra=800/1-PINNs/model')\n",
    "    def plot(self):\n",
    "        import os\n",
    "        os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "        self.network.eval()\n",
    "        with torch.no_grad():\n",
    "            self.u = self.uvp_P[:,0].reshape(len(self.x), len(self.y)).cpu().numpy().T\n",
    "            self.v = self.uvp_P[:,1].reshape(len(self.x), len(self.y)).cpu().numpy().T\n",
    "            self.p = self.uvp_P[:,2].reshape(len(self.x), len(self.y)).cpu().numpy().T\n",
    "\n",
    "        plt.rcParams.update({\n",
    "            \"font.family\": \"Times New Roman\",\n",
    "            \"font.style\": \"italic\"\n",
    "        })\n",
    "\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        contour1 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(), self.u, levels=50, cmap=\"jet\")\n",
    "        cbar = plt.colorbar(contour1, orientation='horizontal', pad=0.2, aspect=60, location='top')\n",
    "        cbar.ax.set_title('u-velocity', fontsize=14, pad=10)\n",
    "        cbar.ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%.3f\"))\n",
    "        cbar.ax.xaxis.set_ticks_position('bottom')\n",
    "        plt.xlabel(\"x \", fontsize=14)\n",
    "        plt.ylabel(\"y \", fontsize=14)\n",
    "        plt.savefig(\"C:/Users/hossein/Result/Backward-facing step/Ra=800/1-PINNs/u_plot.png\", dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        contour2 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(), self.v, levels=50, cmap=\"jet\")\n",
    "        cbar = plt.colorbar(contour2, orientation='horizontal', pad=0.2, aspect=60, location='top')\n",
    "        cbar.ax.set_title('v-velocity', fontsize=14, pad=10)\n",
    "        cbar.ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%.3f\"))\n",
    "        cbar.ax.xaxis.set_ticks_position('bottom')\n",
    "        plt.xlabel(\"x \", fontsize=14)\n",
    "        plt.ylabel(\"y \", fontsize=14)\n",
    "        plt.savefig(\"C:/Users/hossein/Result/Backward-facing step/Ra=800/1-PINNs/v_plot.png\", dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        contour3 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(), self.p, levels=50, cmap=\"jet\")\n",
    "        cbar = plt.colorbar(contour3, orientation='horizontal', pad=0.2, aspect=60, location='top')\n",
    "        cbar.ax.set_title('Pressure', fontsize=14, pad=10)\n",
    "        cbar.ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%.3f\"))\n",
    "        cbar.ax.xaxis.set_ticks_position('bottom')\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.savefig(\"C:/Users/hossein/Result/Backward-facing step/Ra=800/1-PINNs/pressure_plot.png\", dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(self.loss_history, label='Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss Function History')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        df = pd.DataFrame({\"loss\": self.loss_history})\n",
    "        df.to_csv(\"C:/Users/hossein/Result/Backward-facing step/Ra=800/1-PINNs/loss_history3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "177b46bb-c019-4a9d-af2e-def5a8b158b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Iteration 0, Loss: 0.000000427\n",
      "Iteration 10, Loss: 0.000010422\n",
      "Iteration 20, Loss: 0.000004432\n",
      "Iteration 30, Loss: 0.000002277\n",
      "Iteration 40, Loss: 0.000001067\n",
      "Iteration 50, Loss: 0.000000612\n",
      "Iteration 60, Loss: 0.000000510\n",
      "Iteration 70, Loss: 0.000000462\n",
      "Iteration 80, Loss: 0.000000442\n",
      "Iteration 90, Loss: 0.000000434\n",
      "Iteration 100, Loss: 0.000000433\n",
      "Iteration 110, Loss: 0.000000431\n",
      "Iteration 120, Loss: 0.000000431\n",
      "Iteration 130, Loss: 0.000000430\n",
      "Iteration 140, Loss: 0.000000430\n",
      "Iteration 150, Loss: 0.000000429\n",
      "Iteration 160, Loss: 0.000000429\n",
      "Iteration 170, Loss: 0.000000429\n",
      "Iteration 180, Loss: 0.000000429\n",
      "Iteration 190, Loss: 0.000000429\n",
      "Iteration 200, Loss: 0.000000428\n",
      "Iteration 210, Loss: 0.000000428\n",
      "Iteration 220, Loss: 0.000000428\n",
      "Iteration 230, Loss: 0.000000428\n",
      "Iteration 240, Loss: 0.000000428\n",
      "Iteration 250, Loss: 0.000000428\n",
      "Iteration 260, Loss: 0.000000428\n",
      "Iteration 270, Loss: 0.000000428\n",
      "Iteration 280, Loss: 0.000000428\n",
      "Iteration 290, Loss: 0.000000427\n",
      "Iteration 300, Loss: 0.000000427\n",
      "Iteration 310, Loss: 0.000000427\n",
      "Iteration 320, Loss: 0.000000427\n",
      "Iteration 330, Loss: 0.000000427\n",
      "Iteration 340, Loss: 0.000000427\n",
      "Iteration 350, Loss: 0.000000427\n",
      "Iteration 360, Loss: 0.000000427\n",
      "Iteration 370, Loss: 0.000000427\n",
      "Iteration 380, Loss: 0.000000427\n",
      "Iteration 390, Loss: 0.000000427\n",
      "Iteration 400, Loss: 0.000000427\n",
      "Iteration 410, Loss: 0.000000426\n",
      "Iteration 420, Loss: 0.000000426\n",
      "Iteration 430, Loss: 0.000000426\n",
      "Iteration 440, Loss: 0.000000426\n",
      "Iteration 450, Loss: 0.000000426\n",
      "Iteration 460, Loss: 0.000000426\n",
      "Iteration 470, Loss: 0.000000426\n",
      "Iteration 480, Loss: 0.000000426\n",
      "Iteration 490, Loss: 0.000000426\n",
      "Iteration 500, Loss: 0.000000426\n",
      "Iteration 510, Loss: 0.000000426\n",
      "Iteration 520, Loss: 0.000000426\n",
      "Iteration 530, Loss: 0.000000426\n",
      "Iteration 540, Loss: 0.000000929\n",
      "Iteration 550, Loss: 0.000000494\n",
      "Iteration 560, Loss: 0.000000448\n",
      "Iteration 570, Loss: 0.000000458\n",
      "Iteration 580, Loss: 0.000000439\n",
      "Iteration 590, Loss: 0.000000443\n",
      "Iteration 600, Loss: 0.000000427\n",
      "Iteration 610, Loss: 0.000000426\n",
      "Iteration 620, Loss: 0.000000519\n",
      "Iteration 630, Loss: 0.000001519\n",
      "Iteration 640, Loss: 0.000001092\n",
      "Iteration 650, Loss: 0.000000659\n",
      "Iteration 660, Loss: 0.000000514\n",
      "Iteration 670, Loss: 0.000000460\n",
      "Iteration 680, Loss: 0.000000434\n",
      "Iteration 690, Loss: 0.000000426\n",
      "Iteration 700, Loss: 0.000000427\n",
      "Iteration 710, Loss: 0.000000425\n",
      "Iteration 720, Loss: 0.000000425\n",
      "Iteration 730, Loss: 0.000000425\n",
      "Iteration 740, Loss: 0.000000425\n",
      "Iteration 750, Loss: 0.000000461\n",
      "Iteration 760, Loss: 0.000000794\n",
      "Iteration 770, Loss: 0.000000706\n",
      "Iteration 780, Loss: 0.000000555\n",
      "Iteration 790, Loss: 0.000001371\n",
      "Iteration 800, Loss: 0.000000674\n",
      "Iteration 810, Loss: 0.000000582\n",
      "Iteration 820, Loss: 0.000000499\n",
      "Iteration 830, Loss: 0.000000524\n",
      "Iteration 840, Loss: 0.000000461\n",
      "Iteration 850, Loss: 0.000000443\n",
      "Iteration 860, Loss: 0.000000430\n",
      "Iteration 870, Loss: 0.000000489\n",
      "Iteration 880, Loss: 0.000002532\n",
      "Iteration 890, Loss: 0.000000853\n",
      "Iteration 900, Loss: 0.000000552\n",
      "Iteration 910, Loss: 0.000000476\n",
      "Iteration 920, Loss: 0.000000436\n",
      "Iteration 930, Loss: 0.000000458\n",
      "Iteration 940, Loss: 0.000000467\n",
      "Iteration 950, Loss: 0.000000491\n",
      "Iteration 960, Loss: 0.000000894\n",
      "Iteration 970, Loss: 0.000000559\n",
      "Iteration 980, Loss: 0.000000454\n",
      "Iteration 990, Loss: 0.000000430\n",
      "Iteration 1000, Loss: 0.000000430\n",
      "Iteration 1010, Loss: 0.000000437\n",
      "Iteration 1020, Loss: 0.000001117\n",
      "Iteration 1030, Loss: 0.000001411\n",
      "Iteration 1040, Loss: 0.000000561\n",
      "Iteration 1050, Loss: 0.000000486\n",
      "Iteration 1060, Loss: 0.000000447\n",
      "Iteration 1070, Loss: 0.000000429\n",
      "Iteration 1080, Loss: 0.000000426\n",
      "Iteration 1090, Loss: 0.000000428\n",
      "Iteration 1100, Loss: 0.000000441\n",
      "Iteration 1110, Loss: 0.000000570\n",
      "Iteration 1120, Loss: 0.000001188\n",
      "Iteration 1130, Loss: 0.000000771\n",
      "Iteration 1140, Loss: 0.000000478\n",
      "Iteration 1150, Loss: 0.000000434\n",
      "Iteration 1160, Loss: 0.000000439\n",
      "Iteration 1170, Loss: 0.000000428\n",
      "Iteration 1180, Loss: 0.000000425\n",
      "Iteration 1190, Loss: 0.000000425\n",
      "Iteration 1200, Loss: 0.000000424\n",
      "Iteration 1210, Loss: 0.000000424\n",
      "Iteration 1220, Loss: 0.000000424\n",
      "Iteration 1230, Loss: 0.000000425\n",
      "Iteration 1240, Loss: 0.000000540\n",
      "Iteration 1250, Loss: 0.000003757\n",
      "Iteration 1260, Loss: 0.000001262\n",
      "Iteration 1270, Loss: 0.000000616\n",
      "Iteration 1280, Loss: 0.000000478\n",
      "Iteration 1290, Loss: 0.000000441\n",
      "Iteration 1300, Loss: 0.000000431\n",
      "Iteration 1310, Loss: 0.000000429\n",
      "Iteration 1320, Loss: 0.000000425\n",
      "Iteration 1330, Loss: 0.000000425\n",
      "Iteration 1340, Loss: 0.000000424\n",
      "Iteration 1350, Loss: 0.000000429\n",
      "Iteration 1360, Loss: 0.000001340\n",
      "Iteration 1370, Loss: 0.000001531\n",
      "Iteration 1380, Loss: 0.000000745\n",
      "Iteration 1390, Loss: 0.000000542\n",
      "Iteration 1400, Loss: 0.000000467\n",
      "Iteration 1410, Loss: 0.000000435\n",
      "Iteration 1420, Loss: 0.000000425\n",
      "Iteration 1430, Loss: 0.000000424\n",
      "Iteration 1440, Loss: 0.000000424\n",
      "Iteration 1450, Loss: 0.000000426\n",
      "Iteration 1460, Loss: 0.000000559\n",
      "Iteration 1470, Loss: 0.000001865\n",
      "Iteration 1480, Loss: 0.000001162\n",
      "Iteration 1490, Loss: 0.000000726\n",
      "Iteration 1500, Loss: 0.000000463\n",
      "Iteration 1510, Loss: 0.000000434\n",
      "Iteration 1520, Loss: 0.000000430\n",
      "Iteration 1530, Loss: 0.000000427\n",
      "Iteration 1540, Loss: 0.000000424\n",
      "Iteration 1550, Loss: 0.000000424\n",
      "Iteration 1560, Loss: 0.000000423\n",
      "Iteration 1570, Loss: 0.000000425\n",
      "Iteration 1580, Loss: 0.000000526\n",
      "Iteration 1590, Loss: 0.000001040\n",
      "Iteration 1600, Loss: 0.000001359\n",
      "Iteration 1610, Loss: 0.000000481\n",
      "Iteration 1620, Loss: 0.000000543\n",
      "Iteration 1630, Loss: 0.000000492\n",
      "Iteration 1640, Loss: 0.000000439\n",
      "Iteration 1650, Loss: 0.000000427\n",
      "Iteration 1660, Loss: 0.000000426\n",
      "Iteration 1670, Loss: 0.000000424\n",
      "Iteration 1680, Loss: 0.000000468\n",
      "Iteration 1690, Loss: 0.000002659\n",
      "Iteration 1700, Loss: 0.000000527\n",
      "Iteration 1710, Loss: 0.000000466\n",
      "Iteration 1720, Loss: 0.000000483\n",
      "Iteration 1730, Loss: 0.000000504\n",
      "Iteration 1740, Loss: 0.000001129\n",
      "Iteration 1750, Loss: 0.000000458\n",
      "Iteration 1760, Loss: 0.000000430\n",
      "Iteration 1770, Loss: 0.000000427\n",
      "Iteration 1780, Loss: 0.000000429\n",
      "Iteration 1790, Loss: 0.000000460\n",
      "Iteration 1800, Loss: 0.000000577\n",
      "Iteration 1810, Loss: 0.000000445\n",
      "Iteration 1820, Loss: 0.000000437\n",
      "Iteration 1830, Loss: 0.000000444\n",
      "Iteration 1840, Loss: 0.000000542\n",
      "Iteration 1850, Loss: 0.000003026\n",
      "Iteration 1860, Loss: 0.000001106\n",
      "Iteration 1870, Loss: 0.000000510\n",
      "Iteration 1880, Loss: 0.000000511\n",
      "Iteration 1890, Loss: 0.000000435\n",
      "Iteration 1900, Loss: 0.000000434\n",
      "Iteration 1910, Loss: 0.000000436\n",
      "Iteration 1920, Loss: 0.000000815\n",
      "Iteration 1930, Loss: 0.000000560\n",
      "Iteration 1940, Loss: 0.000000562\n",
      "Iteration 1950, Loss: 0.000000432\n",
      "Iteration 1960, Loss: 0.000000435\n",
      "Iteration 1970, Loss: 0.000000429\n",
      "Iteration 1980, Loss: 0.000000424\n",
      "Iteration 1990, Loss: 0.000000492\n",
      "Iteration 2000, Loss: 0.000003902\n",
      "Iteration 2010, Loss: 0.000001076\n",
      "Iteration 2020, Loss: 0.000000519\n",
      "Iteration 2030, Loss: 0.000000494\n",
      "Iteration 2040, Loss: 0.000000458\n",
      "Iteration 2050, Loss: 0.000000431\n",
      "Iteration 2060, Loss: 0.000000426\n",
      "Iteration 2070, Loss: 0.000000423\n",
      "Iteration 2080, Loss: 0.000000423\n",
      "Iteration 2090, Loss: 0.000000473\n",
      "Iteration 2100, Loss: 0.000003029\n",
      "Iteration 2110, Loss: 0.000001140\n",
      "Iteration 2120, Loss: 0.000000767\n",
      "Iteration 2130, Loss: 0.000000445\n",
      "Iteration 2140, Loss: 0.000000434\n",
      "Iteration 2150, Loss: 0.000000433\n",
      "Iteration 2160, Loss: 0.000000422\n",
      "Iteration 2170, Loss: 0.000000426\n",
      "Iteration 2180, Loss: 0.000000484\n",
      "Iteration 2190, Loss: 0.000000432\n",
      "Iteration 2200, Loss: 0.000000448\n",
      "Iteration 2210, Loss: 0.000000463\n",
      "Iteration 2220, Loss: 0.000001141\n",
      "Iteration 2230, Loss: 0.000000479\n",
      "Iteration 2240, Loss: 0.000000550\n",
      "Iteration 2250, Loss: 0.000000564\n",
      "Iteration 2260, Loss: 0.000000462\n",
      "Iteration 2270, Loss: 0.000000428\n",
      "Iteration 2280, Loss: 0.000000424\n",
      "Iteration 2290, Loss: 0.000000423\n",
      "Iteration 2300, Loss: 0.000000425\n",
      "Iteration 2310, Loss: 0.000000497\n",
      "Iteration 2320, Loss: 0.000001225\n",
      "Iteration 2330, Loss: 0.000000472\n",
      "Iteration 2340, Loss: 0.000000515\n",
      "Iteration 2350, Loss: 0.000000460\n",
      "Iteration 2360, Loss: 0.000001125\n",
      "Iteration 2370, Loss: 0.000000495\n",
      "Iteration 2380, Loss: 0.000000606\n",
      "Iteration 2390, Loss: 0.000000585\n",
      "Iteration 2400, Loss: 0.000000437\n",
      "Iteration 2410, Loss: 0.000000429\n",
      "Iteration 2420, Loss: 0.000000549\n",
      "Iteration 2430, Loss: 0.000001372\n",
      "Iteration 2440, Loss: 0.000000738\n",
      "Iteration 2450, Loss: 0.000000447\n",
      "Iteration 2460, Loss: 0.000000471\n",
      "Iteration 2470, Loss: 0.000000442\n",
      "Iteration 2480, Loss: 0.000000431\n",
      "Iteration 2490, Loss: 0.000000440\n",
      "Iteration 2500, Loss: 0.000000627\n",
      "Iteration 2510, Loss: 0.000000768\n",
      "Iteration 2520, Loss: 0.000001069\n",
      "Iteration 2530, Loss: 0.000000562\n",
      "Iteration 2540, Loss: 0.000000431\n",
      "Iteration 2550, Loss: 0.000000464\n",
      "Iteration 2560, Loss: 0.000000425\n",
      "Iteration 2570, Loss: 0.000000445\n",
      "Iteration 2580, Loss: 0.000000825\n",
      "Iteration 2590, Loss: 0.000001645\n",
      "Iteration 2600, Loss: 0.000000714\n",
      "Iteration 2610, Loss: 0.000000482\n",
      "Iteration 2620, Loss: 0.000000481\n",
      "Iteration 2630, Loss: 0.000000440\n",
      "Iteration 2640, Loss: 0.000000428\n",
      "Iteration 2650, Loss: 0.000000491\n",
      "Iteration 2660, Loss: 0.000002457\n",
      "Iteration 2670, Loss: 0.000001265\n",
      "Iteration 2680, Loss: 0.000000632\n",
      "Iteration 2690, Loss: 0.000000429\n",
      "Iteration 2700, Loss: 0.000000459\n",
      "Iteration 2710, Loss: 0.000000437\n",
      "Iteration 2720, Loss: 0.000000425\n",
      "Iteration 2730, Loss: 0.000000428\n",
      "Iteration 2740, Loss: 0.000000750\n",
      "Iteration 2750, Loss: 0.000001069\n",
      "Iteration 2760, Loss: 0.000000600\n",
      "Iteration 2770, Loss: 0.000000477\n",
      "Iteration 2780, Loss: 0.000000456\n",
      "Iteration 2790, Loss: 0.000000440\n",
      "Iteration 2800, Loss: 0.000000492\n",
      "Iteration 2810, Loss: 0.000001493\n",
      "Iteration 2820, Loss: 0.000000592\n",
      "Iteration 2830, Loss: 0.000000580\n",
      "Iteration 2840, Loss: 0.000000508\n",
      "Iteration 2850, Loss: 0.000000458\n",
      "Iteration 2860, Loss: 0.000000439\n",
      "Iteration 2870, Loss: 0.000000466\n",
      "Iteration 2880, Loss: 0.000001198\n",
      "Iteration 2890, Loss: 0.000000505\n",
      "Iteration 2900, Loss: 0.000000440\n",
      "Iteration 2910, Loss: 0.000000450\n",
      "Iteration 2920, Loss: 0.000000440\n",
      "Iteration 2930, Loss: 0.000000425\n",
      "Iteration 2940, Loss: 0.000000421\n",
      "Iteration 2950, Loss: 0.000000425\n",
      "Iteration 2960, Loss: 0.000000491\n",
      "Iteration 2970, Loss: 0.000001256\n",
      "Iteration 2980, Loss: 0.000000575\n",
      "Iteration 2990, Loss: 0.000000550\n",
      "Iteration 3000, Loss: 0.000001138\n",
      "Iteration 3010, Loss: 0.000000701\n",
      "Iteration 3020, Loss: 0.000000514\n",
      "Iteration 3030, Loss: 0.000000450\n",
      "Iteration 3040, Loss: 0.000000435\n",
      "Iteration 3050, Loss: 0.000000436\n",
      "Iteration 3060, Loss: 0.000000428\n",
      "Iteration 3070, Loss: 0.000000482\n",
      "Iteration 3080, Loss: 0.000001790\n",
      "Iteration 3090, Loss: 0.000001070\n",
      "Iteration 3100, Loss: 0.000000522\n",
      "Iteration 3110, Loss: 0.000000477\n",
      "Iteration 3120, Loss: 0.000000442\n",
      "Iteration 3130, Loss: 0.000000446\n",
      "Iteration 3140, Loss: 0.000000585\n",
      "Iteration 3150, Loss: 0.000001559\n",
      "Iteration 3160, Loss: 0.000000565\n",
      "Iteration 3170, Loss: 0.000000447\n",
      "Iteration 3180, Loss: 0.000000571\n",
      "Iteration 3190, Loss: 0.000000966\n",
      "Iteration 3200, Loss: 0.000000588\n",
      "Iteration 3210, Loss: 0.000000462\n",
      "Iteration 3220, Loss: 0.000000428\n",
      "Iteration 3230, Loss: 0.000000432\n",
      "Iteration 3240, Loss: 0.000000499\n",
      "Iteration 3250, Loss: 0.000001622\n",
      "Iteration 3260, Loss: 0.000000585\n",
      "Iteration 3270, Loss: 0.000000514\n",
      "Iteration 3280, Loss: 0.000000466\n",
      "Iteration 3290, Loss: 0.000000439\n",
      "Iteration 3300, Loss: 0.000000500\n",
      "Iteration 3310, Loss: 0.000001213\n",
      "Iteration 3320, Loss: 0.000000734\n",
      "Iteration 3330, Loss: 0.000000523\n",
      "Iteration 3340, Loss: 0.000000457\n",
      "Iteration 3350, Loss: 0.000000439\n",
      "Iteration 3360, Loss: 0.000000494\n",
      "Iteration 3370, Loss: 0.000000575\n",
      "Iteration 3380, Loss: 0.000002024\n",
      "Iteration 3390, Loss: 0.000000844\n",
      "Iteration 3400, Loss: 0.000000684\n",
      "Iteration 3410, Loss: 0.000000510\n",
      "Iteration 3420, Loss: 0.000000454\n",
      "Iteration 3430, Loss: 0.000000450\n",
      "Iteration 3440, Loss: 0.000000692\n",
      "Iteration 3450, Loss: 0.000000565\n",
      "Iteration 3460, Loss: 0.000000484\n",
      "Iteration 3470, Loss: 0.000000481\n",
      "Iteration 3480, Loss: 0.000000647\n",
      "Iteration 3490, Loss: 0.000000778\n",
      "Iteration 3500, Loss: 0.000000693\n",
      "Iteration 3510, Loss: 0.000000449\n",
      "Iteration 3520, Loss: 0.000000453\n",
      "Iteration 3530, Loss: 0.000000441\n",
      "Iteration 3540, Loss: 0.000000659\n",
      "Iteration 3550, Loss: 0.000002119\n",
      "Iteration 3560, Loss: 0.000000781\n",
      "Iteration 3570, Loss: 0.000000704\n",
      "Iteration 3580, Loss: 0.000000489\n",
      "Iteration 3590, Loss: 0.000000455\n",
      "Iteration 3600, Loss: 0.000000436\n",
      "Iteration 3610, Loss: 0.000000521\n",
      "Iteration 3620, Loss: 0.000001789\n",
      "Iteration 3630, Loss: 0.000000622\n",
      "Iteration 3640, Loss: 0.000000475\n",
      "Iteration 3650, Loss: 0.000000459\n",
      "Iteration 3660, Loss: 0.000000438\n",
      "Iteration 3670, Loss: 0.000000447\n",
      "Iteration 3680, Loss: 0.000000666\n",
      "Iteration 3690, Loss: 0.000001745\n",
      "Iteration 3700, Loss: 0.000000874\n",
      "Iteration 3710, Loss: 0.000000579\n",
      "Iteration 3720, Loss: 0.000000474\n",
      "Iteration 3730, Loss: 0.000000432\n",
      "Iteration 3740, Loss: 0.000000439\n",
      "Iteration 3750, Loss: 0.000000795\n",
      "Iteration 3760, Loss: 0.000000509\n",
      "Iteration 3770, Loss: 0.000000507\n",
      "Iteration 3780, Loss: 0.000000512\n",
      "Iteration 3790, Loss: 0.000000846\n",
      "Iteration 3800, Loss: 0.000001008\n",
      "Iteration 3810, Loss: 0.000000680\n",
      "Iteration 3820, Loss: 0.000000475\n",
      "Iteration 3830, Loss: 0.000000420\n",
      "Iteration 3840, Loss: 0.000000444\n",
      "Iteration 3850, Loss: 0.000000575\n",
      "Iteration 3860, Loss: 0.000001810\n",
      "Iteration 3870, Loss: 0.000000477\n",
      "Iteration 3880, Loss: 0.000000600\n",
      "Iteration 3890, Loss: 0.000000457\n",
      "Iteration 3900, Loss: 0.000000612\n",
      "Iteration 3910, Loss: 0.000001845\n",
      "Iteration 3920, Loss: 0.000000809\n",
      "Iteration 3930, Loss: 0.000000569\n",
      "Iteration 3940, Loss: 0.000000469\n",
      "Iteration 3950, Loss: 0.000000427\n",
      "Iteration 3960, Loss: 0.000000419\n",
      "Iteration 3970, Loss: 0.000000428\n",
      "Iteration 3980, Loss: 0.000000557\n",
      "Iteration 3990, Loss: 0.000000769\n",
      "Iteration 4000, Loss: 0.000000471\n",
      "Iteration 4010, Loss: 0.000000636\n",
      "Iteration 4020, Loss: 0.000001080\n",
      "Iteration 4030, Loss: 0.000000441\n",
      "Iteration 4040, Loss: 0.000000587\n",
      "Iteration 4050, Loss: 0.000000436\n",
      "Iteration 4060, Loss: 0.000000507\n",
      "Iteration 4070, Loss: 0.000000859\n",
      "Iteration 4080, Loss: 0.000000559\n",
      "Iteration 4090, Loss: 0.000000884\n",
      "Iteration 4100, Loss: 0.000000626\n",
      "Iteration 4110, Loss: 0.000000535\n",
      "Iteration 4120, Loss: 0.000000512\n",
      "Iteration 4130, Loss: 0.000001183\n",
      "Iteration 4140, Loss: 0.000000561\n",
      "Iteration 4150, Loss: 0.000000475\n",
      "Iteration 4160, Loss: 0.000000443\n",
      "Iteration 4170, Loss: 0.000000518\n",
      "Iteration 4180, Loss: 0.000003181\n",
      "Iteration 4190, Loss: 0.000001405\n",
      "Iteration 4200, Loss: 0.000000464\n",
      "Iteration 4210, Loss: 0.000000514\n",
      "Iteration 4220, Loss: 0.000000449\n",
      "Iteration 4230, Loss: 0.000000420\n",
      "Iteration 4240, Loss: 0.000000419\n",
      "Iteration 4250, Loss: 0.000000418\n",
      "Iteration 4260, Loss: 0.000000418\n",
      "Iteration 4270, Loss: 0.000000493\n",
      "Iteration 4280, Loss: 0.000000578\n",
      "Iteration 4290, Loss: 0.000001295\n",
      "Iteration 4300, Loss: 0.000000537\n",
      "Iteration 4310, Loss: 0.000000556\n",
      "Iteration 4320, Loss: 0.000000427\n",
      "Iteration 4330, Loss: 0.000000437\n",
      "Iteration 4340, Loss: 0.000000470\n",
      "Iteration 4350, Loss: 0.000001278\n",
      "Iteration 4360, Loss: 0.000001157\n",
      "Iteration 4370, Loss: 0.000000775\n",
      "Iteration 4380, Loss: 0.000000560\n",
      "Iteration 4390, Loss: 0.000000447\n",
      "Iteration 4400, Loss: 0.000000424\n",
      "Iteration 4410, Loss: 0.000000420\n",
      "Iteration 4420, Loss: 0.000000419\n",
      "Iteration 4430, Loss: 0.000000419\n",
      "Iteration 4440, Loss: 0.000000430\n",
      "Iteration 4450, Loss: 0.000000716\n",
      "Iteration 4460, Loss: 0.000001995\n",
      "Iteration 4470, Loss: 0.000000703\n",
      "Iteration 4480, Loss: 0.000000436\n",
      "Iteration 4490, Loss: 0.000000446\n",
      "Iteration 4500, Loss: 0.000000435\n",
      "Iteration 4510, Loss: 0.000000426\n",
      "Iteration 4520, Loss: 0.000000440\n",
      "Iteration 4530, Loss: 0.000000970\n",
      "Iteration 4540, Loss: 0.000000537\n",
      "Iteration 4550, Loss: 0.000000553\n",
      "Iteration 4560, Loss: 0.000000510\n",
      "Iteration 4570, Loss: 0.000000447\n",
      "Iteration 4580, Loss: 0.000000441\n",
      "Iteration 4590, Loss: 0.000000655\n",
      "Iteration 4600, Loss: 0.000001930\n",
      "Iteration 4610, Loss: 0.000000838\n",
      "Iteration 4620, Loss: 0.000000544\n",
      "Iteration 4630, Loss: 0.000000459\n",
      "Iteration 4640, Loss: 0.000000431\n",
      "Iteration 4650, Loss: 0.000000434\n",
      "Iteration 4660, Loss: 0.000000531\n",
      "Iteration 4670, Loss: 0.000000741\n",
      "Iteration 4680, Loss: 0.000000482\n",
      "Iteration 4690, Loss: 0.000000486\n",
      "Iteration 4700, Loss: 0.000001368\n",
      "Iteration 4710, Loss: 0.000000478\n",
      "Iteration 4720, Loss: 0.000000470\n",
      "Iteration 4730, Loss: 0.000000466\n",
      "Iteration 4740, Loss: 0.000000443\n",
      "Iteration 4750, Loss: 0.000000463\n",
      "Iteration 4760, Loss: 0.000001146\n",
      "Iteration 4770, Loss: 0.000000607\n",
      "Iteration 4780, Loss: 0.000000527\n",
      "Iteration 4790, Loss: 0.000000463\n",
      "Iteration 4800, Loss: 0.000000448\n",
      "Iteration 4810, Loss: 0.000000619\n",
      "Iteration 4820, Loss: 0.000002100\n",
      "Iteration 4830, Loss: 0.000000897\n",
      "Iteration 4840, Loss: 0.000000527\n",
      "Iteration 4850, Loss: 0.000000451\n",
      "Iteration 4860, Loss: 0.000000432\n",
      "Iteration 4870, Loss: 0.000000422\n",
      "Iteration 4880, Loss: 0.000000420\n",
      "Iteration 4890, Loss: 0.000000458\n",
      "Iteration 4900, Loss: 0.000001218\n",
      "Iteration 4910, Loss: 0.000001055\n",
      "Iteration 4920, Loss: 0.000000807\n",
      "Iteration 4930, Loss: 0.000000602\n",
      "Iteration 4940, Loss: 0.000000443\n",
      "Iteration 4950, Loss: 0.000000458\n",
      "Iteration 4960, Loss: 0.000000433\n",
      "Iteration 4970, Loss: 0.000000489\n",
      "Iteration 4980, Loss: 0.000001280\n",
      "Iteration 4990, Loss: 0.000001236\n",
      "Iteration 5000, Loss: 0.000000612\n",
      "Iteration 5010, Loss: 0.000000597\n",
      "Iteration 5020, Loss: 0.000000436\n",
      "Iteration 5030, Loss: 0.000000450\n",
      "Iteration 5040, Loss: 0.000000446\n",
      "Iteration 5050, Loss: 0.000000521\n",
      "Iteration 5060, Loss: 0.000001244\n",
      "Iteration 5070, Loss: 0.000000441\n",
      "Iteration 5080, Loss: 0.000000496\n",
      "Iteration 5090, Loss: 0.000000576\n",
      "Iteration 5100, Loss: 0.000000890\n",
      "Iteration 5110, Loss: 0.000000530\n",
      "Iteration 5120, Loss: 0.000000433\n",
      "Iteration 5130, Loss: 0.000000439\n",
      "Iteration 5140, Loss: 0.000000458\n",
      "Iteration 5150, Loss: 0.000000700\n",
      "Iteration 5160, Loss: 0.000000610\n",
      "Iteration 5170, Loss: 0.000001001\n",
      "Iteration 5180, Loss: 0.000001291\n",
      "Iteration 5190, Loss: 0.000000482\n",
      "Iteration 5200, Loss: 0.000000539\n",
      "Iteration 5210, Loss: 0.000000484\n",
      "Iteration 5220, Loss: 0.000000433\n",
      "Iteration 5230, Loss: 0.000000424\n",
      "Iteration 5240, Loss: 0.000000428\n",
      "Iteration 5250, Loss: 0.000000549\n",
      "Iteration 5260, Loss: 0.000000530\n",
      "Iteration 5270, Loss: 0.000000454\n",
      "Iteration 5280, Loss: 0.000000840\n",
      "Iteration 5290, Loss: 0.000000441\n",
      "Iteration 5300, Loss: 0.000000485\n",
      "Iteration 5310, Loss: 0.000000486\n",
      "Iteration 5320, Loss: 0.000000861\n",
      "Iteration 5330, Loss: 0.000001312\n",
      "Iteration 5340, Loss: 0.000000561\n",
      "Iteration 5350, Loss: 0.000000435\n",
      "Iteration 5360, Loss: 0.000000450\n",
      "Iteration 5370, Loss: 0.000000435\n",
      "Iteration 5380, Loss: 0.000000425\n",
      "Iteration 5390, Loss: 0.000000435\n",
      "Iteration 5400, Loss: 0.000000701\n",
      "Iteration 5410, Loss: 0.000001822\n",
      "Iteration 5420, Loss: 0.000000870\n",
      "Iteration 5430, Loss: 0.000000522\n",
      "Iteration 5440, Loss: 0.000000438\n",
      "Iteration 5450, Loss: 0.000000422\n",
      "Iteration 5460, Loss: 0.000000419\n",
      "Iteration 5470, Loss: 0.000000422\n",
      "Iteration 5480, Loss: 0.000000551\n",
      "Iteration 5490, Loss: 0.000001499\n",
      "Iteration 5500, Loss: 0.000000559\n",
      "Iteration 5510, Loss: 0.000000513\n",
      "Iteration 5520, Loss: 0.000000581\n",
      "Iteration 5530, Loss: 0.000000810\n",
      "Iteration 5540, Loss: 0.000000489\n",
      "Iteration 5550, Loss: 0.000000436\n",
      "Iteration 5560, Loss: 0.000000456\n",
      "Iteration 5570, Loss: 0.000000673\n",
      "Iteration 5580, Loss: 0.000001522\n",
      "Iteration 5590, Loss: 0.000000674\n",
      "Iteration 5600, Loss: 0.000000447\n",
      "Iteration 5610, Loss: 0.000000426\n",
      "Iteration 5620, Loss: 0.000000444\n",
      "Iteration 5630, Loss: 0.000000644\n",
      "Iteration 5640, Loss: 0.000000535\n",
      "Iteration 5650, Loss: 0.000000546\n",
      "Iteration 5660, Loss: 0.000000553\n",
      "Iteration 5670, Loss: 0.000000913\n",
      "Iteration 5680, Loss: 0.000000840\n",
      "Iteration 5690, Loss: 0.000000749\n",
      "Iteration 5700, Loss: 0.000000477\n",
      "Iteration 5710, Loss: 0.000000423\n",
      "Iteration 5720, Loss: 0.000000440\n",
      "Iteration 5730, Loss: 0.000000482\n",
      "Iteration 5740, Loss: 0.000001294\n",
      "Iteration 5750, Loss: 0.000001045\n",
      "Iteration 5760, Loss: 0.000000644\n",
      "Iteration 5770, Loss: 0.000000489\n",
      "Iteration 5780, Loss: 0.000000418\n",
      "Iteration 5790, Loss: 0.000000429\n",
      "Iteration 5800, Loss: 0.000000451\n",
      "Iteration 5810, Loss: 0.000000740\n",
      "Iteration 5820, Loss: 0.000001330\n",
      "Iteration 5830, Loss: 0.000000749\n",
      "Iteration 5840, Loss: 0.000000520\n",
      "Iteration 5850, Loss: 0.000000431\n",
      "Iteration 5860, Loss: 0.000000417\n",
      "Iteration 5870, Loss: 0.000000510\n",
      "Iteration 5880, Loss: 0.000000556\n",
      "Iteration 5890, Loss: 0.000000568\n",
      "Iteration 5900, Loss: 0.000000432\n",
      "Iteration 5910, Loss: 0.000000936\n",
      "Iteration 5920, Loss: 0.000001119\n",
      "Iteration 5930, Loss: 0.000000956\n",
      "Iteration 5940, Loss: 0.000000515\n",
      "Iteration 5950, Loss: 0.000000423\n",
      "Iteration 5960, Loss: 0.000000444\n",
      "Iteration 5970, Loss: 0.000000424\n",
      "Iteration 5980, Loss: 0.000000444\n",
      "Iteration 5990, Loss: 0.000000832\n",
      "Iteration 6000, Loss: 0.000000874\n",
      "Iteration 6010, Loss: 0.000000659\n",
      "Iteration 6020, Loss: 0.000000498\n",
      "Iteration 6030, Loss: 0.000000424\n",
      "Iteration 6040, Loss: 0.000000422\n",
      "Iteration 6050, Loss: 0.000000434\n",
      "Iteration 6060, Loss: 0.000000815\n",
      "Iteration 6070, Loss: 0.000000538\n",
      "Iteration 6080, Loss: 0.000000513\n",
      "Iteration 6090, Loss: 0.000000742\n",
      "Iteration 6100, Loss: 0.000001594\n",
      "Iteration 6110, Loss: 0.000000810\n",
      "Iteration 6120, Loss: 0.000000552\n",
      "Iteration 6130, Loss: 0.000000458\n",
      "Iteration 6140, Loss: 0.000000418\n",
      "Iteration 6150, Loss: 0.000000419\n",
      "Iteration 6160, Loss: 0.000000464\n",
      "Iteration 6170, Loss: 0.000001386\n",
      "Iteration 6180, Loss: 0.000000822\n",
      "Iteration 6190, Loss: 0.000000648\n",
      "Iteration 6200, Loss: 0.000000552\n",
      "Iteration 6210, Loss: 0.000000532\n",
      "Iteration 6220, Loss: 0.000000552\n",
      "Iteration 6230, Loss: 0.000000695\n",
      "Iteration 6240, Loss: 0.000000687\n",
      "Iteration 6250, Loss: 0.000000414\n",
      "Iteration 6260, Loss: 0.000000468\n",
      "Iteration 6270, Loss: 0.000000611\n",
      "Iteration 6280, Loss: 0.000001010\n",
      "Iteration 6290, Loss: 0.000000961\n",
      "Iteration 6300, Loss: 0.000000665\n",
      "Iteration 6310, Loss: 0.000000601\n",
      "Iteration 6320, Loss: 0.000000471\n",
      "Iteration 6330, Loss: 0.000000442\n",
      "Iteration 6340, Loss: 0.000000422\n",
      "Iteration 6350, Loss: 0.000000427\n",
      "Iteration 6360, Loss: 0.000000712\n",
      "Iteration 6370, Loss: 0.000000658\n",
      "Iteration 6380, Loss: 0.000001692\n",
      "Iteration 6390, Loss: 0.000000838\n",
      "Iteration 6400, Loss: 0.000000525\n",
      "Iteration 6410, Loss: 0.000000447\n",
      "Iteration 6420, Loss: 0.000000427\n",
      "Iteration 6430, Loss: 0.000000499\n",
      "Iteration 6440, Loss: 0.000001366\n",
      "Iteration 6450, Loss: 0.000000713\n",
      "Iteration 6460, Loss: 0.000000515\n",
      "Iteration 6470, Loss: 0.000000457\n",
      "Iteration 6480, Loss: 0.000000483\n",
      "Iteration 6490, Loss: 0.000001147\n",
      "Iteration 6500, Loss: 0.000000532\n",
      "Iteration 6510, Loss: 0.000000481\n",
      "Iteration 6520, Loss: 0.000000454\n",
      "Iteration 6530, Loss: 0.000000440\n",
      "Iteration 6540, Loss: 0.000000466\n",
      "Iteration 6550, Loss: 0.000001280\n",
      "Iteration 6560, Loss: 0.000000690\n",
      "Iteration 6570, Loss: 0.000000439\n",
      "Iteration 6580, Loss: 0.000000428\n",
      "Iteration 6590, Loss: 0.000000426\n",
      "Iteration 6600, Loss: 0.000000419\n",
      "Iteration 6610, Loss: 0.000000689\n",
      "Iteration 6620, Loss: 0.000002546\n",
      "Iteration 6630, Loss: 0.000000861\n",
      "Iteration 6640, Loss: 0.000000544\n",
      "Iteration 6650, Loss: 0.000000514\n",
      "Iteration 6660, Loss: 0.000000432\n",
      "Iteration 6670, Loss: 0.000000426\n",
      "Iteration 6680, Loss: 0.000000413\n",
      "Iteration 6690, Loss: 0.000000421\n",
      "Iteration 6700, Loss: 0.000000965\n",
      "Iteration 6710, Loss: 0.000000689\n",
      "Iteration 6720, Loss: 0.000000732\n",
      "Iteration 6730, Loss: 0.000000456\n",
      "Iteration 6740, Loss: 0.000000437\n",
      "Iteration 6750, Loss: 0.000000421\n",
      "Iteration 6760, Loss: 0.000000416\n",
      "Iteration 6770, Loss: 0.000000412\n",
      "Iteration 6780, Loss: 0.000000428\n",
      "Iteration 6790, Loss: 0.000000847\n",
      "Iteration 6800, Loss: 0.000000490\n",
      "Iteration 6810, Loss: 0.000000501\n",
      "Iteration 6820, Loss: 0.000000445\n",
      "Iteration 6830, Loss: 0.000000417\n",
      "Iteration 6840, Loss: 0.000000415\n",
      "Iteration 6850, Loss: 0.000000634\n",
      "Iteration 6860, Loss: 0.000002568\n",
      "Iteration 6870, Loss: 0.000000492\n",
      "Iteration 6880, Loss: 0.000000676\n",
      "Iteration 6890, Loss: 0.000000453\n",
      "Iteration 6900, Loss: 0.000000448\n",
      "Iteration 6910, Loss: 0.000000430\n",
      "Iteration 6920, Loss: 0.000000448\n",
      "Iteration 6930, Loss: 0.000000754\n",
      "Iteration 6940, Loss: 0.000000499\n",
      "Iteration 6950, Loss: 0.000000443\n",
      "Iteration 6960, Loss: 0.000000500\n",
      "Iteration 6970, Loss: 0.000000834\n",
      "Iteration 6980, Loss: 0.000000440\n",
      "Iteration 6990, Loss: 0.000000462\n",
      "Iteration 7000, Loss: 0.000000440\n",
      "Iteration 7010, Loss: 0.000000416\n",
      "Iteration 7020, Loss: 0.000000431\n",
      "Iteration 7030, Loss: 0.000000997\n",
      "Iteration 7040, Loss: 0.000001457\n",
      "Iteration 7050, Loss: 0.000000936\n",
      "Iteration 7060, Loss: 0.000000489\n",
      "Iteration 7070, Loss: 0.000000466\n",
      "Iteration 7080, Loss: 0.000000430\n",
      "Iteration 7090, Loss: 0.000000507\n",
      "Iteration 7100, Loss: 0.000001270\n",
      "Iteration 7110, Loss: 0.000000711\n",
      "Iteration 7120, Loss: 0.000000515\n",
      "Iteration 7130, Loss: 0.000000450\n",
      "Iteration 7140, Loss: 0.000000428\n",
      "Iteration 7150, Loss: 0.000000435\n",
      "Iteration 7160, Loss: 0.000000769\n",
      "Iteration 7170, Loss: 0.000002539\n",
      "Iteration 7180, Loss: 0.000000625\n",
      "Iteration 7190, Loss: 0.000000607\n",
      "Iteration 7200, Loss: 0.000000484\n",
      "Iteration 7210, Loss: 0.000000425\n",
      "Iteration 7220, Loss: 0.000000420\n",
      "Iteration 7230, Loss: 0.000000414\n",
      "Iteration 7240, Loss: 0.000000410\n",
      "Iteration 7250, Loss: 0.000000410\n",
      "Iteration 7260, Loss: 0.000000417\n",
      "Iteration 7270, Loss: 0.000000733\n",
      "Iteration 7280, Loss: 0.000000582\n",
      "Iteration 7290, Loss: 0.000000661\n",
      "Iteration 7300, Loss: 0.000000435\n",
      "Iteration 7310, Loss: 0.000000444\n",
      "Iteration 7320, Loss: 0.000000415\n",
      "Iteration 7330, Loss: 0.000000422\n",
      "Iteration 7340, Loss: 0.000000610\n",
      "Iteration 7350, Loss: 0.000001337\n",
      "Iteration 7360, Loss: 0.000000678\n",
      "Iteration 7370, Loss: 0.000000502\n",
      "Iteration 7380, Loss: 0.000000454\n",
      "Iteration 7390, Loss: 0.000000417\n",
      "Iteration 7400, Loss: 0.000000413\n",
      "Iteration 7410, Loss: 0.000000439\n",
      "Iteration 7420, Loss: 0.000001311\n",
      "Iteration 7430, Loss: 0.000000449\n",
      "Iteration 7440, Loss: 0.000000647\n",
      "Iteration 7450, Loss: 0.000000566\n",
      "Iteration 7460, Loss: 0.000000428\n",
      "Iteration 7470, Loss: 0.000000411\n",
      "Iteration 7480, Loss: 0.000000411\n",
      "Iteration 7490, Loss: 0.000000410\n",
      "Iteration 7500, Loss: 0.000000429\n",
      "Iteration 7510, Loss: 0.000001209\n",
      "Iteration 7520, Loss: 0.000000730\n",
      "Iteration 7530, Loss: 0.000000559\n",
      "Iteration 7540, Loss: 0.000000476\n",
      "Iteration 7550, Loss: 0.000000421\n",
      "Iteration 7560, Loss: 0.000000422\n",
      "Iteration 7570, Loss: 0.000000410\n",
      "Iteration 7580, Loss: 0.000000413\n",
      "Iteration 7590, Loss: 0.000000594\n",
      "Iteration 7600, Loss: 0.000003243\n",
      "Iteration 7610, Loss: 0.000000462\n",
      "Iteration 7620, Loss: 0.000000720\n",
      "Iteration 7630, Loss: 0.000000420\n",
      "Iteration 7640, Loss: 0.000000448\n",
      "Iteration 7650, Loss: 0.000000412\n",
      "Iteration 7660, Loss: 0.000000416\n",
      "Iteration 7670, Loss: 0.000000575\n",
      "Iteration 7680, Loss: 0.000001125\n",
      "Iteration 7690, Loss: 0.000000679\n",
      "Iteration 7700, Loss: 0.000000467\n",
      "Iteration 7710, Loss: 0.000000439\n",
      "Iteration 7720, Loss: 0.000000427\n",
      "Iteration 7730, Loss: 0.000000491\n",
      "Iteration 7740, Loss: 0.000001272\n",
      "Iteration 7750, Loss: 0.000000642\n",
      "Iteration 7760, Loss: 0.000000504\n",
      "Iteration 7770, Loss: 0.000000457\n",
      "Iteration 7780, Loss: 0.000000484\n",
      "Iteration 7790, Loss: 0.000001153\n",
      "Iteration 7800, Loss: 0.000000479\n",
      "Iteration 7810, Loss: 0.000000490\n",
      "Iteration 7820, Loss: 0.000000471\n",
      "Iteration 7830, Loss: 0.000000446\n",
      "Iteration 7840, Loss: 0.000000422\n",
      "Iteration 7850, Loss: 0.000000647\n",
      "Iteration 7860, Loss: 0.000000555\n",
      "Iteration 7870, Loss: 0.000000582\n",
      "Iteration 7880, Loss: 0.000000777\n",
      "Iteration 7890, Loss: 0.000000534\n",
      "Iteration 7900, Loss: 0.000000997\n",
      "Iteration 7910, Loss: 0.000000808\n",
      "Iteration 7920, Loss: 0.000000609\n",
      "Iteration 7930, Loss: 0.000000435\n",
      "Iteration 7940, Loss: 0.000000443\n",
      "Iteration 7950, Loss: 0.000000416\n",
      "Iteration 7960, Loss: 0.000000418\n",
      "Iteration 7970, Loss: 0.000000467\n",
      "Iteration 7980, Loss: 0.000001188\n",
      "Iteration 7990, Loss: 0.000000699\n",
      "Iteration 8000, Loss: 0.000000453\n",
      "Iteration 8010, Loss: 0.000000444\n",
      "Iteration 8020, Loss: 0.000000446\n",
      "Iteration 8030, Loss: 0.000000485\n",
      "Iteration 8040, Loss: 0.000001337\n",
      "Iteration 8050, Loss: 0.000000967\n",
      "Iteration 8060, Loss: 0.000000546\n",
      "Iteration 8070, Loss: 0.000000468\n",
      "Iteration 8080, Loss: 0.000000438\n",
      "Iteration 8090, Loss: 0.000000437\n",
      "Iteration 8100, Loss: 0.000000476\n",
      "Iteration 8110, Loss: 0.000000923\n",
      "Iteration 8120, Loss: 0.000000758\n",
      "Iteration 8130, Loss: 0.000000635\n",
      "Iteration 8140, Loss: 0.000000486\n",
      "Iteration 8150, Loss: 0.000000437\n",
      "Iteration 8160, Loss: 0.000000756\n",
      "Iteration 8170, Loss: 0.000000574\n",
      "Iteration 8180, Loss: 0.000000702\n",
      "Iteration 8190, Loss: 0.000000626\n",
      "Iteration 8200, Loss: 0.000000827\n",
      "Iteration 8210, Loss: 0.000000505\n",
      "Iteration 8220, Loss: 0.000000457\n",
      "Iteration 8230, Loss: 0.000000464\n",
      "Iteration 8240, Loss: 0.000000678\n",
      "Iteration 8250, Loss: 0.000001321\n",
      "Iteration 8260, Loss: 0.000000574\n",
      "Iteration 8270, Loss: 0.000000412\n",
      "Iteration 8280, Loss: 0.000000443\n",
      "Iteration 8290, Loss: 0.000000456\n",
      "Iteration 8300, Loss: 0.000001236\n",
      "Iteration 8310, Loss: 0.000000518\n",
      "Iteration 8320, Loss: 0.000000539\n",
      "Iteration 8330, Loss: 0.000000538\n",
      "Iteration 8340, Loss: 0.000000444\n",
      "Iteration 8350, Loss: 0.000000419\n",
      "Iteration 8360, Loss: 0.000000464\n",
      "Iteration 8370, Loss: 0.000000781\n",
      "Iteration 8380, Loss: 0.000000739\n",
      "Iteration 8390, Loss: 0.000001327\n",
      "Iteration 8400, Loss: 0.000000480\n",
      "Iteration 8410, Loss: 0.000000524\n",
      "Iteration 8420, Loss: 0.000000478\n",
      "Iteration 8430, Loss: 0.000000411\n",
      "Iteration 8440, Loss: 0.000000421\n",
      "Iteration 8450, Loss: 0.000000422\n",
      "Iteration 8460, Loss: 0.000000463\n",
      "Iteration 8470, Loss: 0.000001087\n",
      "Iteration 8480, Loss: 0.000000615\n",
      "Iteration 8490, Loss: 0.000000670\n",
      "Iteration 8500, Loss: 0.000000601\n",
      "Iteration 8510, Loss: 0.000000534\n",
      "Iteration 8520, Loss: 0.000000452\n",
      "Iteration 8530, Loss: 0.000000557\n",
      "Iteration 8540, Loss: 0.000000963\n",
      "Iteration 8550, Loss: 0.000000534\n",
      "Iteration 8560, Loss: 0.000000467\n",
      "Iteration 8570, Loss: 0.000000468\n",
      "Iteration 8580, Loss: 0.000000614\n",
      "Iteration 8590, Loss: 0.000001130\n",
      "Iteration 8600, Loss: 0.000000716\n",
      "Iteration 8610, Loss: 0.000000453\n",
      "Iteration 8620, Loss: 0.000000437\n",
      "Iteration 8630, Loss: 0.000000450\n",
      "Iteration 8640, Loss: 0.000000673\n",
      "Iteration 8650, Loss: 0.000001351\n",
      "Iteration 8660, Loss: 0.000000662\n",
      "Iteration 8670, Loss: 0.000000467\n",
      "Iteration 8680, Loss: 0.000000461\n",
      "Iteration 8690, Loss: 0.000000470\n",
      "Iteration 8700, Loss: 0.000000695\n",
      "Iteration 8710, Loss: 0.000000545\n",
      "Iteration 8720, Loss: 0.000000512\n",
      "Iteration 8730, Loss: 0.000000472\n",
      "Iteration 8740, Loss: 0.000002055\n",
      "Iteration 8750, Loss: 0.000000859\n",
      "Iteration 8760, Loss: 0.000000734\n",
      "Iteration 8770, Loss: 0.000000504\n",
      "Iteration 8780, Loss: 0.000000413\n",
      "Iteration 8790, Loss: 0.000000409\n",
      "Iteration 8800, Loss: 0.000000408\n",
      "Iteration 8810, Loss: 0.000000408\n",
      "Iteration 8820, Loss: 0.000000470\n",
      "Iteration 8830, Loss: 0.000001311\n",
      "Iteration 8840, Loss: 0.000000691\n",
      "Iteration 8850, Loss: 0.000000576\n",
      "Iteration 8860, Loss: 0.000000638\n",
      "Iteration 8870, Loss: 0.000000770\n",
      "Iteration 8880, Loss: 0.000000602\n",
      "Iteration 8890, Loss: 0.000000482\n",
      "Iteration 8900, Loss: 0.000000483\n",
      "Iteration 8910, Loss: 0.000000902\n",
      "Iteration 8920, Loss: 0.000000793\n",
      "Iteration 8930, Loss: 0.000000624\n",
      "Iteration 8940, Loss: 0.000000449\n",
      "Iteration 8950, Loss: 0.000000414\n",
      "Iteration 8960, Loss: 0.000000421\n",
      "Iteration 8970, Loss: 0.000000436\n",
      "Iteration 8980, Loss: 0.000000642\n",
      "Iteration 8990, Loss: 0.000001238\n",
      "Iteration 9000, Loss: 0.000000715\n",
      "Iteration 9010, Loss: 0.000000916\n",
      "Iteration 9020, Loss: 0.000000605\n",
      "Iteration 9030, Loss: 0.000000523\n",
      "Iteration 9040, Loss: 0.000000653\n",
      "Iteration 9050, Loss: 0.000000436\n",
      "Iteration 9060, Loss: 0.000000423\n",
      "Iteration 9070, Loss: 0.000000497\n",
      "Iteration 9080, Loss: 0.000001043\n",
      "Iteration 9090, Loss: 0.000000566\n",
      "Iteration 9100, Loss: 0.000000630\n",
      "Iteration 9110, Loss: 0.000000492\n",
      "Iteration 9120, Loss: 0.000000580\n",
      "Iteration 9130, Loss: 0.000001154\n",
      "Iteration 9140, Loss: 0.000000570\n",
      "Iteration 9150, Loss: 0.000000520\n",
      "Iteration 9160, Loss: 0.000000460\n",
      "Iteration 9170, Loss: 0.000000487\n",
      "Iteration 9180, Loss: 0.000000790\n",
      "Iteration 9190, Loss: 0.000001113\n",
      "Iteration 9200, Loss: 0.000000604\n",
      "Iteration 9210, Loss: 0.000000532\n",
      "Iteration 9220, Loss: 0.000000419\n",
      "Iteration 9230, Loss: 0.000000436\n",
      "Iteration 9240, Loss: 0.000000516\n",
      "Iteration 9250, Loss: 0.000001220\n",
      "Iteration 9260, Loss: 0.000000732\n",
      "Iteration 9270, Loss: 0.000000575\n",
      "Iteration 9280, Loss: 0.000000444\n",
      "Iteration 9290, Loss: 0.000000442\n",
      "Iteration 9300, Loss: 0.000000429\n",
      "Iteration 9310, Loss: 0.000000488\n",
      "Iteration 9320, Loss: 0.000001169\n",
      "Iteration 9330, Loss: 0.000001386\n",
      "Iteration 9340, Loss: 0.000000991\n",
      "Iteration 9350, Loss: 0.000000420\n",
      "Iteration 9360, Loss: 0.000000479\n",
      "Iteration 9370, Loss: 0.000000479\n",
      "Iteration 9380, Loss: 0.000000664\n",
      "Iteration 9390, Loss: 0.000001004\n",
      "Iteration 9400, Loss: 0.000000425\n",
      "Iteration 9410, Loss: 0.000000488\n",
      "Iteration 9420, Loss: 0.000000414\n",
      "Iteration 9430, Loss: 0.000000442\n",
      "Iteration 9440, Loss: 0.000000546\n",
      "Iteration 9450, Loss: 0.000001222\n",
      "Iteration 9460, Loss: 0.000000575\n",
      "Iteration 9470, Loss: 0.000000588\n",
      "Iteration 9480, Loss: 0.000000536\n",
      "Iteration 9490, Loss: 0.000000446\n",
      "Iteration 9500, Loss: 0.000000555\n",
      "Iteration 9510, Loss: 0.000000819\n",
      "Iteration 9520, Loss: 0.000000572\n",
      "Iteration 9530, Loss: 0.000000446\n",
      "Iteration 9540, Loss: 0.000000476\n",
      "Iteration 9550, Loss: 0.000000842\n",
      "Iteration 9560, Loss: 0.000001414\n",
      "Iteration 9570, Loss: 0.000000468\n",
      "Iteration 9580, Loss: 0.000000447\n",
      "Iteration 9590, Loss: 0.000000462\n",
      "Iteration 9600, Loss: 0.000000429\n",
      "Iteration 9610, Loss: 0.000000416\n",
      "Iteration 9620, Loss: 0.000000492\n",
      "Iteration 9630, Loss: 0.000001276\n",
      "Iteration 9640, Loss: 0.000000640\n",
      "Iteration 9650, Loss: 0.000000498\n",
      "Iteration 9660, Loss: 0.000000460\n",
      "Iteration 9670, Loss: 0.000000426\n",
      "Iteration 9680, Loss: 0.000000453\n",
      "Iteration 9690, Loss: 0.000000718\n",
      "Iteration 9700, Loss: 0.000000985\n",
      "Iteration 9710, Loss: 0.000000574\n",
      "Iteration 9720, Loss: 0.000000834\n",
      "Iteration 9730, Loss: 0.000000563\n",
      "Iteration 9740, Loss: 0.000000475\n",
      "Iteration 9750, Loss: 0.000000415\n",
      "Iteration 9760, Loss: 0.000000407\n",
      "Iteration 9770, Loss: 0.000000409\n",
      "Iteration 9780, Loss: 0.000000575\n",
      "Iteration 9790, Loss: 0.000003288\n",
      "Iteration 9800, Loss: 0.000000760\n",
      "Iteration 9810, Loss: 0.000000544\n",
      "Iteration 9820, Loss: 0.000000486\n",
      "Iteration 9830, Loss: 0.000000408\n",
      "Iteration 9840, Loss: 0.000000417\n",
      "Iteration 9850, Loss: 0.000000408\n",
      "Iteration 9860, Loss: 0.000000404\n",
      "Iteration 9870, Loss: 0.000000419\n",
      "Iteration 9880, Loss: 0.000000868\n",
      "Iteration 9890, Loss: 0.000001440\n",
      "Iteration 9900, Loss: 0.000000580\n",
      "Iteration 9910, Loss: 0.000000523\n",
      "Iteration 9920, Loss: 0.000000445\n",
      "Iteration 9930, Loss: 0.000000408\n",
      "Iteration 9940, Loss: 0.000000408\n",
      "Iteration 9950, Loss: 0.000000406\n",
      "Iteration 9960, Loss: 0.000000416\n",
      "Iteration 9970, Loss: 0.000001463\n",
      "Iteration 9980, Loss: 0.000000658\n",
      "Iteration 9990, Loss: 0.000001071\n",
      "Iteration 10000, Loss: 0.000000541\n",
      "Iteration 10010, Loss: 0.000000469\n",
      "Iteration 10020, Loss: 0.000000421\n",
      "Iteration 10030, Loss: 0.000000413\n",
      "Iteration 10040, Loss: 0.000000411\n",
      "Iteration 10050, Loss: 0.000000438\n",
      "Iteration 10060, Loss: 0.000000716\n",
      "Iteration 10070, Loss: 0.000000487\n",
      "Iteration 10080, Loss: 0.000000511\n",
      "Iteration 10090, Loss: 0.000000407\n",
      "Iteration 10100, Loss: 0.000000421\n",
      "Iteration 10110, Loss: 0.000000430\n",
      "Iteration 10120, Loss: 0.000000539\n",
      "Iteration 10130, Loss: 0.000001295\n",
      "Iteration 10140, Loss: 0.000000475\n",
      "Iteration 10150, Loss: 0.000000482\n",
      "Iteration 10160, Loss: 0.000000534\n",
      "Iteration 10170, Loss: 0.000000575\n",
      "Iteration 10180, Loss: 0.000000523\n",
      "Iteration 10190, Loss: 0.000000420\n",
      "Iteration 10200, Loss: 0.000000444\n",
      "Iteration 10210, Loss: 0.000000716\n",
      "Iteration 10220, Loss: 0.000000566\n",
      "Iteration 10230, Loss: 0.000002994\n",
      "Iteration 10240, Loss: 0.000001101\n",
      "Iteration 10250, Loss: 0.000000440\n",
      "Iteration 10260, Loss: 0.000000488\n",
      "Iteration 10270, Loss: 0.000000429\n",
      "Iteration 10280, Loss: 0.000000426\n",
      "Iteration 10290, Loss: 0.000000699\n",
      "Iteration 10300, Loss: 0.000000797\n",
      "Iteration 10310, Loss: 0.000000456\n",
      "Iteration 10320, Loss: 0.000000433\n",
      "Iteration 10330, Loss: 0.000000425\n",
      "Iteration 10340, Loss: 0.000000417\n",
      "Iteration 10350, Loss: 0.000000409\n",
      "Iteration 10360, Loss: 0.000000431\n",
      "Iteration 10370, Loss: 0.000000511\n",
      "Iteration 10380, Loss: 0.000000545\n",
      "Iteration 10390, Loss: 0.000002589\n",
      "Iteration 10400, Loss: 0.000001016\n",
      "Iteration 10410, Loss: 0.000000513\n",
      "Iteration 10420, Loss: 0.000000455\n",
      "Iteration 10430, Loss: 0.000000429\n",
      "Iteration 10440, Loss: 0.000000402\n",
      "Iteration 10450, Loss: 0.000000405\n",
      "Iteration 10460, Loss: 0.000000404\n",
      "Iteration 10470, Loss: 0.000000485\n",
      "Iteration 10480, Loss: 0.000002089\n",
      "Iteration 10490, Loss: 0.000000647\n",
      "Iteration 10500, Loss: 0.000000651\n",
      "Iteration 10510, Loss: 0.000000479\n",
      "Iteration 10520, Loss: 0.000000409\n",
      "Iteration 10530, Loss: 0.000000409\n",
      "Iteration 10540, Loss: 0.000000417\n",
      "Iteration 10550, Loss: 0.000001222\n",
      "Iteration 10560, Loss: 0.000000463\n",
      "Iteration 10570, Loss: 0.000001005\n",
      "Iteration 10580, Loss: 0.000000442\n",
      "Iteration 10590, Loss: 0.000000468\n",
      "Iteration 10600, Loss: 0.000000410\n",
      "Iteration 10610, Loss: 0.000000410\n",
      "Iteration 10620, Loss: 0.000000404\n",
      "Iteration 10630, Loss: 0.000000402\n",
      "Iteration 10640, Loss: 0.000000402\n",
      "Iteration 10650, Loss: 0.000000412\n",
      "Iteration 10660, Loss: 0.000000919\n",
      "Iteration 10670, Loss: 0.000000609\n",
      "Iteration 10680, Loss: 0.000000586\n",
      "Iteration 10690, Loss: 0.000000482\n",
      "Iteration 10700, Loss: 0.000000411\n",
      "Iteration 10710, Loss: 0.000000413\n",
      "Iteration 10720, Loss: 0.000000421\n",
      "Iteration 10730, Loss: 0.000000834\n",
      "Iteration 10740, Loss: 0.000001250\n",
      "Iteration 10750, Loss: 0.000000608\n",
      "Iteration 10760, Loss: 0.000000530\n",
      "Iteration 10770, Loss: 0.000000430\n",
      "Iteration 10780, Loss: 0.000000408\n",
      "Iteration 10790, Loss: 0.000000407\n",
      "Iteration 10800, Loss: 0.000000405\n",
      "Iteration 10810, Loss: 0.000000402\n",
      "Iteration 10820, Loss: 0.000000413\n",
      "Iteration 10830, Loss: 0.000000825\n",
      "Iteration 10840, Loss: 0.000001469\n",
      "Iteration 10850, Loss: 0.000000589\n",
      "Iteration 10860, Loss: 0.000000566\n",
      "Iteration 10870, Loss: 0.000000417\n",
      "Iteration 10880, Loss: 0.000000427\n",
      "Iteration 10890, Loss: 0.000000404\n",
      "Iteration 10900, Loss: 0.000000403\n",
      "Iteration 10910, Loss: 0.000000408\n",
      "Iteration 10920, Loss: 0.000000595\n",
      "Iteration 10930, Loss: 0.000002767\n",
      "Iteration 10940, Loss: 0.000000882\n",
      "Iteration 10950, Loss: 0.000000490\n",
      "Iteration 10960, Loss: 0.000000436\n",
      "Iteration 10970, Loss: 0.000000424\n",
      "Iteration 10980, Loss: 0.000000406\n",
      "Iteration 10990, Loss: 0.000000403\n",
      "Iteration 11000, Loss: 0.000000401\n",
      "Iteration 11010, Loss: 0.000000401\n",
      "Iteration 11020, Loss: 0.000000402\n",
      "Iteration 11030, Loss: 0.000000486\n",
      "Iteration 11040, Loss: 0.000001093\n",
      "Iteration 11050, Loss: 0.000000506\n",
      "Iteration 11060, Loss: 0.000001142\n",
      "Iteration 11070, Loss: 0.000000683\n",
      "Iteration 11080, Loss: 0.000000587\n",
      "Iteration 11090, Loss: 0.000000514\n",
      "Iteration 11100, Loss: 0.000000432\n",
      "Iteration 11110, Loss: 0.000000412\n",
      "Iteration 11120, Loss: 0.000000404\n",
      "Iteration 11130, Loss: 0.000000401\n",
      "Iteration 11140, Loss: 0.000000411\n",
      "Iteration 11150, Loss: 0.000000820\n",
      "Iteration 11160, Loss: 0.000000959\n",
      "Iteration 11170, Loss: 0.000000505\n",
      "Iteration 11180, Loss: 0.000000508\n",
      "Iteration 11190, Loss: 0.000000445\n",
      "Iteration 11200, Loss: 0.000000413\n",
      "Iteration 11210, Loss: 0.000000404\n",
      "Iteration 11220, Loss: 0.000000402\n",
      "Iteration 11230, Loss: 0.000000405\n",
      "Iteration 11240, Loss: 0.000000581\n",
      "Iteration 11250, Loss: 0.000003202\n",
      "Iteration 11260, Loss: 0.000000721\n",
      "Iteration 11270, Loss: 0.000000613\n",
      "Iteration 11280, Loss: 0.000000443\n",
      "Iteration 11290, Loss: 0.000000418\n",
      "Iteration 11300, Loss: 0.000000410\n",
      "Iteration 11310, Loss: 0.000000403\n",
      "Iteration 11320, Loss: 0.000000400\n",
      "Iteration 11330, Loss: 0.000000400\n",
      "Iteration 11340, Loss: 0.000000411\n",
      "Iteration 11350, Loss: 0.000001246\n",
      "Iteration 11360, Loss: 0.000000959\n",
      "Iteration 11370, Loss: 0.000000568\n",
      "Iteration 11380, Loss: 0.000000452\n",
      "Iteration 11390, Loss: 0.000000448\n",
      "Iteration 11400, Loss: 0.000000506\n",
      "Iteration 11410, Loss: 0.000001233\n",
      "Iteration 11420, Loss: 0.000000426\n",
      "Iteration 11430, Loss: 0.000000472\n",
      "Iteration 11440, Loss: 0.000000466\n",
      "Iteration 11450, Loss: 0.000000420\n",
      "Iteration 11460, Loss: 0.000000406\n",
      "Iteration 11470, Loss: 0.000000410\n",
      "Iteration 11480, Loss: 0.000000443\n",
      "Iteration 11490, Loss: 0.000000738\n",
      "Iteration 11500, Loss: 0.000001240\n",
      "Iteration 11510, Loss: 0.000000647\n",
      "Iteration 11520, Loss: 0.000000529\n",
      "Iteration 11530, Loss: 0.000000450\n",
      "Iteration 11540, Loss: 0.000000431\n",
      "Iteration 11550, Loss: 0.000000416\n",
      "Iteration 11560, Loss: 0.000000402\n",
      "Iteration 11570, Loss: 0.000000405\n",
      "Iteration 11580, Loss: 0.000000437\n",
      "Iteration 11590, Loss: 0.000001213\n",
      "Iteration 11600, Loss: 0.000000777\n",
      "Iteration 11610, Loss: 0.000000702\n",
      "Iteration 11620, Loss: 0.000000463\n",
      "Iteration 11630, Loss: 0.000000411\n",
      "Iteration 11640, Loss: 0.000000471\n",
      "Iteration 11650, Loss: 0.000001156\n",
      "Iteration 11660, Loss: 0.000000502\n",
      "Iteration 11670, Loss: 0.000000483\n",
      "Iteration 11680, Loss: 0.000000454\n",
      "Iteration 11690, Loss: 0.000000435\n",
      "Iteration 11700, Loss: 0.000000408\n",
      "Iteration 11710, Loss: 0.000000403\n",
      "Iteration 11720, Loss: 0.000000434\n",
      "Iteration 11730, Loss: 0.000001583\n",
      "Iteration 11740, Loss: 0.000001030\n",
      "Iteration 11750, Loss: 0.000000514\n",
      "Iteration 11760, Loss: 0.000000471\n",
      "Iteration 11770, Loss: 0.000000432\n",
      "Iteration 11780, Loss: 0.000000607\n",
      "Iteration 11790, Loss: 0.000001772\n",
      "Iteration 11800, Loss: 0.000000770\n",
      "Iteration 11810, Loss: 0.000000536\n",
      "Iteration 11820, Loss: 0.000000484\n",
      "Iteration 11830, Loss: 0.000000773\n",
      "Iteration 11840, Loss: 0.000000418\n",
      "Iteration 11850, Loss: 0.000000471\n",
      "Iteration 11860, Loss: 0.000000490\n",
      "Iteration 11870, Loss: 0.000000434\n",
      "Iteration 11880, Loss: 0.000000420\n",
      "Iteration 11890, Loss: 0.000000533\n",
      "Iteration 11900, Loss: 0.000002161\n",
      "Iteration 11910, Loss: 0.000000990\n",
      "Iteration 11920, Loss: 0.000000652\n",
      "Iteration 11930, Loss: 0.000000480\n",
      "Iteration 11940, Loss: 0.000000436\n",
      "Iteration 11950, Loss: 0.000000499\n",
      "Iteration 11960, Loss: 0.000001156\n",
      "Iteration 11970, Loss: 0.000000578\n",
      "Iteration 11980, Loss: 0.000000449\n",
      "Iteration 11990, Loss: 0.000000421\n",
      "Iteration 12000, Loss: 0.000000403\n",
      "Iteration 12010, Loss: 0.000000413\n",
      "Iteration 12020, Loss: 0.000000653\n",
      "Iteration 12030, Loss: 0.000001561\n",
      "Iteration 12040, Loss: 0.000000493\n",
      "Iteration 12050, Loss: 0.000000569\n",
      "Iteration 12060, Loss: 0.000000440\n",
      "Iteration 12070, Loss: 0.000000444\n",
      "Iteration 12080, Loss: 0.000000403\n",
      "Iteration 12090, Loss: 0.000000404\n",
      "Iteration 12100, Loss: 0.000000405\n",
      "Iteration 12110, Loss: 0.000000541\n",
      "Iteration 12120, Loss: 0.000001677\n",
      "Iteration 12130, Loss: 0.000000872\n",
      "Iteration 12140, Loss: 0.000000543\n",
      "Iteration 12150, Loss: 0.000000442\n",
      "Iteration 12160, Loss: 0.000000421\n",
      "Iteration 12170, Loss: 0.000000446\n",
      "Iteration 12180, Loss: 0.000001417\n",
      "Iteration 12190, Loss: 0.000000423\n",
      "Iteration 12200, Loss: 0.000000498\n",
      "Iteration 12210, Loss: 0.000000488\n",
      "Iteration 12220, Loss: 0.000000442\n",
      "Iteration 12230, Loss: 0.000000417\n",
      "Iteration 12240, Loss: 0.000000433\n",
      "Iteration 12250, Loss: 0.000001058\n",
      "Iteration 12260, Loss: 0.000000501\n",
      "Iteration 12270, Loss: 0.000000515\n",
      "Iteration 12280, Loss: 0.000000446\n",
      "Iteration 12290, Loss: 0.000000409\n",
      "Iteration 12300, Loss: 0.000000410\n",
      "Iteration 12310, Loss: 0.000000715\n",
      "Iteration 12320, Loss: 0.000001507\n",
      "Iteration 12330, Loss: 0.000000752\n",
      "Iteration 12340, Loss: 0.000000506\n",
      "Iteration 12350, Loss: 0.000000427\n",
      "Iteration 12360, Loss: 0.000000416\n",
      "Iteration 12370, Loss: 0.000000417\n",
      "Iteration 12380, Loss: 0.000000728\n",
      "Iteration 12390, Loss: 0.000000820\n",
      "Iteration 12400, Loss: 0.000000466\n",
      "Iteration 12410, Loss: 0.000000445\n",
      "Iteration 12420, Loss: 0.000000426\n",
      "Iteration 12430, Loss: 0.000000440\n",
      "Iteration 12440, Loss: 0.000001206\n",
      "Iteration 12450, Loss: 0.000000496\n",
      "Iteration 12460, Loss: 0.000000424\n",
      "Iteration 12470, Loss: 0.000000440\n",
      "Iteration 12480, Loss: 0.000000421\n",
      "Iteration 12490, Loss: 0.000000408\n",
      "Iteration 12500, Loss: 0.000000421\n",
      "Iteration 12510, Loss: 0.000000934\n",
      "Iteration 12520, Loss: 0.000000521\n",
      "Iteration 12530, Loss: 0.000000554\n",
      "Iteration 12540, Loss: 0.000000683\n",
      "Iteration 12550, Loss: 0.000000428\n",
      "Iteration 12560, Loss: 0.000000458\n",
      "Iteration 12570, Loss: 0.000000484\n",
      "Iteration 12580, Loss: 0.000001065\n",
      "Iteration 12590, Loss: 0.000000561\n",
      "Iteration 12600, Loss: 0.000000529\n",
      "Iteration 12610, Loss: 0.000000481\n",
      "Iteration 12620, Loss: 0.000000434\n",
      "Iteration 12630, Loss: 0.000000411\n",
      "Iteration 12640, Loss: 0.000000566\n",
      "Iteration 12650, Loss: 0.000001000\n",
      "Iteration 12660, Loss: 0.000000634\n",
      "Iteration 12670, Loss: 0.000000564\n",
      "Iteration 12680, Loss: 0.000000656\n",
      "Iteration 12690, Loss: 0.000000682\n",
      "Iteration 12700, Loss: 0.000000469\n",
      "Iteration 12710, Loss: 0.000000414\n",
      "Iteration 12720, Loss: 0.000000480\n",
      "Iteration 12730, Loss: 0.000001056\n",
      "Iteration 12740, Loss: 0.000000549\n",
      "Iteration 12750, Loss: 0.000000580\n",
      "Iteration 12760, Loss: 0.000000489\n",
      "Iteration 12770, Loss: 0.000000412\n",
      "Iteration 12780, Loss: 0.000000463\n",
      "Iteration 12790, Loss: 0.000001197\n",
      "Iteration 12800, Loss: 0.000000817\n",
      "Iteration 12810, Loss: 0.000000603\n",
      "Iteration 12820, Loss: 0.000000481\n",
      "Iteration 12830, Loss: 0.000000802\n",
      "Iteration 12840, Loss: 0.000000947\n",
      "Iteration 12850, Loss: 0.000000662\n",
      "Iteration 12860, Loss: 0.000000411\n",
      "Iteration 12870, Loss: 0.000000446\n",
      "Iteration 12880, Loss: 0.000000410\n",
      "Iteration 12890, Loss: 0.000000511\n",
      "Iteration 12900, Loss: 0.000001084\n",
      "Iteration 12910, Loss: 0.000000597\n",
      "Iteration 12920, Loss: 0.000000698\n",
      "Iteration 12930, Loss: 0.000001887\n",
      "Iteration 12940, Loss: 0.000000841\n",
      "Iteration 12950, Loss: 0.000000553\n",
      "Iteration 12960, Loss: 0.000000447\n",
      "Iteration 12970, Loss: 0.000000409\n",
      "Iteration 12980, Loss: 0.000000402\n",
      "Iteration 12990, Loss: 0.000000502\n",
      "Iteration 13000, Loss: 0.000001077\n",
      "Iteration 13010, Loss: 0.000000553\n",
      "Iteration 13020, Loss: 0.000000458\n",
      "Iteration 13030, Loss: 0.000000450\n",
      "Iteration 13040, Loss: 0.000001152\n",
      "Iteration 13050, Loss: 0.000000555\n",
      "Iteration 13060, Loss: 0.000000451\n",
      "Iteration 13070, Loss: 0.000000433\n",
      "Iteration 13080, Loss: 0.000000414\n",
      "Iteration 13090, Loss: 0.000000400\n",
      "Iteration 13100, Loss: 0.000000397\n",
      "Iteration 13110, Loss: 0.000000397\n",
      "Iteration 13120, Loss: 0.000000412\n",
      "Iteration 13130, Loss: 0.000001589\n",
      "Iteration 13140, Loss: 0.000001409\n",
      "Iteration 13150, Loss: 0.000000462\n",
      "Iteration 13160, Loss: 0.000000464\n",
      "Iteration 13170, Loss: 0.000000448\n",
      "Iteration 13180, Loss: 0.000000407\n",
      "Iteration 13190, Loss: 0.000000415\n",
      "Iteration 13200, Loss: 0.000000672\n",
      "Iteration 13210, Loss: 0.000002455\n",
      "Iteration 13220, Loss: 0.000000705\n",
      "Iteration 13230, Loss: 0.000000447\n",
      "Iteration 13240, Loss: 0.000000461\n",
      "Iteration 13250, Loss: 0.000000417\n",
      "Iteration 13260, Loss: 0.000000403\n",
      "Iteration 13270, Loss: 0.000000402\n",
      "Iteration 13280, Loss: 0.000000474\n",
      "Iteration 13290, Loss: 0.000001332\n",
      "Iteration 13300, Loss: 0.000000696\n",
      "Iteration 13310, Loss: 0.000000497\n",
      "Iteration 13320, Loss: 0.000000429\n",
      "Iteration 13330, Loss: 0.000000408\n",
      "Iteration 13340, Loss: 0.000000400\n",
      "Iteration 13350, Loss: 0.000000398\n",
      "Iteration 13360, Loss: 0.000000434\n",
      "Iteration 13370, Loss: 0.000002570\n",
      "Iteration 13380, Loss: 0.000001552\n",
      "Iteration 13390, Loss: 0.000000719\n",
      "Iteration 13400, Loss: 0.000000497\n",
      "Iteration 13410, Loss: 0.000000444\n",
      "Iteration 13420, Loss: 0.000000405\n",
      "Iteration 13430, Loss: 0.000000408\n",
      "Iteration 13440, Loss: 0.000000462\n",
      "Iteration 13450, Loss: 0.000001047\n",
      "Iteration 13460, Loss: 0.000000637\n",
      "Iteration 13470, Loss: 0.000000478\n",
      "Iteration 13480, Loss: 0.000000425\n",
      "Iteration 13490, Loss: 0.000000404\n",
      "Iteration 13500, Loss: 0.000000405\n",
      "Iteration 13510, Loss: 0.000000515\n",
      "Iteration 13520, Loss: 0.000001563\n",
      "Iteration 13530, Loss: 0.000000764\n",
      "Iteration 13540, Loss: 0.000000486\n",
      "Iteration 13550, Loss: 0.000000412\n",
      "Iteration 13560, Loss: 0.000000402\n",
      "Iteration 13570, Loss: 0.000000491\n",
      "Iteration 13580, Loss: 0.000003275\n",
      "Iteration 13590, Loss: 0.000001173\n",
      "Iteration 13600, Loss: 0.000000490\n",
      "Iteration 13610, Loss: 0.000000477\n",
      "Iteration 13620, Loss: 0.000000405\n",
      "Iteration 13630, Loss: 0.000000404\n",
      "Iteration 13640, Loss: 0.000000432\n",
      "Iteration 13650, Loss: 0.000000504\n",
      "Iteration 13660, Loss: 0.000000646\n",
      "Iteration 13670, Loss: 0.000000770\n",
      "Iteration 13680, Loss: 0.000000463\n",
      "Iteration 13690, Loss: 0.000000414\n",
      "Iteration 13700, Loss: 0.000000409\n",
      "Iteration 13710, Loss: 0.000000401\n",
      "Iteration 13720, Loss: 0.000000403\n",
      "Iteration 13730, Loss: 0.000000613\n",
      "Iteration 13740, Loss: 0.000001161\n",
      "Iteration 13750, Loss: 0.000001077\n",
      "Iteration 13760, Loss: 0.000000579\n",
      "Iteration 13770, Loss: 0.000000426\n",
      "Iteration 13780, Loss: 0.000000434\n",
      "Iteration 13790, Loss: 0.000000399\n",
      "Iteration 13800, Loss: 0.000000406\n",
      "Iteration 13810, Loss: 0.000000451\n",
      "Iteration 13820, Loss: 0.000001143\n",
      "Iteration 13830, Loss: 0.000000544\n",
      "Iteration 13840, Loss: 0.000000450\n",
      "Iteration 13850, Loss: 0.000000420\n",
      "Iteration 13860, Loss: 0.000000417\n",
      "Iteration 13870, Loss: 0.000000412\n",
      "Iteration 13880, Loss: 0.000000410\n",
      "Iteration 13890, Loss: 0.000001078\n",
      "Iteration 13900, Loss: 0.000000910\n",
      "Iteration 13910, Loss: 0.000000588\n",
      "Iteration 13920, Loss: 0.000000533\n",
      "Iteration 13930, Loss: 0.000000477\n",
      "Iteration 13940, Loss: 0.000000524\n",
      "Iteration 13950, Loss: 0.000000933\n",
      "Iteration 13960, Loss: 0.000000550\n",
      "Iteration 13970, Loss: 0.000000551\n",
      "Iteration 13980, Loss: 0.000000425\n",
      "Iteration 13990, Loss: 0.000000473\n",
      "Iteration 14000, Loss: 0.000001136\n",
      "Iteration 14010, Loss: 0.000000608\n",
      "Iteration 14020, Loss: 0.000000495\n",
      "Iteration 14030, Loss: 0.000000442\n",
      "Iteration 14040, Loss: 0.000000425\n",
      "Iteration 14050, Loss: 0.000000403\n",
      "Iteration 14060, Loss: 0.000000401\n",
      "Iteration 14070, Loss: 0.000000422\n",
      "Iteration 14080, Loss: 0.000001153\n",
      "Iteration 14090, Loss: 0.000000667\n",
      "Iteration 14100, Loss: 0.000000614\n",
      "Iteration 14110, Loss: 0.000000512\n",
      "Iteration 14120, Loss: 0.000000423\n",
      "Iteration 14130, Loss: 0.000000403\n",
      "Iteration 14140, Loss: 0.000000396\n",
      "Iteration 14150, Loss: 0.000000394\n",
      "Iteration 14160, Loss: 0.000000397\n",
      "Iteration 14170, Loss: 0.000000490\n",
      "Iteration 14180, Loss: 0.000003248\n",
      "Iteration 14190, Loss: 0.000001247\n",
      "Iteration 14200, Loss: 0.000000543\n",
      "Iteration 14210, Loss: 0.000000477\n",
      "Iteration 14220, Loss: 0.000000416\n",
      "Iteration 14230, Loss: 0.000000404\n",
      "Iteration 14240, Loss: 0.000000398\n",
      "Iteration 14250, Loss: 0.000000396\n",
      "Iteration 14260, Loss: 0.000000491\n",
      "Iteration 14270, Loss: 0.000001867\n",
      "Iteration 14280, Loss: 0.000000631\n",
      "Iteration 14290, Loss: 0.000000474\n",
      "Iteration 14300, Loss: 0.000000415\n",
      "Iteration 14310, Loss: 0.000000409\n",
      "Iteration 14320, Loss: 0.000000414\n",
      "Iteration 14330, Loss: 0.000000509\n",
      "Iteration 14340, Loss: 0.000001608\n",
      "Iteration 14350, Loss: 0.000000538\n",
      "Iteration 14360, Loss: 0.000000441\n",
      "Iteration 14370, Loss: 0.000000406\n",
      "Iteration 14380, Loss: 0.000000395\n",
      "Iteration 14390, Loss: 0.000000403\n",
      "Iteration 14400, Loss: 0.000000397\n",
      "Iteration 14410, Loss: 0.000000415\n",
      "Iteration 14420, Loss: 0.000000857\n",
      "Iteration 14430, Loss: 0.000000897\n",
      "Iteration 14440, Loss: 0.000000700\n",
      "Iteration 14450, Loss: 0.000000464\n",
      "Iteration 14460, Loss: 0.000000432\n",
      "Iteration 14470, Loss: 0.000000493\n",
      "Iteration 14480, Loss: 0.000000896\n",
      "Iteration 14490, Loss: 0.000000646\n",
      "Iteration 14500, Loss: 0.000000571\n",
      "Iteration 14510, Loss: 0.000000410\n",
      "Iteration 14520, Loss: 0.000000565\n",
      "Iteration 14530, Loss: 0.000000666\n",
      "Iteration 14540, Loss: 0.000000582\n",
      "Iteration 14550, Loss: 0.000000546\n",
      "Iteration 14560, Loss: 0.000001079\n",
      "Iteration 14570, Loss: 0.000000531\n",
      "Iteration 14580, Loss: 0.000000555\n",
      "Iteration 14590, Loss: 0.000000535\n",
      "Iteration 14600, Loss: 0.000000426\n",
      "Iteration 14610, Loss: 0.000000428\n",
      "Iteration 14620, Loss: 0.000000722\n",
      "Iteration 14630, Loss: 0.000000509\n",
      "Iteration 14640, Loss: 0.000000541\n",
      "Iteration 14650, Loss: 0.000000777\n",
      "Iteration 14660, Loss: 0.000000559\n",
      "Iteration 14670, Loss: 0.000000646\n",
      "Iteration 14680, Loss: 0.000000566\n",
      "Iteration 14690, Loss: 0.000000570\n",
      "Iteration 14700, Loss: 0.000000479\n",
      "Iteration 14710, Loss: 0.000000505\n",
      "Iteration 14720, Loss: 0.000000899\n",
      "Iteration 14730, Loss: 0.000000628\n",
      "Iteration 14740, Loss: 0.000000574\n",
      "Iteration 14750, Loss: 0.000000428\n",
      "Iteration 14760, Loss: 0.000000634\n",
      "Iteration 14770, Loss: 0.000001726\n",
      "Iteration 14780, Loss: 0.000000825\n",
      "Iteration 14790, Loss: 0.000000523\n",
      "Iteration 14800, Loss: 0.000000443\n",
      "Iteration 14810, Loss: 0.000000420\n",
      "Iteration 14820, Loss: 0.000000523\n",
      "Iteration 14830, Loss: 0.000000783\n",
      "Iteration 14840, Loss: 0.000000993\n",
      "Iteration 14850, Loss: 0.000000742\n",
      "Iteration 14860, Loss: 0.000000557\n",
      "Iteration 14870, Loss: 0.000000406\n",
      "Iteration 14880, Loss: 0.000000428\n",
      "Iteration 14890, Loss: 0.000000414\n",
      "Iteration 14900, Loss: 0.000000428\n",
      "Iteration 14910, Loss: 0.000000661\n",
      "Iteration 14920, Loss: 0.000000817\n",
      "Iteration 14930, Loss: 0.000001849\n",
      "Iteration 14940, Loss: 0.000000784\n",
      "Iteration 14950, Loss: 0.000000524\n",
      "Iteration 14960, Loss: 0.000000426\n",
      "Iteration 14970, Loss: 0.000000412\n",
      "Iteration 14980, Loss: 0.000000395\n",
      "Iteration 14990, Loss: 0.000000396\n",
      "Iteration 15000, Loss: 0.000000399\n",
      "Iteration 15010, Loss: 0.000000465\n",
      "Iteration 15020, Loss: 0.000001727\n",
      "Iteration 15030, Loss: 0.000000768\n",
      "Iteration 15040, Loss: 0.000000639\n",
      "Iteration 15050, Loss: 0.000000497\n",
      "Iteration 15060, Loss: 0.000000421\n",
      "Iteration 15070, Loss: 0.000000404\n",
      "Iteration 15080, Loss: 0.000000426\n",
      "Iteration 15090, Loss: 0.000000822\n",
      "Iteration 15100, Loss: 0.000001457\n",
      "Iteration 15110, Loss: 0.000000797\n",
      "Iteration 15120, Loss: 0.000000526\n",
      "Iteration 15130, Loss: 0.000000436\n",
      "Iteration 15140, Loss: 0.000000409\n",
      "Iteration 15150, Loss: 0.000000427\n",
      "Iteration 15160, Loss: 0.000000844\n",
      "Iteration 15170, Loss: 0.000000502\n",
      "Iteration 15180, Loss: 0.000000468\n",
      "Iteration 15190, Loss: 0.000000425\n",
      "Iteration 15200, Loss: 0.000000492\n",
      "Iteration 15210, Loss: 0.000001571\n",
      "Iteration 15220, Loss: 0.000000452\n",
      "Iteration 15230, Loss: 0.000000419\n",
      "Iteration 15240, Loss: 0.000000398\n",
      "Iteration 15250, Loss: 0.000000397\n",
      "Iteration 15260, Loss: 0.000000435\n",
      "Iteration 15270, Loss: 0.000001152\n",
      "Iteration 15280, Loss: 0.000000818\n",
      "Iteration 15290, Loss: 0.000000559\n",
      "Iteration 15300, Loss: 0.000000512\n",
      "Iteration 15310, Loss: 0.000000464\n",
      "Iteration 15320, Loss: 0.000000406\n",
      "Iteration 15330, Loss: 0.000000399\n",
      "Iteration 15340, Loss: 0.000000447\n",
      "Iteration 15350, Loss: 0.000001723\n",
      "Iteration 15360, Loss: 0.000000571\n",
      "Iteration 15370, Loss: 0.000000637\n",
      "Iteration 15380, Loss: 0.000000522\n",
      "Iteration 15390, Loss: 0.000000449\n",
      "Iteration 15400, Loss: 0.000000452\n",
      "Iteration 15410, Loss: 0.000000547\n",
      "Iteration 15420, Loss: 0.000000486\n",
      "Iteration 15430, Loss: 0.000000826\n",
      "Iteration 15440, Loss: 0.000000550\n",
      "Iteration 15450, Loss: 0.000000492\n",
      "Iteration 15460, Loss: 0.000000418\n",
      "Iteration 15470, Loss: 0.000000418\n",
      "Iteration 15480, Loss: 0.000000450\n",
      "Iteration 15490, Loss: 0.000001027\n",
      "Iteration 15500, Loss: 0.000000507\n",
      "Iteration 15510, Loss: 0.000001348\n",
      "Iteration 15520, Loss: 0.000000554\n",
      "Iteration 15530, Loss: 0.000000456\n",
      "Iteration 15540, Loss: 0.000000434\n",
      "Iteration 15550, Loss: 0.000000410\n",
      "Iteration 15560, Loss: 0.000000403\n",
      "Iteration 15570, Loss: 0.000000392\n",
      "Iteration 15580, Loss: 0.000000393\n",
      "Iteration 15590, Loss: 0.000000393\n",
      "Iteration 15600, Loss: 0.000000449\n",
      "Iteration 15610, Loss: 0.000001921\n",
      "Iteration 15620, Loss: 0.000001172\n",
      "Iteration 15630, Loss: 0.000000932\n",
      "Iteration 15640, Loss: 0.000000538\n",
      "Iteration 15650, Loss: 0.000000483\n",
      "Iteration 15660, Loss: 0.000000444\n",
      "Iteration 15670, Loss: 0.000000500\n",
      "Iteration 15680, Loss: 0.000000424\n",
      "Iteration 15690, Loss: 0.000000392\n",
      "Iteration 15700, Loss: 0.000000390\n",
      "Iteration 15710, Loss: 0.000000390\n",
      "Iteration 15720, Loss: 0.000000418\n",
      "Iteration 15730, Loss: 0.000003337\n",
      "Iteration 15740, Loss: 0.000002237\n",
      "Iteration 15750, Loss: 0.000000543\n",
      "Iteration 15760, Loss: 0.000000448\n",
      "Iteration 15770, Loss: 0.000000465\n",
      "Iteration 15780, Loss: 0.000000407\n",
      "Iteration 15790, Loss: 0.000000393\n",
      "Iteration 15800, Loss: 0.000000395\n",
      "Iteration 15810, Loss: 0.000000429\n",
      "Iteration 15820, Loss: 0.000001138\n",
      "Iteration 15830, Loss: 0.000000753\n",
      "Iteration 15840, Loss: 0.000000467\n",
      "Iteration 15850, Loss: 0.000000422\n",
      "Iteration 15860, Loss: 0.000000398\n",
      "Iteration 15870, Loss: 0.000000391\n",
      "Iteration 15880, Loss: 0.000000400\n",
      "Iteration 15890, Loss: 0.000000660\n",
      "Iteration 15900, Loss: 0.000000849\n",
      "Iteration 15910, Loss: 0.000000478\n",
      "Iteration 15920, Loss: 0.000000433\n",
      "Iteration 15930, Loss: 0.000000431\n",
      "Iteration 15940, Loss: 0.000000474\n",
      "Iteration 15950, Loss: 0.000000591\n",
      "Iteration 15960, Loss: 0.000000639\n",
      "Iteration 15970, Loss: 0.000000883\n",
      "Iteration 15980, Loss: 0.000000423\n",
      "Iteration 15990, Loss: 0.000000467\n",
      "Iteration 16000, Loss: 0.000000406\n",
      "Iteration 16010, Loss: 0.000000412\n",
      "Iteration 16020, Loss: 0.000000470\n",
      "Iteration 16030, Loss: 0.000000852\n",
      "Iteration 16040, Loss: 0.000000404\n",
      "Iteration 16050, Loss: 0.000000452\n",
      "Iteration 16060, Loss: 0.000000954\n",
      "Iteration 16070, Loss: 0.000000563\n",
      "Iteration 16080, Loss: 0.000001060\n",
      "Iteration 16090, Loss: 0.000000666\n",
      "Iteration 16100, Loss: 0.000000457\n",
      "Iteration 16110, Loss: 0.000000409\n",
      "Iteration 16120, Loss: 0.000000400\n",
      "Iteration 16130, Loss: 0.000000394\n",
      "Iteration 16140, Loss: 0.000000391\n",
      "Iteration 16150, Loss: 0.000000390\n",
      "Iteration 16160, Loss: 0.000000393\n",
      "Iteration 16170, Loss: 0.000000621\n",
      "Iteration 16180, Loss: 0.000000908\n",
      "Iteration 16190, Loss: 0.000000593\n",
      "Iteration 16200, Loss: 0.000000480\n",
      "Iteration 16210, Loss: 0.000000414\n",
      "Iteration 16220, Loss: 0.000000397\n",
      "Iteration 16230, Loss: 0.000000392\n",
      "Iteration 16240, Loss: 0.000000391\n",
      "Iteration 16250, Loss: 0.000000389\n",
      "Iteration 16260, Loss: 0.000000391\n",
      "Iteration 16270, Loss: 0.000000522\n",
      "Iteration 16280, Loss: 0.000001356\n",
      "Iteration 16290, Loss: 0.000000564\n",
      "Iteration 16300, Loss: 0.000000518\n",
      "Iteration 16310, Loss: 0.000000416\n",
      "Iteration 16320, Loss: 0.000000414\n",
      "Iteration 16330, Loss: 0.000000539\n",
      "Iteration 16340, Loss: 0.000002045\n",
      "Iteration 16350, Loss: 0.000000897\n",
      "Iteration 16360, Loss: 0.000000584\n",
      "Iteration 16370, Loss: 0.000000459\n",
      "Iteration 16380, Loss: 0.000000416\n",
      "Iteration 16390, Loss: 0.000000398\n",
      "Iteration 16400, Loss: 0.000000390\n",
      "Iteration 16410, Loss: 0.000000393\n",
      "Iteration 16420, Loss: 0.000000476\n",
      "Iteration 16430, Loss: 0.000001751\n",
      "Iteration 16440, Loss: 0.000000609\n",
      "Iteration 16450, Loss: 0.000000711\n",
      "Iteration 16460, Loss: 0.000000456\n",
      "Iteration 16470, Loss: 0.000000408\n",
      "Iteration 16480, Loss: 0.000000391\n",
      "Iteration 16490, Loss: 0.000000431\n",
      "Iteration 16500, Loss: 0.000001758\n",
      "Iteration 16510, Loss: 0.000000694\n",
      "Iteration 16520, Loss: 0.000000793\n",
      "Iteration 16530, Loss: 0.000000428\n",
      "Iteration 16540, Loss: 0.000000400\n",
      "Iteration 16550, Loss: 0.000000405\n",
      "Iteration 16560, Loss: 0.000000395\n",
      "Iteration 16570, Loss: 0.000000392\n",
      "Iteration 16580, Loss: 0.000000410\n",
      "Iteration 16590, Loss: 0.000000701\n",
      "Iteration 16600, Loss: 0.000001338\n",
      "Iteration 16610, Loss: 0.000000488\n",
      "Iteration 16620, Loss: 0.000000444\n",
      "Iteration 16630, Loss: 0.000000432\n",
      "Iteration 16640, Loss: 0.000000399\n",
      "Iteration 16650, Loss: 0.000000392\n",
      "Iteration 16660, Loss: 0.000000391\n",
      "Iteration 16670, Loss: 0.000000461\n",
      "Iteration 16680, Loss: 0.000003307\n",
      "Iteration 16690, Loss: 0.000001448\n",
      "Iteration 16700, Loss: 0.000000453\n",
      "Iteration 16710, Loss: 0.000000505\n",
      "Iteration 16720, Loss: 0.000000396\n",
      "Iteration 16730, Loss: 0.000000402\n",
      "Iteration 16740, Loss: 0.000000394\n",
      "Iteration 16750, Loss: 0.000000407\n",
      "Iteration 16760, Loss: 0.000000649\n",
      "Iteration 16770, Loss: 0.000001117\n",
      "Iteration 16780, Loss: 0.000000559\n",
      "Iteration 16790, Loss: 0.000000426\n",
      "Iteration 16800, Loss: 0.000000426\n",
      "Iteration 16810, Loss: 0.000000406\n",
      "Iteration 16820, Loss: 0.000000418\n",
      "Iteration 16830, Loss: 0.000000721\n",
      "Iteration 16840, Loss: 0.000000505\n",
      "Iteration 16850, Loss: 0.000000530\n",
      "Iteration 16860, Loss: 0.000001019\n",
      "Iteration 16870, Loss: 0.000000469\n",
      "Iteration 16880, Loss: 0.000000537\n",
      "Iteration 16890, Loss: 0.000000423\n",
      "Iteration 16900, Loss: 0.000000416\n",
      "Iteration 16910, Loss: 0.000000398\n",
      "Iteration 16920, Loss: 0.000000480\n",
      "Iteration 16930, Loss: 0.000001010\n",
      "Iteration 16940, Loss: 0.000001287\n",
      "Iteration 16950, Loss: 0.000000653\n",
      "Iteration 16960, Loss: 0.000000413\n",
      "Iteration 16970, Loss: 0.000000413\n",
      "Iteration 16980, Loss: 0.000000482\n",
      "Iteration 16990, Loss: 0.000001097\n",
      "Iteration 17000, Loss: 0.000000504\n",
      "Iteration 17010, Loss: 0.000000423\n",
      "Iteration 17020, Loss: 0.000000445\n",
      "Iteration 17030, Loss: 0.000001096\n",
      "Iteration 17040, Loss: 0.000000523\n",
      "Iteration 17050, Loss: 0.000000463\n",
      "Iteration 17060, Loss: 0.000000425\n",
      "Iteration 17070, Loss: 0.000000416\n",
      "Iteration 17080, Loss: 0.000000405\n",
      "Iteration 17090, Loss: 0.000000406\n",
      "Iteration 17100, Loss: 0.000000965\n",
      "Iteration 17110, Loss: 0.000000715\n",
      "Iteration 17120, Loss: 0.000000717\n",
      "Iteration 17130, Loss: 0.000000648\n",
      "Iteration 17140, Loss: 0.000000433\n",
      "Iteration 17150, Loss: 0.000000623\n",
      "Iteration 17160, Loss: 0.000001060\n",
      "Iteration 17170, Loss: 0.000000456\n",
      "Iteration 17180, Loss: 0.000000495\n",
      "Iteration 17190, Loss: 0.000000804\n",
      "Iteration 17200, Loss: 0.000000417\n",
      "Iteration 17210, Loss: 0.000000445\n",
      "Iteration 17220, Loss: 0.000000439\n",
      "Iteration 17230, Loss: 0.000000754\n",
      "Iteration 17240, Loss: 0.000001520\n",
      "Iteration 17250, Loss: 0.000000598\n",
      "Iteration 17260, Loss: 0.000000439\n",
      "Iteration 17270, Loss: 0.000000409\n",
      "Iteration 17280, Loss: 0.000000407\n",
      "Iteration 17290, Loss: 0.000000396\n",
      "Iteration 17300, Loss: 0.000000417\n",
      "Iteration 17310, Loss: 0.000000986\n",
      "Iteration 17320, Loss: 0.000000543\n",
      "Iteration 17330, Loss: 0.000000771\n",
      "Iteration 17340, Loss: 0.000000690\n",
      "Iteration 17350, Loss: 0.000000415\n",
      "Iteration 17360, Loss: 0.000000460\n",
      "Iteration 17370, Loss: 0.000000481\n",
      "Iteration 17380, Loss: 0.000000616\n",
      "Iteration 17390, Loss: 0.000000836\n",
      "Iteration 17400, Loss: 0.000000393\n",
      "Iteration 17410, Loss: 0.000000489\n",
      "Iteration 17420, Loss: 0.000000480\n",
      "Iteration 17430, Loss: 0.000000416\n",
      "Iteration 17440, Loss: 0.000000580\n",
      "Iteration 17450, Loss: 0.000001065\n",
      "Iteration 17460, Loss: 0.000001472\n",
      "Iteration 17470, Loss: 0.000000603\n",
      "Iteration 17480, Loss: 0.000000461\n",
      "Iteration 17490, Loss: 0.000000442\n",
      "Iteration 17500, Loss: 0.000000396\n",
      "Iteration 17510, Loss: 0.000000411\n",
      "Iteration 17520, Loss: 0.000000654\n",
      "Iteration 17530, Loss: 0.000000726\n",
      "Iteration 17540, Loss: 0.000000585\n",
      "Iteration 17550, Loss: 0.000000573\n",
      "Iteration 17560, Loss: 0.000000491\n",
      "Iteration 17570, Loss: 0.000000435\n",
      "Iteration 17580, Loss: 0.000000503\n",
      "Iteration 17590, Loss: 0.000001352\n",
      "Iteration 17600, Loss: 0.000000413\n",
      "Iteration 17610, Loss: 0.000000434\n",
      "Iteration 17620, Loss: 0.000000436\n",
      "Iteration 17630, Loss: 0.000000409\n",
      "Iteration 17640, Loss: 0.000000397\n",
      "Iteration 17650, Loss: 0.000000391\n",
      "Iteration 17660, Loss: 0.000000413\n",
      "Iteration 17670, Loss: 0.000001175\n",
      "Iteration 17680, Loss: 0.000001544\n",
      "Iteration 17690, Loss: 0.000000720\n",
      "Iteration 17700, Loss: 0.000000572\n",
      "Iteration 17710, Loss: 0.000000423\n",
      "Iteration 17720, Loss: 0.000000415\n",
      "Iteration 17730, Loss: 0.000000402\n",
      "Iteration 17740, Loss: 0.000000458\n",
      "Iteration 17750, Loss: 0.000001125\n",
      "Iteration 17760, Loss: 0.000000471\n",
      "Iteration 17770, Loss: 0.000000451\n",
      "Iteration 17780, Loss: 0.000000419\n",
      "Iteration 17790, Loss: 0.000000419\n",
      "Iteration 17800, Loss: 0.000000431\n",
      "Iteration 17810, Loss: 0.000000597\n",
      "Iteration 17820, Loss: 0.000000974\n",
      "Iteration 17830, Loss: 0.000001057\n",
      "Iteration 17840, Loss: 0.000000602\n",
      "Iteration 17850, Loss: 0.000000457\n",
      "Iteration 17860, Loss: 0.000000412\n",
      "Iteration 17870, Loss: 0.000000396\n",
      "Iteration 17880, Loss: 0.000000387\n",
      "Iteration 17890, Loss: 0.000000391\n",
      "Iteration 17900, Loss: 0.000000470\n",
      "Iteration 17910, Loss: 0.000002131\n",
      "Iteration 17920, Loss: 0.000000945\n",
      "Iteration 17930, Loss: 0.000000437\n",
      "Iteration 17940, Loss: 0.000000451\n",
      "Iteration 17950, Loss: 0.000000405\n",
      "Iteration 17960, Loss: 0.000000389\n",
      "Iteration 17970, Loss: 0.000000581\n",
      "Iteration 17980, Loss: 0.000000685\n",
      "Iteration 17990, Loss: 0.000002555\n",
      "Iteration 18000, Loss: 0.000001136\n",
      "Iteration 18010, Loss: 0.000000604\n",
      "Iteration 18020, Loss: 0.000000419\n",
      "Iteration 18030, Loss: 0.000000413\n",
      "Iteration 18040, Loss: 0.000000397\n",
      "Iteration 18050, Loss: 0.000000389\n",
      "Iteration 18060, Loss: 0.000000385\n",
      "Iteration 18070, Loss: 0.000000384\n",
      "Iteration 18080, Loss: 0.000000384\n",
      "Iteration 18090, Loss: 0.000000384\n",
      "Iteration 18100, Loss: 0.000000385\n",
      "Iteration 18110, Loss: 0.000000421\n",
      "Iteration 18120, Loss: 0.000002183\n",
      "Iteration 18130, Loss: 0.000001233\n",
      "Iteration 18140, Loss: 0.000000556\n",
      "Iteration 18150, Loss: 0.000000505\n",
      "Iteration 18160, Loss: 0.000000396\n",
      "Iteration 18170, Loss: 0.000000398\n",
      "Iteration 18180, Loss: 0.000000388\n",
      "Iteration 18190, Loss: 0.000000385\n",
      "Iteration 18200, Loss: 0.000000386\n",
      "Iteration 18210, Loss: 0.000000405\n",
      "Iteration 18220, Loss: 0.000000977\n",
      "Iteration 18230, Loss: 0.000001192\n",
      "Iteration 18240, Loss: 0.000000777\n",
      "Iteration 18250, Loss: 0.000000574\n",
      "Iteration 18260, Loss: 0.000000433\n",
      "Iteration 18270, Loss: 0.000000404\n",
      "Iteration 18280, Loss: 0.000000394\n",
      "Iteration 18290, Loss: 0.000000389\n",
      "Iteration 18300, Loss: 0.000000385\n",
      "Iteration 18310, Loss: 0.000000384\n",
      "Iteration 18320, Loss: 0.000000385\n",
      "Iteration 18330, Loss: 0.000000406\n",
      "Iteration 18340, Loss: 0.000001315\n",
      "Iteration 18350, Loss: 0.000000417\n",
      "Iteration 18360, Loss: 0.000000758\n",
      "Iteration 18370, Loss: 0.000000575\n",
      "Iteration 18380, Loss: 0.000000396\n",
      "Iteration 18390, Loss: 0.000000398\n",
      "Iteration 18400, Loss: 0.000000395\n",
      "Iteration 18410, Loss: 0.000000387\n",
      "Iteration 18420, Loss: 0.000000385\n",
      "Iteration 18430, Loss: 0.000000385\n",
      "Iteration 18440, Loss: 0.000000408\n",
      "Iteration 18450, Loss: 0.000000584\n",
      "Iteration 18460, Loss: 0.000000908\n",
      "Iteration 18470, Loss: 0.000000936\n",
      "Iteration 18480, Loss: 0.000000623\n",
      "Iteration 18490, Loss: 0.000000452\n",
      "Iteration 18500, Loss: 0.000000401\n",
      "Iteration 18510, Loss: 0.000000397\n",
      "Iteration 18520, Loss: 0.000000411\n",
      "Iteration 18530, Loss: 0.000001200\n",
      "Iteration 18540, Loss: 0.000000422\n",
      "Iteration 18550, Loss: 0.000000625\n",
      "Iteration 18560, Loss: 0.000000522\n",
      "Iteration 18570, Loss: 0.000000390\n",
      "Iteration 18580, Loss: 0.000000395\n",
      "Iteration 18590, Loss: 0.000000391\n",
      "Iteration 18600, Loss: 0.000000390\n",
      "Iteration 18610, Loss: 0.000000623\n",
      "Iteration 18620, Loss: 0.000001531\n",
      "Iteration 18630, Loss: 0.000000701\n",
      "Iteration 18640, Loss: 0.000000501\n",
      "Iteration 18650, Loss: 0.000000418\n",
      "Iteration 18660, Loss: 0.000000391\n",
      "Iteration 18670, Loss: 0.000000390\n",
      "Iteration 18680, Loss: 0.000000385\n",
      "Iteration 18690, Loss: 0.000000387\n",
      "Iteration 18700, Loss: 0.000000446\n",
      "Iteration 18710, Loss: 0.000001183\n",
      "Iteration 18720, Loss: 0.000001197\n",
      "Iteration 18730, Loss: 0.000000729\n",
      "Iteration 18740, Loss: 0.000000598\n",
      "Iteration 18750, Loss: 0.000000470\n",
      "Iteration 18760, Loss: 0.000000393\n",
      "Iteration 18770, Loss: 0.000000397\n",
      "Iteration 18780, Loss: 0.000000386\n",
      "Iteration 18790, Loss: 0.000000424\n",
      "Iteration 18800, Loss: 0.000001311\n",
      "Iteration 18810, Loss: 0.000000629\n",
      "Iteration 18820, Loss: 0.000000585\n",
      "Iteration 18830, Loss: 0.000002209\n",
      "Iteration 18840, Loss: 0.000000970\n",
      "Iteration 18850, Loss: 0.000000709\n",
      "Iteration 18860, Loss: 0.000000477\n",
      "Iteration 18870, Loss: 0.000000404\n",
      "Iteration 18880, Loss: 0.000000389\n",
      "Iteration 18890, Loss: 0.000000385\n",
      "Iteration 18900, Loss: 0.000000384\n",
      "Iteration 18910, Loss: 0.000000383\n",
      "Iteration 18920, Loss: 0.000000382\n",
      "Iteration 18930, Loss: 0.000000382\n",
      "Iteration 18940, Loss: 0.000000383\n",
      "Iteration 18950, Loss: 0.000000437\n",
      "Iteration 18960, Loss: 0.000002341\n",
      "Iteration 18970, Loss: 0.000001267\n",
      "Iteration 18980, Loss: 0.000000685\n",
      "Iteration 18990, Loss: 0.000000513\n",
      "Iteration 19000, Loss: 0.000000415\n",
      "Iteration 19010, Loss: 0.000000403\n",
      "Iteration 19020, Loss: 0.000000386\n",
      "Iteration 19030, Loss: 0.000000384\n",
      "Iteration 19040, Loss: 0.000000409\n",
      "Iteration 19050, Loss: 0.000001377\n",
      "Iteration 19060, Loss: 0.000000454\n",
      "Iteration 19070, Loss: 0.000000750\n",
      "Iteration 19080, Loss: 0.000000509\n",
      "Iteration 19090, Loss: 0.000000386\n",
      "Iteration 19100, Loss: 0.000000393\n",
      "Iteration 19110, Loss: 0.000000390\n",
      "Iteration 19120, Loss: 0.000000385\n",
      "Iteration 19130, Loss: 0.000000384\n",
      "Iteration 19140, Loss: 0.000000397\n",
      "Iteration 19150, Loss: 0.000001266\n",
      "Iteration 19160, Loss: 0.000001552\n",
      "Iteration 19170, Loss: 0.000000708\n",
      "Iteration 19180, Loss: 0.000000508\n",
      "Iteration 19190, Loss: 0.000000429\n",
      "Iteration 19200, Loss: 0.000000399\n",
      "Iteration 19210, Loss: 0.000000388\n",
      "Iteration 19220, Loss: 0.000000383\n",
      "Iteration 19230, Loss: 0.000000382\n",
      "Iteration 19240, Loss: 0.000000382\n",
      "Iteration 19250, Loss: 0.000000382\n",
      "Iteration 19260, Loss: 0.000000382\n",
      "Iteration 19270, Loss: 0.000000405\n",
      "Iteration 19280, Loss: 0.000002324\n",
      "Iteration 19290, Loss: 0.000001643\n",
      "Iteration 19300, Loss: 0.000000541\n",
      "Iteration 19310, Loss: 0.000000565\n",
      "Iteration 19320, Loss: 0.000000392\n",
      "Iteration 19330, Loss: 0.000000405\n",
      "Iteration 19340, Loss: 0.000000383\n",
      "Iteration 19350, Loss: 0.000000385\n",
      "Iteration 19360, Loss: 0.000000382\n",
      "Iteration 19370, Loss: 0.000000383\n",
      "Iteration 19380, Loss: 0.000000466\n",
      "Iteration 19390, Loss: 0.000000622\n",
      "Iteration 19400, Loss: 0.000000510\n",
      "Iteration 19410, Loss: 0.000000402\n",
      "Iteration 19420, Loss: 0.000000414\n",
      "Iteration 19430, Loss: 0.000000396\n",
      "Iteration 19440, Loss: 0.000000403\n",
      "Iteration 19450, Loss: 0.000000566\n",
      "Iteration 19460, Loss: 0.000000847\n",
      "Iteration 19470, Loss: 0.000000560\n",
      "Iteration 19480, Loss: 0.000001551\n",
      "Iteration 19490, Loss: 0.000000537\n",
      "Iteration 19500, Loss: 0.000000498\n",
      "Iteration 19510, Loss: 0.000000461\n",
      "Iteration 19520, Loss: 0.000000418\n",
      "Iteration 19530, Loss: 0.000000395\n",
      "Iteration 19540, Loss: 0.000000384\n",
      "Iteration 19550, Loss: 0.000000386\n",
      "Iteration 19560, Loss: 0.000000493\n",
      "Iteration 19570, Loss: 0.000001176\n",
      "Iteration 19580, Loss: 0.000000672\n",
      "Iteration 19590, Loss: 0.000000586\n",
      "Iteration 19600, Loss: 0.000000664\n",
      "Iteration 19610, Loss: 0.000000498\n",
      "Iteration 19620, Loss: 0.000000406\n",
      "Iteration 19630, Loss: 0.000000533\n",
      "Iteration 19640, Loss: 0.000000664\n",
      "Iteration 19650, Loss: 0.000001043\n",
      "Iteration 19660, Loss: 0.000000756\n",
      "Iteration 19670, Loss: 0.000000574\n",
      "Iteration 19680, Loss: 0.000000439\n",
      "Iteration 19690, Loss: 0.000000392\n",
      "Iteration 19700, Loss: 0.000000394\n",
      "Iteration 19710, Loss: 0.000000419\n",
      "Iteration 19720, Loss: 0.000000708\n",
      "Iteration 19730, Loss: 0.000000914\n",
      "Iteration 19740, Loss: 0.000000907\n",
      "Iteration 19750, Loss: 0.000000637\n",
      "Iteration 19760, Loss: 0.000000421\n",
      "Iteration 19770, Loss: 0.000000475\n",
      "Iteration 19780, Loss: 0.000000487\n",
      "Iteration 19790, Loss: 0.000000542\n",
      "Iteration 19800, Loss: 0.000000758\n",
      "Iteration 19810, Loss: 0.000000481\n",
      "Iteration 19820, Loss: 0.000000674\n",
      "Iteration 19830, Loss: 0.000001005\n",
      "Iteration 19840, Loss: 0.000000395\n",
      "Iteration 19850, Loss: 0.000000463\n",
      "Iteration 19860, Loss: 0.000000400\n",
      "Iteration 19870, Loss: 0.000000415\n",
      "Iteration 19880, Loss: 0.000000844\n",
      "Iteration 19890, Loss: 0.000000607\n",
      "Iteration 19900, Loss: 0.000001446\n",
      "Iteration 19910, Loss: 0.000000519\n",
      "Iteration 19920, Loss: 0.000000423\n",
      "Iteration 19930, Loss: 0.000000419\n",
      "Iteration 19940, Loss: 0.000000413\n",
      "Iteration 19950, Loss: 0.000000385\n",
      "Iteration 19960, Loss: 0.000000386\n",
      "Iteration 19970, Loss: 0.000000386\n",
      "Iteration 19980, Loss: 0.000000479\n",
      "Iteration 19990, Loss: 0.000002361\n",
      "Iteration 20000, Loss: 0.000000496\n",
      "Iteration 20010, Loss: 0.000000608\n",
      "Iteration 20020, Loss: 0.000000510\n",
      "Iteration 20030, Loss: 0.000000572\n",
      "Iteration 20040, Loss: 0.000000500\n",
      "Iteration 20050, Loss: 0.000000383\n",
      "Iteration 20060, Loss: 0.000000417\n",
      "Iteration 20070, Loss: 0.000000519\n",
      "Iteration 20080, Loss: 0.000000949\n",
      "Iteration 20090, Loss: 0.000000660\n",
      "Iteration 20100, Loss: 0.000000482\n",
      "Iteration 20110, Loss: 0.000000474\n",
      "Iteration 20120, Loss: 0.000000434\n",
      "Iteration 20130, Loss: 0.000000665\n",
      "Iteration 20140, Loss: 0.000001137\n",
      "Iteration 20150, Loss: 0.000000432\n",
      "Iteration 20160, Loss: 0.000000451\n",
      "Iteration 20170, Loss: 0.000000404\n",
      "Iteration 20180, Loss: 0.000000392\n",
      "Iteration 20190, Loss: 0.000000415\n",
      "Iteration 20200, Loss: 0.000000588\n",
      "Iteration 20210, Loss: 0.000001654\n",
      "Iteration 20220, Loss: 0.000001092\n",
      "Iteration 20230, Loss: 0.000000572\n",
      "Iteration 20240, Loss: 0.000000475\n",
      "Iteration 20250, Loss: 0.000000415\n",
      "Iteration 20260, Loss: 0.000000388\n",
      "Iteration 20270, Loss: 0.000000387\n",
      "Iteration 20280, Loss: 0.000000425\n",
      "Iteration 20290, Loss: 0.000000434\n",
      "Iteration 20300, Loss: 0.000000407\n",
      "Iteration 20310, Loss: 0.000000872\n",
      "Iteration 20320, Loss: 0.000001255\n",
      "Iteration 20330, Loss: 0.000000747\n",
      "Iteration 20340, Loss: 0.000000424\n",
      "Iteration 20350, Loss: 0.000000434\n",
      "Iteration 20360, Loss: 0.000000393\n",
      "Iteration 20370, Loss: 0.000000386\n",
      "Iteration 20380, Loss: 0.000000385\n",
      "Iteration 20390, Loss: 0.000000398\n",
      "Iteration 20400, Loss: 0.000000537\n",
      "Iteration 20410, Loss: 0.000001797\n",
      "Iteration 20420, Loss: 0.000000697\n",
      "Iteration 20430, Loss: 0.000000833\n",
      "Iteration 20440, Loss: 0.000000465\n",
      "Iteration 20450, Loss: 0.000000386\n",
      "Iteration 20460, Loss: 0.000000395\n",
      "Iteration 20470, Loss: 0.000000387\n",
      "Iteration 20480, Loss: 0.000000383\n",
      "Iteration 20490, Loss: 0.000000402\n",
      "Iteration 20500, Loss: 0.000001066\n",
      "Iteration 20510, Loss: 0.000000559\n",
      "Iteration 20520, Loss: 0.000000543\n",
      "Iteration 20530, Loss: 0.000000397\n",
      "Iteration 20540, Loss: 0.000000393\n",
      "Iteration 20550, Loss: 0.000000386\n",
      "Iteration 20560, Loss: 0.000000391\n",
      "Iteration 20570, Loss: 0.000000664\n",
      "Iteration 20580, Loss: 0.000001813\n",
      "Iteration 20590, Loss: 0.000000726\n",
      "Iteration 20600, Loss: 0.000000441\n",
      "Iteration 20610, Loss: 0.000000399\n",
      "Iteration 20620, Loss: 0.000000411\n",
      "Iteration 20630, Loss: 0.000000600\n",
      "Iteration 20640, Loss: 0.000000777\n",
      "Iteration 20650, Loss: 0.000000513\n",
      "Iteration 20660, Loss: 0.000000443\n",
      "Iteration 20670, Loss: 0.000000484\n",
      "Iteration 20680, Loss: 0.000000437\n",
      "Iteration 20690, Loss: 0.000000406\n",
      "Iteration 20700, Loss: 0.000000491\n",
      "Iteration 20710, Loss: 0.000001291\n",
      "Iteration 20720, Loss: 0.000000465\n",
      "Iteration 20730, Loss: 0.000000458\n",
      "Iteration 20740, Loss: 0.000000457\n",
      "Iteration 20750, Loss: 0.000000495\n",
      "Iteration 20760, Loss: 0.000000671\n",
      "Iteration 20770, Loss: 0.000000486\n",
      "Iteration 20780, Loss: 0.000000548\n",
      "Iteration 20790, Loss: 0.000000800\n",
      "Iteration 20800, Loss: 0.000000556\n",
      "Iteration 20810, Loss: 0.000000512\n",
      "Iteration 20820, Loss: 0.000000792\n",
      "Iteration 20830, Loss: 0.000000541\n",
      "Iteration 20840, Loss: 0.000000926\n",
      "Iteration 20850, Loss: 0.000000564\n",
      "Iteration 20860, Loss: 0.000000522\n",
      "Iteration 20870, Loss: 0.000000400\n",
      "Iteration 20880, Loss: 0.000000401\n",
      "Iteration 20890, Loss: 0.000000465\n",
      "Iteration 20900, Loss: 0.000000829\n",
      "Iteration 20910, Loss: 0.000000656\n",
      "Iteration 20920, Loss: 0.000000695\n",
      "Iteration 20930, Loss: 0.000000936\n",
      "Iteration 20940, Loss: 0.000000524\n",
      "Iteration 20950, Loss: 0.000000443\n",
      "Iteration 20960, Loss: 0.000000400\n",
      "Iteration 20970, Loss: 0.000000433\n",
      "Iteration 20980, Loss: 0.000002265\n",
      "Iteration 20990, Loss: 0.000001092\n",
      "Iteration 21000, Loss: 0.000000605\n",
      "Iteration 21010, Loss: 0.000000466\n",
      "Iteration 21020, Loss: 0.000000396\n",
      "Iteration 21030, Loss: 0.000000386\n",
      "Iteration 21040, Loss: 0.000000381\n",
      "Iteration 21050, Loss: 0.000000380\n",
      "Iteration 21060, Loss: 0.000000384\n",
      "Iteration 21070, Loss: 0.000000544\n",
      "Iteration 21080, Loss: 0.000000988\n",
      "Iteration 21090, Loss: 0.000000630\n",
      "Iteration 21100, Loss: 0.000000479\n",
      "Iteration 21110, Loss: 0.000000428\n",
      "Iteration 21120, Loss: 0.000000438\n",
      "Iteration 21130, Loss: 0.000000619\n",
      "Iteration 21140, Loss: 0.000001011\n",
      "Iteration 21150, Loss: 0.000000414\n",
      "Iteration 21160, Loss: 0.000000449\n",
      "Iteration 21170, Loss: 0.000000402\n",
      "Iteration 21180, Loss: 0.000000457\n",
      "Iteration 21190, Loss: 0.000000971\n",
      "Iteration 21200, Loss: 0.000000527\n",
      "Iteration 21210, Loss: 0.000001049\n",
      "Iteration 21220, Loss: 0.000000395\n",
      "Iteration 21230, Loss: 0.000000474\n",
      "Iteration 21240, Loss: 0.000000403\n",
      "Iteration 21250, Loss: 0.000000401\n",
      "Iteration 21260, Loss: 0.000000387\n",
      "Iteration 21270, Loss: 0.000000399\n",
      "Iteration 21280, Loss: 0.000000692\n",
      "Iteration 21290, Loss: 0.000001720\n",
      "Iteration 21300, Loss: 0.000000578\n",
      "Iteration 21310, Loss: 0.000000582\n",
      "Iteration 21320, Loss: 0.000000397\n",
      "Iteration 21330, Loss: 0.000000405\n",
      "Iteration 21340, Loss: 0.000000381\n",
      "Iteration 21350, Loss: 0.000000394\n",
      "Iteration 21360, Loss: 0.000000873\n",
      "Iteration 21370, Loss: 0.000000610\n",
      "Iteration 21380, Loss: 0.000000601\n",
      "Iteration 21390, Loss: 0.000000466\n",
      "Iteration 21400, Loss: 0.000000424\n",
      "Iteration 21410, Loss: 0.000000549\n",
      "Iteration 21420, Loss: 0.000001064\n",
      "Iteration 21430, Loss: 0.000000383\n",
      "Iteration 21440, Loss: 0.000000486\n",
      "Iteration 21450, Loss: 0.000000392\n",
      "Iteration 21460, Loss: 0.000000407\n",
      "Iteration 21470, Loss: 0.000000450\n",
      "Iteration 21480, Loss: 0.000000863\n",
      "Iteration 21490, Loss: 0.000000781\n",
      "Iteration 21500, Loss: 0.000000623\n",
      "Iteration 21510, Loss: 0.000000430\n",
      "Iteration 21520, Loss: 0.000000409\n",
      "Iteration 21530, Loss: 0.000000592\n",
      "Iteration 21540, Loss: 0.000000652\n",
      "Iteration 21550, Loss: 0.000000673\n",
      "Iteration 21560, Loss: 0.000000451\n",
      "Iteration 21570, Loss: 0.000000386\n",
      "Iteration 21580, Loss: 0.000000397\n",
      "Iteration 21590, Loss: 0.000000808\n",
      "Iteration 21600, Loss: 0.000001213\n",
      "Iteration 21610, Loss: 0.000000413\n",
      "Iteration 21620, Loss: 0.000000594\n",
      "Iteration 21630, Loss: 0.000000433\n",
      "Iteration 21640, Loss: 0.000000426\n",
      "Iteration 21650, Loss: 0.000000558\n",
      "Iteration 21660, Loss: 0.000001258\n",
      "Iteration 21670, Loss: 0.000000455\n",
      "Iteration 21680, Loss: 0.000000397\n",
      "Iteration 21690, Loss: 0.000000443\n",
      "Iteration 21700, Loss: 0.000000433\n",
      "Iteration 21710, Loss: 0.000000678\n",
      "Iteration 21720, Loss: 0.000000487\n",
      "Iteration 21730, Loss: 0.000000415\n",
      "Iteration 21740, Loss: 0.000000400\n",
      "Iteration 21750, Loss: 0.000000391\n",
      "Iteration 21760, Loss: 0.000000810\n",
      "Iteration 21770, Loss: 0.000001458\n",
      "Iteration 21780, Loss: 0.000000522\n",
      "Iteration 21790, Loss: 0.000000718\n",
      "Iteration 21800, Loss: 0.000000412\n",
      "Iteration 21810, Loss: 0.000000409\n",
      "Iteration 21820, Loss: 0.000000392\n",
      "Iteration 21830, Loss: 0.000000399\n",
      "Iteration 21840, Loss: 0.000000607\n",
      "Iteration 21850, Loss: 0.000000490\n",
      "Iteration 21860, Loss: 0.000000420\n",
      "Iteration 21870, Loss: 0.000000421\n",
      "Iteration 21880, Loss: 0.000000549\n",
      "Iteration 21890, Loss: 0.000000891\n",
      "Iteration 21900, Loss: 0.000000584\n",
      "Iteration 21910, Loss: 0.000000431\n",
      "Iteration 21920, Loss: 0.000000400\n",
      "Iteration 21930, Loss: 0.000000400\n",
      "Iteration 21940, Loss: 0.000000391\n",
      "Iteration 21950, Loss: 0.000000419\n",
      "Iteration 21960, Loss: 0.000000756\n",
      "Iteration 21970, Loss: 0.000001009\n",
      "Iteration 21980, Loss: 0.000000973\n",
      "Iteration 21990, Loss: 0.000000477\n",
      "Iteration 22000, Loss: 0.000000499\n",
      "Iteration 22010, Loss: 0.000000440\n",
      "Iteration 22020, Loss: 0.000000392\n",
      "Iteration 22030, Loss: 0.000000381\n",
      "Iteration 22040, Loss: 0.000000378\n",
      "Iteration 22050, Loss: 0.000000384\n",
      "Iteration 22060, Loss: 0.000001315\n",
      "Iteration 22070, Loss: 0.000001383\n",
      "Iteration 22080, Loss: 0.000000538\n",
      "Iteration 22090, Loss: 0.000000439\n",
      "Iteration 22100, Loss: 0.000000413\n",
      "Iteration 22110, Loss: 0.000000387\n",
      "Iteration 22120, Loss: 0.000000376\n",
      "Iteration 22130, Loss: 0.000000379\n",
      "Iteration 22140, Loss: 0.000000398\n",
      "Iteration 22150, Loss: 0.000000961\n",
      "Iteration 22160, Loss: 0.000000706\n",
      "Iteration 22170, Loss: 0.000000384\n",
      "Iteration 22180, Loss: 0.000000460\n",
      "Iteration 22190, Loss: 0.000000440\n",
      "Iteration 22200, Loss: 0.000000445\n",
      "Iteration 22210, Loss: 0.000000430\n",
      "Iteration 22220, Loss: 0.000000407\n",
      "Iteration 22230, Loss: 0.000000426\n",
      "Iteration 22240, Loss: 0.000000699\n",
      "Iteration 22250, Loss: 0.000000414\n",
      "Iteration 22260, Loss: 0.000000434\n",
      "Iteration 22270, Loss: 0.000000406\n",
      "Iteration 22280, Loss: 0.000000379\n",
      "Iteration 22290, Loss: 0.000000452\n",
      "Iteration 22300, Loss: 0.000002856\n",
      "Iteration 22310, Loss: 0.000001529\n",
      "Iteration 22320, Loss: 0.000000470\n",
      "Iteration 22330, Loss: 0.000000474\n",
      "Iteration 22340, Loss: 0.000000422\n",
      "Iteration 22350, Loss: 0.000000391\n",
      "Iteration 22360, Loss: 0.000000502\n",
      "Iteration 22370, Loss: 0.000000835\n",
      "Iteration 22380, Loss: 0.000000517\n",
      "Iteration 22390, Loss: 0.000000432\n",
      "Iteration 22400, Loss: 0.000000390\n",
      "Iteration 22410, Loss: 0.000000392\n",
      "Iteration 22420, Loss: 0.000000592\n",
      "Iteration 22430, Loss: 0.000000511\n",
      "Iteration 22440, Loss: 0.000000721\n",
      "Iteration 22450, Loss: 0.000000462\n",
      "Iteration 22460, Loss: 0.000000475\n",
      "Iteration 22470, Loss: 0.000000506\n",
      "Iteration 22480, Loss: 0.000001136\n",
      "Iteration 22490, Loss: 0.000000423\n",
      "Iteration 22500, Loss: 0.000000572\n",
      "Iteration 22510, Loss: 0.000000471\n",
      "Iteration 22520, Loss: 0.000000392\n",
      "Iteration 22530, Loss: 0.000000395\n",
      "Iteration 22540, Loss: 0.000000397\n",
      "Iteration 22550, Loss: 0.000000823\n",
      "Iteration 22560, Loss: 0.000000633\n",
      "Iteration 22570, Loss: 0.000001026\n",
      "Iteration 22580, Loss: 0.000000509\n",
      "Iteration 22590, Loss: 0.000000459\n",
      "Iteration 22600, Loss: 0.000000398\n",
      "Iteration 22610, Loss: 0.000000404\n",
      "Iteration 22620, Loss: 0.000000414\n",
      "Iteration 22630, Loss: 0.000000608\n",
      "Iteration 22640, Loss: 0.000001429\n",
      "Iteration 22650, Loss: 0.000000772\n",
      "Iteration 22660, Loss: 0.000000484\n",
      "Iteration 22670, Loss: 0.000000406\n",
      "Iteration 22680, Loss: 0.000000387\n",
      "Iteration 22690, Loss: 0.000000400\n",
      "Iteration 22700, Loss: 0.000000773\n",
      "Iteration 22710, Loss: 0.000001263\n",
      "Iteration 22720, Loss: 0.000000584\n",
      "Iteration 22730, Loss: 0.000000424\n",
      "Iteration 22740, Loss: 0.000000404\n",
      "Iteration 22750, Loss: 0.000000389\n",
      "Iteration 22760, Loss: 0.000000380\n",
      "Iteration 22770, Loss: 0.000000379\n",
      "Iteration 22780, Loss: 0.000000442\n",
      "Iteration 22790, Loss: 0.000001093\n",
      "Iteration 22800, Loss: 0.000000706\n",
      "Iteration 22810, Loss: 0.000001801\n",
      "Iteration 22820, Loss: 0.000000919\n",
      "Iteration 22830, Loss: 0.000000635\n",
      "Iteration 22840, Loss: 0.000000467\n",
      "Iteration 22850, Loss: 0.000000396\n",
      "Iteration 22860, Loss: 0.000000388\n",
      "Iteration 22870, Loss: 0.000000394\n",
      "Iteration 22880, Loss: 0.000000466\n",
      "Iteration 22890, Loss: 0.000000995\n",
      "Iteration 22900, Loss: 0.000000480\n",
      "Iteration 22910, Loss: 0.000000448\n",
      "Iteration 22920, Loss: 0.000000403\n",
      "Iteration 22930, Loss: 0.000000397\n",
      "Iteration 22940, Loss: 0.000000407\n",
      "Iteration 22950, Loss: 0.000000423\n",
      "Iteration 22960, Loss: 0.000000719\n",
      "Iteration 22970, Loss: 0.000002582\n",
      "Iteration 22980, Loss: 0.000000544\n",
      "Iteration 22990, Loss: 0.000000557\n",
      "Iteration 23000, Loss: 0.000000455\n",
      "Iteration 23010, Loss: 0.000000384\n",
      "Iteration 23020, Loss: 0.000000382\n",
      "Iteration 23030, Loss: 0.000000383\n",
      "Iteration 23040, Loss: 0.000000501\n",
      "Iteration 23050, Loss: 0.000001205\n",
      "Iteration 23060, Loss: 0.000000673\n",
      "Iteration 23070, Loss: 0.000000436\n",
      "Iteration 23080, Loss: 0.000000408\n",
      "Iteration 23090, Loss: 0.000000392\n",
      "Iteration 23100, Loss: 0.000000378\n",
      "Iteration 23110, Loss: 0.000000375\n",
      "Iteration 23120, Loss: 0.000000374\n",
      "Iteration 23130, Loss: 0.000000374\n",
      "Iteration 23140, Loss: 0.000000551\n",
      "Iteration 23150, Loss: 0.000003726\n",
      "Iteration 23160, Loss: 0.000001296\n",
      "Iteration 23170, Loss: 0.000000701\n",
      "Iteration 23180, Loss: 0.000000437\n",
      "Iteration 23190, Loss: 0.000000385\n",
      "Iteration 23200, Loss: 0.000000384\n",
      "Iteration 23210, Loss: 0.000000379\n",
      "Iteration 23220, Loss: 0.000000375\n",
      "Iteration 23230, Loss: 0.000000374\n",
      "Iteration 23240, Loss: 0.000000373\n",
      "Iteration 23250, Loss: 0.000000373\n",
      "Iteration 23260, Loss: 0.000000373\n",
      "Iteration 23270, Loss: 0.000000404\n",
      "Iteration 23280, Loss: 0.000002053\n",
      "Iteration 23290, Loss: 0.000001068\n",
      "Iteration 23300, Loss: 0.000000462\n",
      "Iteration 23310, Loss: 0.000000460\n",
      "Iteration 23320, Loss: 0.000000380\n",
      "Iteration 23330, Loss: 0.000000386\n",
      "Iteration 23340, Loss: 0.000000375\n",
      "Iteration 23350, Loss: 0.000000375\n",
      "Iteration 23360, Loss: 0.000000392\n",
      "Iteration 23370, Loss: 0.000000603\n",
      "Iteration 23380, Loss: 0.000002509\n",
      "Iteration 23390, Loss: 0.000001106\n",
      "Iteration 23400, Loss: 0.000000572\n",
      "Iteration 23410, Loss: 0.000000384\n",
      "Iteration 23420, Loss: 0.000000381\n",
      "Iteration 23430, Loss: 0.000000379\n",
      "Iteration 23440, Loss: 0.000000375\n",
      "Iteration 23450, Loss: 0.000000373\n",
      "Iteration 23460, Loss: 0.000000373\n",
      "Iteration 23470, Loss: 0.000000372\n",
      "Iteration 23480, Loss: 0.000000375\n",
      "Iteration 23490, Loss: 0.000000476\n",
      "Iteration 23500, Loss: 0.000001773\n",
      "Iteration 23510, Loss: 0.000000832\n",
      "Iteration 23520, Loss: 0.000000463\n",
      "Iteration 23530, Loss: 0.000000453\n",
      "Iteration 23540, Loss: 0.000000402\n",
      "Iteration 23550, Loss: 0.000000381\n",
      "Iteration 23560, Loss: 0.000000378\n",
      "Iteration 23570, Loss: 0.000000417\n",
      "Iteration 23580, Loss: 0.000001188\n",
      "Iteration 23590, Loss: 0.000000563\n",
      "Iteration 23600, Loss: 0.000000508\n",
      "Iteration 23610, Loss: 0.000000439\n",
      "Iteration 23620, Loss: 0.000000391\n",
      "Iteration 23630, Loss: 0.000000380\n",
      "Iteration 23640, Loss: 0.000000380\n",
      "Iteration 23650, Loss: 0.000000591\n",
      "Iteration 23660, Loss: 0.000002717\n",
      "Iteration 23670, Loss: 0.000000613\n",
      "Iteration 23680, Loss: 0.000000570\n",
      "Iteration 23690, Loss: 0.000000411\n",
      "Iteration 23700, Loss: 0.000000383\n",
      "Iteration 23710, Loss: 0.000000380\n",
      "Iteration 23720, Loss: 0.000000375\n",
      "Iteration 23730, Loss: 0.000000372\n",
      "Iteration 23740, Loss: 0.000000372\n",
      "Iteration 23750, Loss: 0.000000374\n",
      "Iteration 23760, Loss: 0.000000530\n",
      "Iteration 23770, Loss: 0.000001463\n",
      "Iteration 23780, Loss: 0.000000560\n",
      "Iteration 23790, Loss: 0.000000548\n",
      "Iteration 23800, Loss: 0.000000395\n",
      "Iteration 23810, Loss: 0.000000396\n",
      "Iteration 23820, Loss: 0.000000474\n",
      "Iteration 23830, Loss: 0.000001823\n",
      "Iteration 23840, Loss: 0.000000667\n",
      "Iteration 23850, Loss: 0.000000536\n",
      "Iteration 23860, Loss: 0.000000447\n",
      "Iteration 23870, Loss: 0.000000402\n",
      "Iteration 23880, Loss: 0.000000381\n",
      "Iteration 23890, Loss: 0.000000372\n",
      "Iteration 23900, Loss: 0.000000373\n",
      "Iteration 23910, Loss: 0.000000372\n",
      "Iteration 23920, Loss: 0.000000382\n",
      "Iteration 23930, Loss: 0.000000801\n",
      "Iteration 23940, Loss: 0.000001445\n",
      "Iteration 23950, Loss: 0.000000734\n",
      "Iteration 23960, Loss: 0.000000469\n",
      "Iteration 23970, Loss: 0.000000416\n",
      "Iteration 23980, Loss: 0.000000387\n",
      "Iteration 23990, Loss: 0.000000383\n",
      "Iteration 24000, Loss: 0.000000381\n",
      "Iteration 24010, Loss: 0.000000428\n",
      "Iteration 24020, Loss: 0.000000992\n",
      "Iteration 24030, Loss: 0.000000998\n",
      "Iteration 24040, Loss: 0.000000581\n",
      "Iteration 24050, Loss: 0.000000441\n",
      "Iteration 24060, Loss: 0.000000405\n",
      "Iteration 24070, Loss: 0.000000391\n",
      "Iteration 24080, Loss: 0.000000383\n",
      "Iteration 24090, Loss: 0.000000533\n",
      "Iteration 24100, Loss: 0.000001150\n",
      "Iteration 24110, Loss: 0.000000496\n",
      "Iteration 24120, Loss: 0.000000379\n",
      "Iteration 24130, Loss: 0.000000401\n",
      "Iteration 24140, Loss: 0.000000520\n",
      "Iteration 24150, Loss: 0.000001996\n",
      "Iteration 24160, Loss: 0.000000865\n",
      "Iteration 24170, Loss: 0.000000595\n",
      "Iteration 24180, Loss: 0.000000456\n",
      "Iteration 24190, Loss: 0.000000402\n",
      "Iteration 24200, Loss: 0.000000383\n",
      "Iteration 24210, Loss: 0.000000378\n",
      "Iteration 24220, Loss: 0.000000436\n",
      "Iteration 24230, Loss: 0.000001324\n",
      "Iteration 24240, Loss: 0.000000578\n",
      "Iteration 24250, Loss: 0.000000451\n",
      "Iteration 24260, Loss: 0.000000389\n",
      "Iteration 24270, Loss: 0.000000384\n",
      "Iteration 24280, Loss: 0.000000383\n",
      "Iteration 24290, Loss: 0.000000546\n",
      "Iteration 24300, Loss: 0.000002761\n",
      "Iteration 24310, Loss: 0.000001057\n",
      "Iteration 24320, Loss: 0.000000618\n",
      "Iteration 24330, Loss: 0.000000419\n",
      "Iteration 24340, Loss: 0.000000396\n",
      "Iteration 24350, Loss: 0.000000380\n",
      "Iteration 24360, Loss: 0.000000379\n",
      "Iteration 24370, Loss: 0.000000405\n",
      "Iteration 24380, Loss: 0.000000975\n",
      "Iteration 24390, Loss: 0.000000518\n",
      "Iteration 24400, Loss: 0.000000474\n",
      "Iteration 24410, Loss: 0.000000401\n",
      "Iteration 24420, Loss: 0.000000399\n",
      "Iteration 24430, Loss: 0.000000388\n",
      "Iteration 24440, Loss: 0.000000409\n",
      "Iteration 24450, Loss: 0.000000803\n",
      "Iteration 24460, Loss: 0.000001058\n",
      "Iteration 24470, Loss: 0.000000655\n",
      "Iteration 24480, Loss: 0.000000503\n",
      "Iteration 24490, Loss: 0.000000451\n",
      "Iteration 24500, Loss: 0.000000453\n",
      "Iteration 24510, Loss: 0.000000505\n",
      "Iteration 24520, Loss: 0.000000410\n",
      "Iteration 24530, Loss: 0.000000420\n",
      "Iteration 24540, Loss: 0.000001210\n",
      "Iteration 24550, Loss: 0.000000661\n",
      "Iteration 24560, Loss: 0.000000649\n",
      "Iteration 24570, Loss: 0.000000699\n",
      "Iteration 24580, Loss: 0.000000630\n",
      "Iteration 24590, Loss: 0.000000439\n",
      "Iteration 24600, Loss: 0.000000438\n",
      "Iteration 24610, Loss: 0.000000494\n",
      "Iteration 24620, Loss: 0.000000709\n",
      "Iteration 24630, Loss: 0.000000796\n",
      "Iteration 24640, Loss: 0.000000552\n",
      "Iteration 24650, Loss: 0.000000519\n",
      "Iteration 24660, Loss: 0.000000434\n",
      "Iteration 24670, Loss: 0.000000460\n",
      "Iteration 24680, Loss: 0.000000474\n",
      "Iteration 24690, Loss: 0.000000911\n",
      "Iteration 24700, Loss: 0.000000776\n",
      "Iteration 24710, Loss: 0.000000621\n",
      "Iteration 24720, Loss: 0.000000429\n",
      "Iteration 24730, Loss: 0.000000396\n",
      "Iteration 24740, Loss: 0.000000385\n",
      "Iteration 24750, Loss: 0.000000506\n",
      "Iteration 24760, Loss: 0.000001979\n",
      "Iteration 24770, Loss: 0.000000841\n",
      "Iteration 24780, Loss: 0.000000413\n",
      "Iteration 24790, Loss: 0.000000444\n",
      "Iteration 24800, Loss: 0.000000398\n",
      "Iteration 24810, Loss: 0.000000382\n",
      "Iteration 24820, Loss: 0.000000461\n",
      "Iteration 24830, Loss: 0.000001311\n",
      "Iteration 24840, Loss: 0.000000691\n",
      "Iteration 24850, Loss: 0.000000513\n",
      "Iteration 24860, Loss: 0.000000418\n",
      "Iteration 24870, Loss: 0.000000387\n",
      "Iteration 24880, Loss: 0.000000384\n",
      "Iteration 24890, Loss: 0.000000396\n",
      "Iteration 24900, Loss: 0.000000688\n",
      "Iteration 24910, Loss: 0.000002238\n",
      "Iteration 24920, Loss: 0.000000574\n",
      "Iteration 24930, Loss: 0.000000561\n",
      "Iteration 24940, Loss: 0.000000480\n",
      "Iteration 24950, Loss: 0.000000391\n",
      "Iteration 24960, Loss: 0.000000380\n",
      "Iteration 24970, Loss: 0.000000372\n",
      "Iteration 24980, Loss: 0.000000370\n",
      "Iteration 24990, Loss: 0.000000377\n",
      "Iteration 25000, Loss: 0.000000724\n",
      "Iteration 25010, Loss: 0.000000593\n",
      "Iteration 25020, Loss: 0.000000626\n",
      "Iteration 25030, Loss: 0.000000404\n",
      "Iteration 25040, Loss: 0.000000406\n",
      "Iteration 25050, Loss: 0.000000372\n",
      "Iteration 25060, Loss: 0.000000377\n",
      "Iteration 25070, Loss: 0.000000410\n",
      "Iteration 25080, Loss: 0.000001039\n",
      "Iteration 25090, Loss: 0.000001305\n",
      "Iteration 25100, Loss: 0.000000690\n",
      "Iteration 25110, Loss: 0.000000491\n",
      "Iteration 25120, Loss: 0.000000396\n",
      "Iteration 25130, Loss: 0.000000381\n",
      "Iteration 25140, Loss: 0.000000389\n",
      "Iteration 25150, Loss: 0.000000456\n",
      "Iteration 25160, Loss: 0.000001315\n",
      "Iteration 25170, Loss: 0.000000388\n",
      "Iteration 25180, Loss: 0.000000391\n",
      "Iteration 25190, Loss: 0.000000386\n",
      "Iteration 25200, Loss: 0.000000393\n",
      "Iteration 25210, Loss: 0.000000381\n",
      "Iteration 25220, Loss: 0.000000390\n",
      "Iteration 25230, Loss: 0.000000879\n",
      "Iteration 25240, Loss: 0.000001306\n",
      "Iteration 25250, Loss: 0.000000604\n",
      "Iteration 25260, Loss: 0.000000462\n",
      "Iteration 25270, Loss: 0.000000383\n",
      "Iteration 25280, Loss: 0.000000380\n",
      "Iteration 25290, Loss: 0.000000379\n",
      "Iteration 25300, Loss: 0.000000386\n",
      "Iteration 25310, Loss: 0.000000566\n",
      "Iteration 25320, Loss: 0.000001820\n",
      "Iteration 25330, Loss: 0.000000830\n",
      "Iteration 25340, Loss: 0.000000537\n",
      "Iteration 25350, Loss: 0.000000429\n",
      "Iteration 25360, Loss: 0.000000396\n",
      "Iteration 25370, Loss: 0.000000480\n",
      "Iteration 25380, Loss: 0.000000769\n",
      "Iteration 25390, Loss: 0.000000412\n",
      "Iteration 25400, Loss: 0.000000399\n",
      "Iteration 25410, Loss: 0.000000645\n",
      "Iteration 25420, Loss: 0.000001230\n",
      "Iteration 25430, Loss: 0.000000581\n",
      "Iteration 25440, Loss: 0.000000466\n",
      "Iteration 25450, Loss: 0.000000412\n",
      "Iteration 25460, Loss: 0.000000399\n",
      "Iteration 25470, Loss: 0.000000537\n",
      "Iteration 25480, Loss: 0.000001530\n",
      "Iteration 25490, Loss: 0.000000556\n",
      "Iteration 25500, Loss: 0.000000410\n",
      "Iteration 25510, Loss: 0.000000395\n",
      "Iteration 25520, Loss: 0.000000386\n",
      "Iteration 25530, Loss: 0.000000376\n",
      "Iteration 25540, Loss: 0.000000547\n",
      "Iteration 25550, Loss: 0.000001146\n",
      "Iteration 25560, Loss: 0.000000536\n",
      "Iteration 25570, Loss: 0.000000467\n",
      "Iteration 25580, Loss: 0.000000405\n",
      "Iteration 25590, Loss: 0.000000371\n",
      "Iteration 25600, Loss: 0.000000401\n",
      "Iteration 25610, Loss: 0.000002191\n",
      "Iteration 25620, Loss: 0.000001078\n",
      "Iteration 25630, Loss: 0.000000992\n",
      "Iteration 25640, Loss: 0.000000401\n",
      "Iteration 25650, Loss: 0.000000439\n",
      "Iteration 25660, Loss: 0.000000382\n",
      "Iteration 25670, Loss: 0.000000373\n",
      "Iteration 25680, Loss: 0.000000411\n",
      "Iteration 25690, Loss: 0.000001047\n",
      "Iteration 25700, Loss: 0.000000474\n",
      "Iteration 25710, Loss: 0.000000436\n",
      "Iteration 25720, Loss: 0.000000391\n",
      "Iteration 25730, Loss: 0.000000376\n",
      "Iteration 25740, Loss: 0.000000373\n",
      "Iteration 25750, Loss: 0.000000370\n",
      "Iteration 25760, Loss: 0.000000379\n",
      "Iteration 25770, Loss: 0.000000654\n",
      "Iteration 25780, Loss: 0.000000900\n",
      "Iteration 25790, Loss: 0.000000631\n",
      "Iteration 25800, Loss: 0.000000459\n",
      "Iteration 25810, Loss: 0.000000425\n",
      "Iteration 25820, Loss: 0.000000430\n",
      "Iteration 25830, Loss: 0.000000579\n",
      "Iteration 25840, Loss: 0.000001128\n",
      "Iteration 25850, Loss: 0.000000434\n",
      "Iteration 25860, Loss: 0.000000438\n",
      "Iteration 25870, Loss: 0.000000428\n",
      "Iteration 25880, Loss: 0.000000374\n",
      "Iteration 25890, Loss: 0.000000376\n",
      "Iteration 25900, Loss: 0.000000434\n",
      "Iteration 25910, Loss: 0.000001172\n",
      "Iteration 25920, Loss: 0.000001791\n",
      "Iteration 25930, Loss: 0.000000622\n",
      "Iteration 25940, Loss: 0.000000538\n",
      "Iteration 25950, Loss: 0.000000488\n",
      "Iteration 25960, Loss: 0.000000660\n",
      "Iteration 25970, Loss: 0.000000686\n",
      "Iteration 25980, Loss: 0.000000373\n",
      "Iteration 25990, Loss: 0.000000449\n",
      "Iteration 26000, Loss: 0.000000458\n",
      "Iteration 26010, Loss: 0.000000544\n",
      "Iteration 26020, Loss: 0.000000762\n",
      "Iteration 26030, Loss: 0.000000844\n",
      "Iteration 26040, Loss: 0.000000485\n",
      "Iteration 26050, Loss: 0.000000382\n",
      "Iteration 26060, Loss: 0.000000399\n",
      "Iteration 26070, Loss: 0.000000397\n",
      "Iteration 26080, Loss: 0.000000429\n",
      "Iteration 26090, Loss: 0.000000845\n",
      "Iteration 26100, Loss: 0.000001313\n",
      "Iteration 26110, Loss: 0.000000704\n",
      "Iteration 26120, Loss: 0.000000496\n",
      "Iteration 26130, Loss: 0.000000476\n",
      "Iteration 26140, Loss: 0.000000400\n",
      "Iteration 26150, Loss: 0.000000449\n",
      "Iteration 26160, Loss: 0.000000384\n",
      "Iteration 26170, Loss: 0.000000376\n",
      "Iteration 26180, Loss: 0.000000374\n",
      "Iteration 26190, Loss: 0.000000399\n",
      "Iteration 26200, Loss: 0.000001207\n",
      "Iteration 26210, Loss: 0.000000527\n",
      "Iteration 26220, Loss: 0.000000540\n",
      "Iteration 26230, Loss: 0.000000499\n",
      "Iteration 26240, Loss: 0.000000421\n",
      "Iteration 26250, Loss: 0.000000393\n",
      "Iteration 26260, Loss: 0.000000545\n",
      "Iteration 26270, Loss: 0.000000920\n",
      "Iteration 26280, Loss: 0.000000532\n",
      "Iteration 26290, Loss: 0.000000408\n",
      "Iteration 26300, Loss: 0.000000384\n",
      "Iteration 26310, Loss: 0.000000409\n",
      "Iteration 26320, Loss: 0.000000573\n",
      "Iteration 26330, Loss: 0.000001059\n",
      "Iteration 26340, Loss: 0.000000546\n",
      "Iteration 26350, Loss: 0.000000502\n",
      "Iteration 26360, Loss: 0.000000412\n",
      "Iteration 26370, Loss: 0.000000374\n",
      "Iteration 26380, Loss: 0.000000384\n",
      "Iteration 26390, Loss: 0.000000487\n",
      "Iteration 26400, Loss: 0.000001995\n",
      "Iteration 26410, Loss: 0.000000842\n",
      "Iteration 26420, Loss: 0.000000560\n",
      "Iteration 26430, Loss: 0.000000422\n",
      "Iteration 26440, Loss: 0.000000380\n",
      "Iteration 26450, Loss: 0.000000374\n",
      "Iteration 26460, Loss: 0.000000390\n",
      "Iteration 26470, Loss: 0.000000740\n",
      "Iteration 26480, Loss: 0.000000480\n",
      "Iteration 26490, Loss: 0.000001650\n",
      "Iteration 26500, Loss: 0.000000574\n",
      "Iteration 26510, Loss: 0.000000447\n",
      "Iteration 26520, Loss: 0.000000396\n",
      "Iteration 26530, Loss: 0.000000375\n",
      "Iteration 26540, Loss: 0.000000369\n",
      "Iteration 26550, Loss: 0.000000374\n",
      "Iteration 26560, Loss: 0.000000442\n",
      "Iteration 26570, Loss: 0.000001201\n",
      "Iteration 26580, Loss: 0.000000523\n",
      "Iteration 26590, Loss: 0.000000451\n",
      "Iteration 26600, Loss: 0.000000919\n",
      "Iteration 26610, Loss: 0.000000809\n",
      "Iteration 26620, Loss: 0.000000553\n",
      "Iteration 26630, Loss: 0.000000425\n",
      "Iteration 26640, Loss: 0.000000398\n",
      "Iteration 26650, Loss: 0.000000395\n",
      "Iteration 26660, Loss: 0.000000603\n",
      "Iteration 26670, Loss: 0.000001058\n",
      "Iteration 26680, Loss: 0.000000482\n",
      "Iteration 26690, Loss: 0.000000372\n",
      "Iteration 26700, Loss: 0.000000380\n",
      "Iteration 26710, Loss: 0.000000376\n",
      "Iteration 26720, Loss: 0.000000382\n",
      "Iteration 26730, Loss: 0.000000536\n",
      "Iteration 26740, Loss: 0.000001825\n",
      "Iteration 26750, Loss: 0.000000780\n",
      "Iteration 26760, Loss: 0.000000522\n",
      "Iteration 26770, Loss: 0.000000418\n",
      "Iteration 26780, Loss: 0.000000376\n",
      "Iteration 26790, Loss: 0.000000374\n",
      "Iteration 26800, Loss: 0.000000568\n",
      "Iteration 26810, Loss: 0.000000584\n",
      "Iteration 26820, Loss: 0.000000453\n",
      "Iteration 26830, Loss: 0.000000630\n",
      "Iteration 26840, Loss: 0.000000784\n",
      "Iteration 26850, Loss: 0.000000692\n",
      "Iteration 26860, Loss: 0.000000755\n",
      "Iteration 26870, Loss: 0.000000455\n",
      "Iteration 26880, Loss: 0.000000384\n",
      "Iteration 26890, Loss: 0.000000444\n",
      "Iteration 26900, Loss: 0.000000747\n",
      "Iteration 26910, Loss: 0.000000798\n",
      "Iteration 26920, Loss: 0.000000489\n",
      "Iteration 26930, Loss: 0.000000385\n",
      "Iteration 26940, Loss: 0.000000628\n",
      "Iteration 26950, Loss: 0.000000505\n",
      "Iteration 26960, Loss: 0.000000415\n",
      "Iteration 26970, Loss: 0.000000402\n",
      "Iteration 26980, Loss: 0.000000420\n",
      "Iteration 26990, Loss: 0.000002119\n",
      "Iteration 27000, Loss: 0.000000978\n",
      "Iteration 27010, Loss: 0.000000925\n",
      "Iteration 27020, Loss: 0.000000508\n",
      "Iteration 27030, Loss: 0.000000403\n",
      "Iteration 27040, Loss: 0.000000536\n",
      "Iteration 27050, Loss: 0.000000714\n",
      "Iteration 27060, Loss: 0.000000448\n",
      "Iteration 27070, Loss: 0.000000370\n",
      "Iteration 27080, Loss: 0.000000384\n",
      "Iteration 27090, Loss: 0.000000367\n",
      "Iteration 27100, Loss: 0.000000414\n",
      "Iteration 27110, Loss: 0.000001093\n",
      "Iteration 27120, Loss: 0.000000623\n",
      "Iteration 27130, Loss: 0.000000530\n",
      "Iteration 27140, Loss: 0.000000525\n",
      "Iteration 27150, Loss: 0.000000396\n",
      "Iteration 27160, Loss: 0.000000456\n",
      "Iteration 27170, Loss: 0.000000936\n",
      "Iteration 27180, Loss: 0.000000632\n",
      "Iteration 27190, Loss: 0.000000673\n",
      "Iteration 27200, Loss: 0.000000467\n",
      "Iteration 27210, Loss: 0.000000371\n",
      "Iteration 27220, Loss: 0.000000384\n",
      "Iteration 27230, Loss: 0.000000469\n",
      "Iteration 27240, Loss: 0.000001709\n",
      "Iteration 27250, Loss: 0.000000886\n",
      "Iteration 27260, Loss: 0.000000538\n",
      "Iteration 27270, Loss: 0.000000380\n",
      "Iteration 27280, Loss: 0.000000379\n",
      "Iteration 27290, Loss: 0.000000371\n",
      "Iteration 27300, Loss: 0.000000398\n",
      "Iteration 27310, Loss: 0.000001091\n",
      "Iteration 27320, Loss: 0.000001233\n",
      "Iteration 27330, Loss: 0.000000708\n",
      "Iteration 27340, Loss: 0.000000436\n",
      "Iteration 27350, Loss: 0.000000397\n",
      "Iteration 27360, Loss: 0.000000384\n",
      "Iteration 27370, Loss: 0.000000369\n",
      "Iteration 27380, Loss: 0.000000366\n",
      "Iteration 27390, Loss: 0.000000373\n",
      "Iteration 27400, Loss: 0.000000566\n",
      "Iteration 27410, Loss: 0.000002558\n",
      "Iteration 27420, Loss: 0.000000938\n",
      "Iteration 27430, Loss: 0.000000397\n",
      "Iteration 27440, Loss: 0.000000400\n",
      "Iteration 27450, Loss: 0.000000391\n",
      "Iteration 27460, Loss: 0.000000377\n",
      "Iteration 27470, Loss: 0.000000387\n",
      "Iteration 27480, Loss: 0.000001070\n",
      "Iteration 27490, Loss: 0.000000538\n",
      "Iteration 27500, Loss: 0.000000543\n",
      "Iteration 27510, Loss: 0.000000396\n",
      "Iteration 27520, Loss: 0.000000373\n",
      "Iteration 27530, Loss: 0.000000375\n",
      "Iteration 27540, Loss: 0.000000392\n",
      "Iteration 27550, Loss: 0.000000951\n",
      "Iteration 27560, Loss: 0.000000839\n",
      "Iteration 27570, Loss: 0.000000444\n",
      "Iteration 27580, Loss: 0.000000423\n",
      "Iteration 27590, Loss: 0.000000396\n",
      "Iteration 27600, Loss: 0.000000373\n",
      "Iteration 27610, Loss: 0.000000365\n",
      "Iteration 27620, Loss: 0.000000365\n",
      "Iteration 27630, Loss: 0.000000366\n",
      "Iteration 27640, Loss: 0.000000398\n",
      "Iteration 27650, Loss: 0.000001391\n",
      "Iteration 27660, Loss: 0.000001130\n",
      "Iteration 27670, Loss: 0.000000566\n",
      "Iteration 27680, Loss: 0.000000475\n",
      "Iteration 27690, Loss: 0.000000388\n",
      "Iteration 27700, Loss: 0.000000375\n",
      "Iteration 27710, Loss: 0.000000368\n",
      "Iteration 27720, Loss: 0.000000377\n",
      "Iteration 27730, Loss: 0.000000988\n",
      "Iteration 27740, Loss: 0.000000676\n",
      "Iteration 27750, Loss: 0.000000839\n",
      "Iteration 27760, Loss: 0.000000449\n",
      "Iteration 27770, Loss: 0.000000422\n",
      "Iteration 27780, Loss: 0.000000381\n",
      "Iteration 27790, Loss: 0.000000367\n",
      "Iteration 27800, Loss: 0.000000366\n",
      "Iteration 27810, Loss: 0.000000364\n",
      "Iteration 27820, Loss: 0.000000372\n",
      "Iteration 27830, Loss: 0.000000689\n",
      "Iteration 27840, Loss: 0.000002061\n",
      "Iteration 27850, Loss: 0.000000769\n",
      "Iteration 27860, Loss: 0.000000530\n",
      "Iteration 27870, Loss: 0.000000424\n",
      "Iteration 27880, Loss: 0.000000377\n",
      "Iteration 27890, Loss: 0.000000369\n",
      "Iteration 27900, Loss: 0.000000365\n",
      "Iteration 27910, Loss: 0.000000364\n",
      "Iteration 27920, Loss: 0.000000363\n",
      "Iteration 27930, Loss: 0.000000364\n",
      "Iteration 27940, Loss: 0.000000405\n",
      "Iteration 27950, Loss: 0.000001600\n",
      "Iteration 27960, Loss: 0.000000835\n",
      "Iteration 27970, Loss: 0.000000724\n",
      "Iteration 27980, Loss: 0.000000469\n",
      "Iteration 27990, Loss: 0.000000417\n",
      "Iteration 28000, Loss: 0.000000463\n",
      "Iteration 28010, Loss: 0.000000811\n",
      "Iteration 28020, Loss: 0.000000423\n",
      "Iteration 28030, Loss: 0.000000379\n",
      "Iteration 28040, Loss: 0.000000375\n",
      "Iteration 28050, Loss: 0.000000373\n",
      "Iteration 28060, Loss: 0.000000380\n",
      "Iteration 28070, Loss: 0.000000827\n",
      "Iteration 28080, Loss: 0.000001022\n",
      "Iteration 28090, Loss: 0.000000383\n",
      "Iteration 28100, Loss: 0.000000436\n",
      "Iteration 28110, Loss: 0.000000425\n",
      "Iteration 28120, Loss: 0.000000395\n",
      "Iteration 28130, Loss: 0.000000592\n",
      "Iteration 28140, Loss: 0.000001037\n",
      "Iteration 28150, Loss: 0.000000537\n",
      "Iteration 28160, Loss: 0.000000407\n",
      "Iteration 28170, Loss: 0.000000380\n",
      "Iteration 28180, Loss: 0.000000373\n",
      "Iteration 28190, Loss: 0.000000511\n",
      "Iteration 28200, Loss: 0.000001561\n",
      "Iteration 28210, Loss: 0.000000566\n",
      "Iteration 28220, Loss: 0.000000384\n",
      "Iteration 28230, Loss: 0.000000395\n",
      "Iteration 28240, Loss: 0.000000378\n",
      "Iteration 28250, Loss: 0.000000374\n",
      "Iteration 28260, Loss: 0.000000371\n",
      "Iteration 28270, Loss: 0.000000415\n",
      "Iteration 28280, Loss: 0.000001335\n",
      "Iteration 28290, Loss: 0.000000381\n",
      "Iteration 28300, Loss: 0.000000416\n",
      "Iteration 28310, Loss: 0.000000440\n",
      "Iteration 28320, Loss: 0.000000469\n",
      "Iteration 28330, Loss: 0.000000761\n",
      "Iteration 28340, Loss: 0.000000383\n",
      "Iteration 28350, Loss: 0.000000413\n",
      "Iteration 28360, Loss: 0.000000385\n",
      "Iteration 28370, Loss: 0.000000372\n",
      "Iteration 28380, Loss: 0.000000410\n",
      "Iteration 28390, Loss: 0.000000807\n",
      "Iteration 28400, Loss: 0.000000877\n",
      "Iteration 28410, Loss: 0.000000662\n",
      "Iteration 28420, Loss: 0.000000520\n",
      "Iteration 28430, Loss: 0.000000392\n",
      "Iteration 28440, Loss: 0.000000387\n",
      "Iteration 28450, Loss: 0.000000439\n",
      "Iteration 28460, Loss: 0.000000929\n",
      "Iteration 28470, Loss: 0.000000482\n",
      "Iteration 28480, Loss: 0.000001157\n",
      "Iteration 28490, Loss: 0.000000377\n",
      "Iteration 28500, Loss: 0.000000444\n",
      "Iteration 28510, Loss: 0.000000419\n",
      "Iteration 28520, Loss: 0.000000364\n",
      "Iteration 28530, Loss: 0.000000380\n",
      "Iteration 28540, Loss: 0.000000417\n",
      "Iteration 28550, Loss: 0.000000801\n",
      "Iteration 28560, Loss: 0.000000536\n",
      "Iteration 28570, Loss: 0.000001992\n",
      "Iteration 28580, Loss: 0.000000750\n",
      "Iteration 28590, Loss: 0.000000486\n",
      "Iteration 28600, Loss: 0.000000424\n",
      "Iteration 28610, Loss: 0.000000390\n",
      "Iteration 28620, Loss: 0.000000376\n",
      "Iteration 28630, Loss: 0.000000448\n",
      "Iteration 28640, Loss: 0.000001317\n",
      "Iteration 28650, Loss: 0.000000667\n",
      "Iteration 28660, Loss: 0.000000463\n",
      "Iteration 28670, Loss: 0.000000385\n",
      "Iteration 28680, Loss: 0.000000369\n",
      "Iteration 28690, Loss: 0.000000369\n",
      "Iteration 28700, Loss: 0.000000415\n",
      "Iteration 28710, Loss: 0.000000752\n",
      "Iteration 28720, Loss: 0.000002514\n",
      "Iteration 28730, Loss: 0.000000945\n",
      "Iteration 28740, Loss: 0.000000542\n",
      "Iteration 28750, Loss: 0.000000372\n",
      "Iteration 28760, Loss: 0.000000393\n",
      "Iteration 28770, Loss: 0.000000368\n",
      "Iteration 28780, Loss: 0.000000363\n",
      "Iteration 28790, Loss: 0.000000362\n",
      "Iteration 28800, Loss: 0.000000361\n",
      "Iteration 28810, Loss: 0.000000361\n",
      "Iteration 28820, Loss: 0.000000361\n",
      "Iteration 28830, Loss: 0.000000362\n",
      "Iteration 28840, Loss: 0.000000525\n",
      "Iteration 28850, Loss: 0.000001496\n",
      "Iteration 28860, Loss: 0.000000825\n",
      "Iteration 28870, Loss: 0.000000960\n",
      "Iteration 28880, Loss: 0.000000715\n",
      "Iteration 28890, Loss: 0.000000582\n",
      "Iteration 28900, Loss: 0.000000459\n",
      "Iteration 28910, Loss: 0.000000405\n",
      "Iteration 28920, Loss: 0.000000371\n",
      "Iteration 28930, Loss: 0.000000363\n",
      "Iteration 28940, Loss: 0.000000364\n",
      "Iteration 28950, Loss: 0.000000367\n",
      "Iteration 28960, Loss: 0.000000397\n",
      "Iteration 28970, Loss: 0.000000997\n",
      "Iteration 28980, Loss: 0.000000581\n",
      "Iteration 28990, Loss: 0.000000400\n",
      "Iteration 29000, Loss: 0.000000419\n",
      "Iteration 29010, Loss: 0.000000492\n",
      "Iteration 29020, Loss: 0.000000374\n",
      "Iteration 29030, Loss: 0.000000383\n",
      "Iteration 29040, Loss: 0.000000383\n",
      "Iteration 29050, Loss: 0.000000403\n",
      "Iteration 29060, Loss: 0.000000682\n",
      "Iteration 29070, Loss: 0.000000731\n",
      "Iteration 29080, Loss: 0.000000446\n",
      "Iteration 29090, Loss: 0.000000533\n",
      "Iteration 29100, Loss: 0.000000775\n",
      "Iteration 29110, Loss: 0.000000437\n",
      "Iteration 29120, Loss: 0.000000411\n",
      "Iteration 29130, Loss: 0.000000439\n",
      "Iteration 29140, Loss: 0.000000547\n",
      "Iteration 29150, Loss: 0.000000890\n",
      "Iteration 29160, Loss: 0.000000396\n",
      "Iteration 29170, Loss: 0.000000509\n",
      "Iteration 29180, Loss: 0.000000875\n",
      "Iteration 29190, Loss: 0.000000505\n",
      "Iteration 29200, Loss: 0.000000399\n",
      "Iteration 29210, Loss: 0.000000376\n",
      "Iteration 29220, Loss: 0.000000407\n",
      "Iteration 29230, Loss: 0.000000830\n",
      "Iteration 29240, Loss: 0.000000846\n",
      "Iteration 29250, Loss: 0.000000605\n",
      "Iteration 29260, Loss: 0.000000467\n",
      "Iteration 29270, Loss: 0.000000395\n",
      "Iteration 29280, Loss: 0.000000371\n",
      "Iteration 29290, Loss: 0.000000593\n",
      "Iteration 29300, Loss: 0.000000708\n",
      "Iteration 29310, Loss: 0.000000640\n",
      "Iteration 29320, Loss: 0.000000749\n",
      "Iteration 29330, Loss: 0.000000385\n",
      "Iteration 29340, Loss: 0.000000424\n",
      "Iteration 29350, Loss: 0.000000467\n",
      "Iteration 29360, Loss: 0.000000610\n",
      "Iteration 29370, Loss: 0.000000716\n",
      "Iteration 29380, Loss: 0.000000444\n",
      "Iteration 29390, Loss: 0.000000902\n",
      "Iteration 29400, Loss: 0.000000439\n",
      "Iteration 29410, Loss: 0.000000555\n",
      "Iteration 29420, Loss: 0.000000773\n",
      "Iteration 29430, Loss: 0.000000422\n",
      "Iteration 29440, Loss: 0.000000431\n",
      "Iteration 29450, Loss: 0.000000451\n",
      "Iteration 29460, Loss: 0.000000464\n",
      "Iteration 29470, Loss: 0.000000634\n",
      "Iteration 29480, Loss: 0.000001215\n",
      "Iteration 29490, Loss: 0.000000884\n",
      "Iteration 29500, Loss: 0.000000523\n",
      "Iteration 29510, Loss: 0.000000400\n",
      "Iteration 29520, Loss: 0.000000388\n",
      "Iteration 29530, Loss: 0.000000368\n",
      "Iteration 29540, Loss: 0.000000367\n",
      "Iteration 29550, Loss: 0.000000366\n",
      "Iteration 29560, Loss: 0.000000427\n",
      "Iteration 29570, Loss: 0.000001800\n",
      "Iteration 29580, Loss: 0.000000623\n",
      "Iteration 29590, Loss: 0.000000543\n",
      "Iteration 29600, Loss: 0.000000460\n",
      "Iteration 29610, Loss: 0.000000394\n",
      "Iteration 29620, Loss: 0.000000372\n",
      "Iteration 29630, Loss: 0.000000377\n",
      "Iteration 29640, Loss: 0.000001226\n",
      "Iteration 29650, Loss: 0.000001215\n",
      "Iteration 29660, Loss: 0.000000575\n",
      "Iteration 29670, Loss: 0.000000418\n",
      "Iteration 29680, Loss: 0.000000370\n",
      "Iteration 29690, Loss: 0.000000367\n",
      "Iteration 29700, Loss: 0.000000367\n",
      "Iteration 29710, Loss: 0.000000401\n",
      "Iteration 29720, Loss: 0.000001505\n",
      "Iteration 29730, Loss: 0.000000960\n",
      "Iteration 29740, Loss: 0.000000833\n",
      "Iteration 29750, Loss: 0.000000452\n",
      "Iteration 29760, Loss: 0.000000379\n",
      "Iteration 29770, Loss: 0.000000378\n",
      "Iteration 29780, Loss: 0.000000367\n",
      "Iteration 29790, Loss: 0.000000363\n",
      "Iteration 29800, Loss: 0.000000373\n",
      "Iteration 29810, Loss: 0.000000661\n",
      "Iteration 29820, Loss: 0.000000639\n",
      "Iteration 29830, Loss: 0.000000384\n",
      "Iteration 29840, Loss: 0.000000380\n",
      "Iteration 29850, Loss: 0.000000436\n",
      "Iteration 29860, Loss: 0.000000920\n",
      "Iteration 29870, Loss: 0.000000525\n",
      "Iteration 29880, Loss: 0.000000481\n",
      "Iteration 29890, Loss: 0.000000371\n",
      "Iteration 29900, Loss: 0.000000395\n",
      "Iteration 29910, Loss: 0.000000385\n",
      "Iteration 29920, Loss: 0.000000433\n",
      "Iteration 29930, Loss: 0.000001010\n",
      "Iteration 29940, Loss: 0.000000528\n",
      "Iteration 29950, Loss: 0.000000503\n",
      "Iteration 29960, Loss: 0.000000471\n",
      "Iteration 29970, Loss: 0.000000557\n",
      "Iteration 29980, Loss: 0.000000817\n",
      "Iteration 29990, Loss: 0.000000452\n",
      "Iteration 30000, Loss: 0.000000373\n",
      "Iteration 30010, Loss: 0.000000405\n",
      "Iteration 30020, Loss: 0.000000810\n",
      "Iteration 30030, Loss: 0.000000629\n",
      "Iteration 30040, Loss: 0.000000847\n",
      "Iteration 30050, Loss: 0.000000419\n",
      "Iteration 30060, Loss: 0.000000452\n",
      "Iteration 30070, Loss: 0.000000374\n",
      "Iteration 30080, Loss: 0.000000383\n",
      "Iteration 30090, Loss: 0.000000693\n",
      "Iteration 30100, Loss: 0.000000563\n",
      "Iteration 30110, Loss: 0.000000804\n",
      "Iteration 30120, Loss: 0.000001310\n",
      "Iteration 30130, Loss: 0.000000796\n",
      "Iteration 30140, Loss: 0.000000605\n",
      "Iteration 30150, Loss: 0.000000423\n",
      "Iteration 30160, Loss: 0.000000390\n",
      "Iteration 30170, Loss: 0.000000381\n",
      "Iteration 30180, Loss: 0.000000397\n",
      "Iteration 30190, Loss: 0.000000397\n",
      "Iteration 30200, Loss: 0.000000386\n",
      "Iteration 30210, Loss: 0.000000437\n",
      "Iteration 30220, Loss: 0.000000695\n",
      "Iteration 30230, Loss: 0.000000681\n",
      "Iteration 30240, Loss: 0.000000645\n",
      "Iteration 30250, Loss: 0.000000390\n",
      "Iteration 30260, Loss: 0.000000386\n",
      "Iteration 30270, Loss: 0.000000623\n",
      "Iteration 30280, Loss: 0.000001283\n",
      "Iteration 30290, Loss: 0.000000535\n",
      "Iteration 30300, Loss: 0.000000431\n",
      "Iteration 30310, Loss: 0.000000448\n",
      "Iteration 30320, Loss: 0.000000794\n",
      "Iteration 30330, Loss: 0.000000612\n",
      "Iteration 30340, Loss: 0.000000477\n",
      "Iteration 30350, Loss: 0.000000381\n",
      "Iteration 30360, Loss: 0.000000432\n",
      "Iteration 30370, Loss: 0.000000662\n",
      "Iteration 30380, Loss: 0.000001184\n",
      "Iteration 30390, Loss: 0.000000614\n",
      "Iteration 30400, Loss: 0.000000410\n",
      "Iteration 30410, Loss: 0.000000394\n",
      "Iteration 30420, Loss: 0.000000430\n",
      "Iteration 30430, Loss: 0.000000721\n",
      "Iteration 30440, Loss: 0.000000735\n",
      "Iteration 30450, Loss: 0.000000566\n",
      "Iteration 30460, Loss: 0.000000452\n",
      "Iteration 30470, Loss: 0.000000439\n",
      "Iteration 30480, Loss: 0.000000624\n",
      "Iteration 30490, Loss: 0.000001002\n",
      "Iteration 30500, Loss: 0.000000406\n",
      "Iteration 30510, Loss: 0.000000413\n",
      "Iteration 30520, Loss: 0.000000384\n",
      "Iteration 30530, Loss: 0.000000401\n",
      "Iteration 30540, Loss: 0.000000609\n",
      "Iteration 30550, Loss: 0.000000987\n",
      "Iteration 30560, Loss: 0.000000497\n",
      "Iteration 30570, Loss: 0.000000717\n",
      "Iteration 30580, Loss: 0.000000755\n",
      "Iteration 30590, Loss: 0.000001130\n",
      "Iteration 30600, Loss: 0.000000677\n",
      "Iteration 30610, Loss: 0.000000431\n",
      "Iteration 30620, Loss: 0.000000381\n",
      "Iteration 30630, Loss: 0.000000378\n",
      "Iteration 30640, Loss: 0.000000360\n",
      "Iteration 30650, Loss: 0.000000370\n",
      "Iteration 30660, Loss: 0.000000440\n",
      "Iteration 30670, Loss: 0.000000838\n",
      "Iteration 30680, Loss: 0.000001055\n",
      "Iteration 30690, Loss: 0.000000695\n",
      "Iteration 30700, Loss: 0.000000444\n",
      "Iteration 30710, Loss: 0.000000403\n",
      "Iteration 30720, Loss: 0.000000392\n",
      "Iteration 30730, Loss: 0.000000371\n",
      "Iteration 30740, Loss: 0.000000361\n",
      "Iteration 30750, Loss: 0.000000359\n",
      "Iteration 30760, Loss: 0.000000360\n",
      "Iteration 30770, Loss: 0.000000449\n",
      "Iteration 30780, Loss: 0.000001635\n",
      "Iteration 30790, Loss: 0.000000623\n",
      "Iteration 30800, Loss: 0.000000610\n",
      "Iteration 30810, Loss: 0.000001391\n",
      "Iteration 30820, Loss: 0.000000482\n",
      "Iteration 30830, Loss: 0.000000393\n",
      "Iteration 30840, Loss: 0.000000450\n",
      "Iteration 30850, Loss: 0.000000377\n",
      "Iteration 30860, Loss: 0.000000359\n",
      "Iteration 30870, Loss: 0.000000363\n",
      "Iteration 30880, Loss: 0.000000368\n",
      "Iteration 30890, Loss: 0.000000466\n",
      "Iteration 30900, Loss: 0.000001903\n",
      "Iteration 30910, Loss: 0.000000857\n",
      "Iteration 30920, Loss: 0.000000706\n",
      "Iteration 30930, Loss: 0.000000401\n",
      "Iteration 30940, Loss: 0.000000434\n",
      "Iteration 30950, Loss: 0.000000410\n",
      "Iteration 30960, Loss: 0.000000429\n",
      "Iteration 30970, Loss: 0.000000709\n",
      "Iteration 30980, Loss: 0.000000887\n",
      "Iteration 30990, Loss: 0.000000511\n",
      "Iteration 31000, Loss: 0.000000357\n",
      "Iteration 31010, Loss: 0.000000398\n",
      "Iteration 31020, Loss: 0.000000360\n",
      "Iteration 31030, Loss: 0.000000442\n",
      "Iteration 31040, Loss: 0.000001477\n",
      "Iteration 31050, Loss: 0.000000769\n",
      "Iteration 31060, Loss: 0.000001219\n",
      "Iteration 31070, Loss: 0.000000404\n",
      "Iteration 31080, Loss: 0.000000423\n",
      "Iteration 31090, Loss: 0.000000403\n",
      "Iteration 31100, Loss: 0.000000361\n",
      "Iteration 31110, Loss: 0.000000373\n",
      "Iteration 31120, Loss: 0.000000488\n",
      "Iteration 31130, Loss: 0.000000744\n",
      "Iteration 31140, Loss: 0.000001676\n",
      "Iteration 31150, Loss: 0.000000583\n",
      "Iteration 31160, Loss: 0.000000411\n",
      "Iteration 31170, Loss: 0.000000369\n",
      "Iteration 31180, Loss: 0.000000365\n",
      "Iteration 31190, Loss: 0.000000372\n",
      "Iteration 31200, Loss: 0.000000442\n",
      "Iteration 31210, Loss: 0.000000530\n",
      "Iteration 31220, Loss: 0.000000885\n",
      "Iteration 31230, Loss: 0.000001151\n",
      "Iteration 31240, Loss: 0.000000445\n",
      "Iteration 31250, Loss: 0.000000466\n",
      "Iteration 31260, Loss: 0.000000365\n",
      "Iteration 31270, Loss: 0.000000382\n",
      "Iteration 31280, Loss: 0.000000420\n",
      "Iteration 31290, Loss: 0.000000799\n",
      "Iteration 31300, Loss: 0.000000847\n",
      "Iteration 31310, Loss: 0.000000614\n",
      "Iteration 31320, Loss: 0.000000549\n",
      "Iteration 31330, Loss: 0.000000474\n",
      "Iteration 31340, Loss: 0.000000440\n",
      "Iteration 31350, Loss: 0.000001041\n",
      "Iteration 31360, Loss: 0.000000458\n",
      "Iteration 31370, Loss: 0.000000455\n",
      "Iteration 31380, Loss: 0.000000402\n",
      "Iteration 31390, Loss: 0.000000373\n",
      "Iteration 31400, Loss: 0.000000396\n",
      "Iteration 31410, Loss: 0.000001985\n",
      "Iteration 31420, Loss: 0.000000970\n",
      "Iteration 31430, Loss: 0.000000812\n",
      "Iteration 31440, Loss: 0.000000404\n",
      "Iteration 31450, Loss: 0.000000387\n",
      "Iteration 31460, Loss: 0.000000374\n",
      "Iteration 31470, Loss: 0.000000367\n",
      "Iteration 31480, Loss: 0.000000422\n",
      "Iteration 31490, Loss: 0.000000938\n",
      "Iteration 31500, Loss: 0.000000728\n",
      "Iteration 31510, Loss: 0.000000455\n",
      "Iteration 31520, Loss: 0.000000391\n",
      "Iteration 31530, Loss: 0.000000375\n",
      "Iteration 31540, Loss: 0.000000362\n",
      "Iteration 31550, Loss: 0.000000356\n",
      "Iteration 31560, Loss: 0.000000356\n",
      "Iteration 31570, Loss: 0.000000360\n",
      "Iteration 31580, Loss: 0.000000499\n",
      "Iteration 31590, Loss: 0.000002645\n",
      "Iteration 31600, Loss: 0.000001140\n",
      "Iteration 31610, Loss: 0.000000469\n",
      "Iteration 31620, Loss: 0.000000373\n",
      "Iteration 31630, Loss: 0.000000391\n",
      "Iteration 31640, Loss: 0.000000408\n",
      "Iteration 31650, Loss: 0.000000881\n",
      "Iteration 31660, Loss: 0.000000511\n",
      "Iteration 31670, Loss: 0.000000439\n",
      "Iteration 31680, Loss: 0.000000390\n",
      "Iteration 31690, Loss: 0.000000386\n",
      "Iteration 31700, Loss: 0.000000364\n",
      "Iteration 31710, Loss: 0.000000381\n",
      "Iteration 31720, Loss: 0.000000549\n",
      "Iteration 31730, Loss: 0.000001292\n",
      "Iteration 31740, Loss: 0.000000534\n",
      "Iteration 31750, Loss: 0.000000481\n",
      "Iteration 31760, Loss: 0.000000415\n",
      "Iteration 31770, Loss: 0.000000381\n",
      "Iteration 31780, Loss: 0.000000401\n",
      "Iteration 31790, Loss: 0.000000984\n",
      "Iteration 31800, Loss: 0.000000548\n",
      "Iteration 31810, Loss: 0.000000401\n",
      "Iteration 31820, Loss: 0.000000404\n",
      "Iteration 31830, Loss: 0.000000413\n",
      "Iteration 31840, Loss: 0.000000639\n",
      "Iteration 31850, Loss: 0.000001070\n",
      "Iteration 31860, Loss: 0.000000507\n",
      "Iteration 31870, Loss: 0.000000359\n",
      "Iteration 31880, Loss: 0.000000402\n",
      "Iteration 31890, Loss: 0.000000380\n",
      "Iteration 31900, Loss: 0.000000466\n",
      "Iteration 31910, Loss: 0.000000872\n",
      "Iteration 31920, Loss: 0.000000489\n",
      "Iteration 31930, Loss: 0.000000658\n",
      "Iteration 31940, Loss: 0.000001113\n",
      "Iteration 31950, Loss: 0.000000482\n",
      "Iteration 31960, Loss: 0.000000377\n",
      "Iteration 31970, Loss: 0.000000404\n",
      "Iteration 31980, Loss: 0.000000499\n",
      "Iteration 31990, Loss: 0.000000462\n",
      "Iteration 32000, Loss: 0.000000550\n",
      "Iteration 32010, Loss: 0.000001908\n",
      "Iteration 32020, Loss: 0.000000762\n",
      "Iteration 32030, Loss: 0.000000461\n",
      "Iteration 32040, Loss: 0.000000387\n",
      "Iteration 32050, Loss: 0.000000369\n",
      "Iteration 32060, Loss: 0.000000365\n",
      "Iteration 32070, Loss: 0.000000521\n",
      "Iteration 32080, Loss: 0.000002701\n",
      "Iteration 32090, Loss: 0.000000954\n",
      "Iteration 32100, Loss: 0.000000422\n",
      "Iteration 32110, Loss: 0.000000422\n",
      "Iteration 32120, Loss: 0.000000381\n",
      "Iteration 32130, Loss: 0.000000360\n",
      "Iteration 32140, Loss: 0.000000357\n",
      "Iteration 32150, Loss: 0.000000369\n",
      "Iteration 32160, Loss: 0.000000600\n",
      "Iteration 32170, Loss: 0.000001043\n",
      "Iteration 32180, Loss: 0.000000601\n",
      "Iteration 32190, Loss: 0.000000498\n",
      "Iteration 32200, Loss: 0.000000520\n",
      "Iteration 32210, Loss: 0.000000727\n",
      "Iteration 32220, Loss: 0.000000466\n",
      "Iteration 32230, Loss: 0.000000393\n",
      "Iteration 32240, Loss: 0.000000430\n",
      "Iteration 32250, Loss: 0.000000466\n",
      "Iteration 32260, Loss: 0.000001020\n",
      "Iteration 32270, Loss: 0.000000476\n",
      "Iteration 32280, Loss: 0.000000480\n",
      "Iteration 32290, Loss: 0.000000412\n",
      "Iteration 32300, Loss: 0.000000382\n",
      "Iteration 32310, Loss: 0.000000421\n",
      "Iteration 32320, Loss: 0.000001038\n",
      "Iteration 32330, Loss: 0.000000501\n",
      "Iteration 32340, Loss: 0.000000458\n",
      "Iteration 32350, Loss: 0.000000399\n",
      "Iteration 32360, Loss: 0.000000403\n",
      "Iteration 32370, Loss: 0.000000460\n",
      "Iteration 32380, Loss: 0.000000632\n",
      "Iteration 32390, Loss: 0.000000602\n",
      "Iteration 32400, Loss: 0.000000683\n",
      "Iteration 32410, Loss: 0.000000470\n",
      "Iteration 32420, Loss: 0.000000407\n",
      "Iteration 32430, Loss: 0.000000369\n",
      "Iteration 32440, Loss: 0.000000561\n",
      "Iteration 32450, Loss: 0.000001954\n",
      "Iteration 32460, Loss: 0.000000916\n",
      "Iteration 32470, Loss: 0.000000586\n",
      "Iteration 32480, Loss: 0.000000507\n",
      "Iteration 32490, Loss: 0.000000596\n",
      "Iteration 32500, Loss: 0.000000423\n",
      "Iteration 32510, Loss: 0.000000381\n",
      "Iteration 32520, Loss: 0.000000395\n",
      "Iteration 32530, Loss: 0.000000420\n",
      "Iteration 32540, Loss: 0.000000652\n",
      "Iteration 32550, Loss: 0.000000805\n",
      "Iteration 32560, Loss: 0.000000480\n",
      "Iteration 32570, Loss: 0.000000698\n",
      "Iteration 32580, Loss: 0.000000766\n",
      "Iteration 32590, Loss: 0.000000402\n",
      "Iteration 32600, Loss: 0.000000416\n",
      "Iteration 32610, Loss: 0.000000356\n",
      "Iteration 32620, Loss: 0.000000378\n",
      "Iteration 32630, Loss: 0.000000711\n",
      "Iteration 32640, Loss: 0.000001136\n",
      "Iteration 32650, Loss: 0.000000412\n",
      "Iteration 32660, Loss: 0.000000532\n",
      "Iteration 32670, Loss: 0.000000616\n",
      "Iteration 32680, Loss: 0.000000575\n",
      "Iteration 32690, Loss: 0.000000379\n",
      "Iteration 32700, Loss: 0.000000451\n",
      "Iteration 32710, Loss: 0.000000464\n",
      "Iteration 32720, Loss: 0.000000521\n",
      "Iteration 32730, Loss: 0.000001065\n",
      "Iteration 32740, Loss: 0.000000362\n",
      "Iteration 32750, Loss: 0.000000436\n",
      "Iteration 32760, Loss: 0.000000413\n",
      "Iteration 32770, Loss: 0.000000370\n",
      "Iteration 32780, Loss: 0.000000389\n",
      "Iteration 32790, Loss: 0.000000936\n",
      "Iteration 32800, Loss: 0.000001256\n",
      "Iteration 32810, Loss: 0.000000672\n",
      "Iteration 32820, Loss: 0.000000480\n",
      "Iteration 32830, Loss: 0.000000390\n",
      "Iteration 32840, Loss: 0.000000363\n",
      "Iteration 32850, Loss: 0.000000364\n",
      "Iteration 32860, Loss: 0.000000396\n",
      "Iteration 32870, Loss: 0.000001174\n",
      "Iteration 32880, Loss: 0.000000570\n",
      "Iteration 32890, Loss: 0.000000476\n",
      "Iteration 32900, Loss: 0.000000480\n",
      "Iteration 32910, Loss: 0.000000842\n",
      "Iteration 32920, Loss: 0.000000578\n",
      "Iteration 32930, Loss: 0.000000508\n",
      "Iteration 32940, Loss: 0.000000359\n",
      "Iteration 32950, Loss: 0.000000401\n",
      "Iteration 32960, Loss: 0.000000416\n",
      "Iteration 32970, Loss: 0.000000385\n",
      "Iteration 32980, Loss: 0.000000703\n",
      "Iteration 32990, Loss: 0.000001581\n",
      "Iteration 33000, Loss: 0.000000609\n",
      "Iteration 33010, Loss: 0.000000417\n",
      "Iteration 33020, Loss: 0.000000374\n",
      "Iteration 33030, Loss: 0.000000371\n",
      "Iteration 33040, Loss: 0.000000362\n",
      "Iteration 33050, Loss: 0.000000534\n",
      "Iteration 33060, Loss: 0.000001136\n",
      "Iteration 33070, Loss: 0.000000564\n",
      "Iteration 33080, Loss: 0.000000420\n",
      "Iteration 33090, Loss: 0.000000383\n",
      "Iteration 33100, Loss: 0.000000360\n",
      "Iteration 33110, Loss: 0.000000472\n",
      "Iteration 33120, Loss: 0.000002867\n",
      "Iteration 33130, Loss: 0.000000945\n",
      "Iteration 33140, Loss: 0.000000462\n",
      "Iteration 33150, Loss: 0.000000393\n",
      "Iteration 33160, Loss: 0.000000367\n",
      "Iteration 33170, Loss: 0.000000362\n",
      "Iteration 33180, Loss: 0.000000355\n",
      "Iteration 33190, Loss: 0.000000353\n",
      "Iteration 33200, Loss: 0.000000352\n",
      "Iteration 33210, Loss: 0.000000357\n",
      "Iteration 33220, Loss: 0.000000537\n",
      "Iteration 33230, Loss: 0.000000970\n",
      "Iteration 33240, Loss: 0.000000675\n",
      "Iteration 33250, Loss: 0.000000422\n",
      "Iteration 33260, Loss: 0.000000418\n",
      "Iteration 33270, Loss: 0.000000407\n",
      "Iteration 33280, Loss: 0.000000443\n",
      "Iteration 33290, Loss: 0.000000832\n",
      "Iteration 33300, Loss: 0.000000594\n",
      "Iteration 33310, Loss: 0.000000522\n",
      "Iteration 33320, Loss: 0.000000362\n",
      "Iteration 33330, Loss: 0.000000383\n",
      "Iteration 33340, Loss: 0.000000353\n",
      "Iteration 33350, Loss: 0.000000367\n",
      "Iteration 33360, Loss: 0.000000656\n",
      "Iteration 33370, Loss: 0.000001969\n",
      "Iteration 33380, Loss: 0.000000880\n",
      "Iteration 33390, Loss: 0.000000542\n",
      "Iteration 33400, Loss: 0.000000414\n",
      "Iteration 33410, Loss: 0.000000365\n",
      "Iteration 33420, Loss: 0.000000368\n",
      "Iteration 33430, Loss: 0.000000448\n",
      "Iteration 33440, Loss: 0.000001835\n",
      "Iteration 33450, Loss: 0.000000686\n",
      "Iteration 33460, Loss: 0.000000547\n",
      "Iteration 33470, Loss: 0.000000438\n",
      "Iteration 33480, Loss: 0.000000385\n",
      "Iteration 33490, Loss: 0.000000363\n",
      "Iteration 33500, Loss: 0.000000352\n",
      "Iteration 33510, Loss: 0.000000354\n",
      "Iteration 33520, Loss: 0.000000407\n",
      "Iteration 33530, Loss: 0.000000409\n",
      "Iteration 33540, Loss: 0.000000900\n",
      "Iteration 33550, Loss: 0.000000846\n",
      "Iteration 33560, Loss: 0.000000524\n",
      "Iteration 33570, Loss: 0.000000454\n",
      "Iteration 33580, Loss: 0.000000361\n",
      "Iteration 33590, Loss: 0.000000372\n",
      "Iteration 33600, Loss: 0.000000402\n",
      "Iteration 33610, Loss: 0.000000856\n",
      "Iteration 33620, Loss: 0.000000770\n",
      "Iteration 33630, Loss: 0.000000573\n",
      "Iteration 33640, Loss: 0.000000454\n",
      "Iteration 33650, Loss: 0.000000389\n",
      "Iteration 33660, Loss: 0.000000403\n",
      "Iteration 33670, Loss: 0.000000965\n",
      "Iteration 33680, Loss: 0.000000691\n",
      "Iteration 33690, Loss: 0.000000421\n",
      "Iteration 33700, Loss: 0.000000383\n",
      "Iteration 33710, Loss: 0.000000408\n",
      "Iteration 33720, Loss: 0.000000890\n",
      "Iteration 33730, Loss: 0.000000807\n",
      "Iteration 33740, Loss: 0.000000650\n",
      "Iteration 33750, Loss: 0.000000441\n",
      "Iteration 33760, Loss: 0.000000406\n",
      "Iteration 33770, Loss: 0.000000386\n",
      "Iteration 33780, Loss: 0.000000401\n",
      "Iteration 33790, Loss: 0.000000746\n",
      "Iteration 33800, Loss: 0.000000405\n",
      "Iteration 33810, Loss: 0.000000411\n",
      "Iteration 33820, Loss: 0.000000421\n",
      "Iteration 33830, Loss: 0.000000648\n",
      "Iteration 33840, Loss: 0.000001023\n",
      "Iteration 33850, Loss: 0.000000823\n",
      "Iteration 33860, Loss: 0.000000546\n",
      "Iteration 33870, Loss: 0.000000360\n",
      "Iteration 33880, Loss: 0.000000368\n",
      "Iteration 33890, Loss: 0.000000351\n",
      "Iteration 33900, Loss: 0.000000355\n",
      "Iteration 33910, Loss: 0.000000392\n",
      "Iteration 33920, Loss: 0.000001212\n",
      "Iteration 33930, Loss: 0.000000402\n",
      "Iteration 33940, Loss: 0.000000470\n",
      "Iteration 33950, Loss: 0.000000479\n",
      "Iteration 33960, Loss: 0.000000407\n",
      "Iteration 33970, Loss: 0.000000462\n",
      "Iteration 33980, Loss: 0.000000443\n",
      "Iteration 33990, Loss: 0.000000379\n",
      "Iteration 34000, Loss: 0.000000483\n",
      "Iteration 34010, Loss: 0.000001638\n",
      "Iteration 34020, Loss: 0.000000674\n",
      "Iteration 34030, Loss: 0.000000385\n",
      "Iteration 34040, Loss: 0.000000388\n",
      "Iteration 34050, Loss: 0.000000370\n",
      "Iteration 34060, Loss: 0.000000379\n",
      "Iteration 34070, Loss: 0.000001051\n",
      "Iteration 34080, Loss: 0.000000537\n",
      "Iteration 34090, Loss: 0.000000431\n",
      "Iteration 34100, Loss: 0.000000432\n",
      "Iteration 34110, Loss: 0.000000400\n",
      "Iteration 34120, Loss: 0.000000364\n",
      "Iteration 34130, Loss: 0.000000355\n",
      "Iteration 34140, Loss: 0.000000352\n",
      "Iteration 34150, Loss: 0.000000363\n",
      "Iteration 34160, Loss: 0.000000745\n",
      "Iteration 34170, Loss: 0.000000871\n",
      "Iteration 34180, Loss: 0.000000533\n",
      "Iteration 34190, Loss: 0.000000502\n",
      "Iteration 34200, Loss: 0.000000368\n",
      "Iteration 34210, Loss: 0.000000374\n",
      "Iteration 34220, Loss: 0.000000394\n",
      "Iteration 34230, Loss: 0.000000631\n",
      "Iteration 34240, Loss: 0.000001031\n",
      "Iteration 34250, Loss: 0.000000506\n",
      "Iteration 34260, Loss: 0.000000374\n",
      "Iteration 34270, Loss: 0.000000459\n",
      "Iteration 34280, Loss: 0.000000878\n",
      "Iteration 34290, Loss: 0.000000515\n",
      "Iteration 34300, Loss: 0.000000386\n",
      "Iteration 34310, Loss: 0.000000421\n",
      "Iteration 34320, Loss: 0.000000438\n",
      "Iteration 34330, Loss: 0.000000482\n",
      "Iteration 34340, Loss: 0.000000897\n",
      "Iteration 34350, Loss: 0.000000909\n",
      "Iteration 34360, Loss: 0.000000562\n",
      "Iteration 34370, Loss: 0.000000392\n",
      "Iteration 34380, Loss: 0.000000371\n",
      "Iteration 34390, Loss: 0.000000377\n",
      "Iteration 34400, Loss: 0.000000541\n",
      "Iteration 34410, Loss: 0.000001015\n",
      "Iteration 34420, Loss: 0.000000546\n",
      "Iteration 34430, Loss: 0.000000411\n",
      "Iteration 34440, Loss: 0.000000457\n",
      "Iteration 34450, Loss: 0.000001827\n",
      "Iteration 34460, Loss: 0.000000737\n",
      "Iteration 34470, Loss: 0.000000536\n",
      "Iteration 34480, Loss: 0.000000439\n",
      "Iteration 34490, Loss: 0.000000383\n",
      "Iteration 34500, Loss: 0.000000360\n",
      "Iteration 34510, Loss: 0.000000356\n",
      "Iteration 34520, Loss: 0.000000481\n",
      "Iteration 34530, Loss: 0.000000685\n",
      "Iteration 34540, Loss: 0.000000685\n",
      "Iteration 34550, Loss: 0.000000391\n",
      "Iteration 34560, Loss: 0.000000394\n",
      "Iteration 34570, Loss: 0.000000400\n",
      "Iteration 34580, Loss: 0.000001004\n",
      "Iteration 34590, Loss: 0.000000611\n",
      "Iteration 34600, Loss: 0.000000411\n",
      "Iteration 34610, Loss: 0.000000379\n",
      "Iteration 34620, Loss: 0.000000365\n",
      "Iteration 34630, Loss: 0.000000396\n",
      "Iteration 34640, Loss: 0.000001255\n",
      "Iteration 34650, Loss: 0.000000549\n",
      "Iteration 34660, Loss: 0.000000484\n",
      "Iteration 34670, Loss: 0.000000391\n",
      "Iteration 34680, Loss: 0.000000356\n",
      "Iteration 34690, Loss: 0.000000350\n",
      "Iteration 34700, Loss: 0.000000366\n",
      "Iteration 34710, Loss: 0.000000853\n",
      "Iteration 34720, Loss: 0.000000728\n",
      "Iteration 34730, Loss: 0.000001226\n",
      "Iteration 34740, Loss: 0.000000514\n",
      "Iteration 34750, Loss: 0.000000394\n",
      "Iteration 34760, Loss: 0.000000501\n",
      "Iteration 34770, Loss: 0.000000351\n",
      "Iteration 34780, Loss: 0.000000401\n",
      "Iteration 34790, Loss: 0.000000384\n",
      "Iteration 34800, Loss: 0.000000362\n",
      "Iteration 34810, Loss: 0.000000375\n",
      "Iteration 34820, Loss: 0.000000688\n",
      "Iteration 34830, Loss: 0.000001447\n",
      "Iteration 34840, Loss: 0.000000728\n",
      "Iteration 34850, Loss: 0.000000586\n",
      "Iteration 34860, Loss: 0.000000762\n",
      "Iteration 34870, Loss: 0.000000417\n",
      "Iteration 34880, Loss: 0.000000437\n",
      "Iteration 34890, Loss: 0.000000382\n",
      "Iteration 34900, Loss: 0.000000367\n",
      "Iteration 34910, Loss: 0.000000399\n",
      "Iteration 34920, Loss: 0.000000863\n",
      "Iteration 34930, Loss: 0.000000571\n",
      "Iteration 34940, Loss: 0.000000382\n",
      "Iteration 34950, Loss: 0.000000383\n",
      "Iteration 34960, Loss: 0.000000371\n",
      "Iteration 34970, Loss: 0.000000371\n",
      "Iteration 34980, Loss: 0.000000595\n",
      "Iteration 34990, Loss: 0.000002259\n",
      "Iteration 35000, Loss: 0.000000581\n",
      "Iteration 35010, Loss: 0.000000523\n",
      "Iteration 35020, Loss: 0.000000368\n",
      "Iteration 35030, Loss: 0.000000372\n",
      "Iteration 35040, Loss: 0.000000351\n",
      "Iteration 35050, Loss: 0.000000354\n",
      "Iteration 35060, Loss: 0.000000372\n",
      "Iteration 35070, Loss: 0.000000542\n",
      "Iteration 35080, Loss: 0.000001464\n",
      "Iteration 35090, Loss: 0.000000416\n",
      "Iteration 35100, Loss: 0.000000438\n",
      "Iteration 35110, Loss: 0.000000409\n",
      "Iteration 35120, Loss: 0.000000384\n",
      "Iteration 35130, Loss: 0.000000363\n",
      "Iteration 35140, Loss: 0.000000352\n",
      "Iteration 35150, Loss: 0.000000348\n",
      "Iteration 35160, Loss: 0.000000350\n",
      "Iteration 35170, Loss: 0.000000407\n",
      "Iteration 35180, Loss: 0.000001389\n",
      "Iteration 35190, Loss: 0.000000943\n",
      "Iteration 35200, Loss: 0.000000425\n",
      "Iteration 35210, Loss: 0.000000454\n",
      "Iteration 35220, Loss: 0.000000377\n",
      "Iteration 35230, Loss: 0.000000356\n",
      "Iteration 35240, Loss: 0.000000353\n",
      "Iteration 35250, Loss: 0.000000412\n",
      "Iteration 35260, Loss: 0.000001786\n",
      "Iteration 35270, Loss: 0.000001098\n",
      "Iteration 35280, Loss: 0.000000465\n",
      "Iteration 35290, Loss: 0.000000414\n",
      "Iteration 35300, Loss: 0.000000369\n",
      "Iteration 35310, Loss: 0.000000360\n",
      "Iteration 35320, Loss: 0.000000350\n",
      "Iteration 35330, Loss: 0.000000348\n",
      "Iteration 35340, Loss: 0.000000353\n",
      "Iteration 35350, Loss: 0.000000653\n",
      "Iteration 35360, Loss: 0.000001479\n",
      "Iteration 35370, Loss: 0.000000879\n",
      "Iteration 35380, Loss: 0.000000448\n",
      "Iteration 35390, Loss: 0.000000409\n",
      "Iteration 35400, Loss: 0.000000364\n",
      "Iteration 35410, Loss: 0.000000352\n",
      "Iteration 35420, Loss: 0.000000350\n",
      "Iteration 35430, Loss: 0.000000348\n",
      "Iteration 35440, Loss: 0.000000347\n",
      "Iteration 35450, Loss: 0.000000348\n",
      "Iteration 35460, Loss: 0.000000460\n",
      "Iteration 35470, Loss: 0.000004586\n",
      "Iteration 35480, Loss: 0.000000507\n",
      "Iteration 35490, Loss: 0.000000858\n",
      "Iteration 35500, Loss: 0.000000408\n",
      "Iteration 35510, Loss: 0.000000409\n",
      "Iteration 35520, Loss: 0.000000362\n",
      "Iteration 35530, Loss: 0.000000350\n",
      "Iteration 35540, Loss: 0.000000350\n",
      "Iteration 35550, Loss: 0.000000347\n",
      "Iteration 35560, Loss: 0.000000347\n",
      "Iteration 35570, Loss: 0.000000347\n",
      "Iteration 35580, Loss: 0.000000347\n",
      "Iteration 35590, Loss: 0.000000347\n",
      "Iteration 35600, Loss: 0.000000369\n",
      "Iteration 35610, Loss: 0.000002064\n",
      "Iteration 35620, Loss: 0.000000677\n",
      "Iteration 35630, Loss: 0.000000546\n",
      "Iteration 35640, Loss: 0.000000427\n",
      "Iteration 35650, Loss: 0.000000362\n",
      "Iteration 35660, Loss: 0.000000347\n",
      "Iteration 35670, Loss: 0.000000349\n",
      "Iteration 35680, Loss: 0.000000349\n",
      "Iteration 35690, Loss: 0.000000395\n",
      "Iteration 35700, Loss: 0.000002035\n",
      "Iteration 35710, Loss: 0.000000929\n",
      "Iteration 35720, Loss: 0.000000688\n",
      "Iteration 35730, Loss: 0.000000369\n",
      "Iteration 35740, Loss: 0.000000357\n",
      "Iteration 35750, Loss: 0.000000358\n",
      "Iteration 35760, Loss: 0.000000353\n",
      "Iteration 35770, Loss: 0.000000367\n",
      "Iteration 35780, Loss: 0.000001018\n",
      "Iteration 35790, Loss: 0.000000759\n",
      "Iteration 35800, Loss: 0.000000599\n",
      "Iteration 35810, Loss: 0.000000399\n",
      "Iteration 35820, Loss: 0.000000360\n",
      "Iteration 35830, Loss: 0.000000357\n",
      "Iteration 35840, Loss: 0.000000350\n",
      "Iteration 35850, Loss: 0.000000350\n",
      "Iteration 35860, Loss: 0.000000373\n",
      "Iteration 35870, Loss: 0.000000890\n",
      "Iteration 35880, Loss: 0.000000756\n",
      "Iteration 35890, Loss: 0.000000386\n",
      "Iteration 35900, Loss: 0.000000363\n",
      "Iteration 35910, Loss: 0.000000373\n",
      "Iteration 35920, Loss: 0.000000361\n",
      "Iteration 35930, Loss: 0.000000391\n",
      "Iteration 35940, Loss: 0.000001608\n",
      "Iteration 35950, Loss: 0.000000842\n",
      "Iteration 35960, Loss: 0.000000425\n",
      "Iteration 35970, Loss: 0.000000373\n",
      "Iteration 35980, Loss: 0.000000365\n",
      "Iteration 35990, Loss: 0.000000353\n",
      "Iteration 36000, Loss: 0.000000416\n",
      "Iteration 36010, Loss: 0.000000418\n",
      "Iteration 36020, Loss: 0.000000567\n",
      "Iteration 36030, Loss: 0.000003029\n",
      "Iteration 36040, Loss: 0.000001347\n",
      "Iteration 36050, Loss: 0.000000371\n",
      "Iteration 36060, Loss: 0.000000444\n",
      "Iteration 36070, Loss: 0.000000373\n",
      "Iteration 36080, Loss: 0.000000348\n",
      "Iteration 36090, Loss: 0.000000348\n",
      "Iteration 36100, Loss: 0.000000347\n",
      "Iteration 36110, Loss: 0.000000346\n",
      "Iteration 36120, Loss: 0.000000349\n",
      "Iteration 36130, Loss: 0.000000450\n",
      "Iteration 36140, Loss: 0.000001062\n",
      "Iteration 36150, Loss: 0.000000436\n",
      "Iteration 36160, Loss: 0.000000442\n",
      "Iteration 36170, Loss: 0.000000356\n",
      "Iteration 36180, Loss: 0.000000358\n",
      "Iteration 36190, Loss: 0.000000366\n",
      "Iteration 36200, Loss: 0.000000555\n",
      "Iteration 36210, Loss: 0.000002332\n",
      "Iteration 36220, Loss: 0.000000664\n",
      "Iteration 36230, Loss: 0.000000582\n",
      "Iteration 36240, Loss: 0.000000394\n",
      "Iteration 36250, Loss: 0.000000375\n",
      "Iteration 36260, Loss: 0.000000355\n",
      "Iteration 36270, Loss: 0.000000347\n",
      "Iteration 36280, Loss: 0.000000348\n",
      "Iteration 36290, Loss: 0.000000347\n",
      "Iteration 36300, Loss: 0.000000359\n",
      "Iteration 36310, Loss: 0.000000725\n",
      "Iteration 36320, Loss: 0.000001380\n",
      "Iteration 36330, Loss: 0.000000426\n",
      "Iteration 36340, Loss: 0.000000396\n",
      "Iteration 36350, Loss: 0.000000396\n",
      "Iteration 36360, Loss: 0.000000365\n",
      "Iteration 36370, Loss: 0.000000352\n",
      "Iteration 36380, Loss: 0.000000348\n",
      "Iteration 36390, Loss: 0.000000346\n",
      "Iteration 36400, Loss: 0.000000353\n",
      "Iteration 36410, Loss: 0.000000740\n",
      "Iteration 36420, Loss: 0.000001032\n",
      "Iteration 36430, Loss: 0.000000684\n",
      "Iteration 36440, Loss: 0.000000409\n",
      "Iteration 36450, Loss: 0.000000390\n",
      "Iteration 36460, Loss: 0.000000358\n",
      "Iteration 36470, Loss: 0.000000357\n",
      "Iteration 36480, Loss: 0.000000412\n",
      "Iteration 36490, Loss: 0.000001385\n",
      "Iteration 36500, Loss: 0.000000379\n",
      "Iteration 36510, Loss: 0.000000365\n",
      "Iteration 36520, Loss: 0.000000355\n",
      "Iteration 36530, Loss: 0.000000347\n",
      "Iteration 36540, Loss: 0.000000350\n",
      "Iteration 36550, Loss: 0.000000355\n",
      "Iteration 36560, Loss: 0.000000432\n",
      "Iteration 36570, Loss: 0.000001006\n",
      "Iteration 36580, Loss: 0.000000458\n",
      "Iteration 36590, Loss: 0.000000401\n",
      "Iteration 36600, Loss: 0.000000684\n",
      "Iteration 36610, Loss: 0.000001255\n",
      "Iteration 36620, Loss: 0.000000662\n",
      "Iteration 36630, Loss: 0.000000441\n",
      "Iteration 36640, Loss: 0.000000366\n",
      "Iteration 36650, Loss: 0.000000353\n",
      "Iteration 36660, Loss: 0.000000374\n",
      "Iteration 36670, Loss: 0.000000858\n",
      "Iteration 36680, Loss: 0.000000507\n",
      "Iteration 36690, Loss: 0.000000474\n",
      "Iteration 36700, Loss: 0.000000407\n",
      "Iteration 36710, Loss: 0.000000373\n",
      "Iteration 36720, Loss: 0.000000402\n",
      "Iteration 36730, Loss: 0.000001242\n",
      "Iteration 36740, Loss: 0.000000387\n",
      "Iteration 36750, Loss: 0.000000384\n",
      "Iteration 36760, Loss: 0.000000367\n",
      "Iteration 36770, Loss: 0.000000356\n",
      "Iteration 36780, Loss: 0.000000347\n",
      "Iteration 36790, Loss: 0.000000348\n",
      "Iteration 36800, Loss: 0.000000449\n",
      "Iteration 36810, Loss: 0.000001202\n",
      "Iteration 36820, Loss: 0.000000429\n",
      "Iteration 36830, Loss: 0.000000463\n",
      "Iteration 36840, Loss: 0.000000362\n",
      "Iteration 36850, Loss: 0.000000366\n",
      "Iteration 36860, Loss: 0.000000477\n",
      "Iteration 36870, Loss: 0.000001374\n",
      "Iteration 36880, Loss: 0.000001175\n",
      "Iteration 36890, Loss: 0.000000511\n",
      "Iteration 36900, Loss: 0.000000567\n",
      "Iteration 36910, Loss: 0.000000404\n",
      "Iteration 36920, Loss: 0.000000353\n",
      "Iteration 36930, Loss: 0.000000363\n",
      "Iteration 36940, Loss: 0.000000379\n",
      "Iteration 36950, Loss: 0.000000380\n",
      "Iteration 36960, Loss: 0.000000353\n",
      "Iteration 36970, Loss: 0.000000632\n",
      "Iteration 36980, Loss: 0.000002216\n",
      "Iteration 36990, Loss: 0.000000401\n",
      "Iteration 37000, Loss: 0.000000635\n",
      "Iteration 37010, Loss: 0.000000353\n",
      "Iteration 37020, Loss: 0.000000380\n",
      "Iteration 37030, Loss: 0.000000349\n",
      "Iteration 37040, Loss: 0.000000363\n",
      "Iteration 37050, Loss: 0.000000811\n",
      "Iteration 37060, Loss: 0.000000427\n",
      "Iteration 37070, Loss: 0.000000454\n",
      "Iteration 37080, Loss: 0.000000381\n",
      "Iteration 37090, Loss: 0.000000349\n",
      "Iteration 37100, Loss: 0.000000347\n",
      "Iteration 37110, Loss: 0.000000363\n",
      "Iteration 37120, Loss: 0.000000665\n",
      "Iteration 37130, Loss: 0.000000551\n",
      "Iteration 37140, Loss: 0.000000411\n",
      "Iteration 37150, Loss: 0.000000383\n",
      "Iteration 37160, Loss: 0.000000434\n",
      "Iteration 37170, Loss: 0.000000636\n",
      "Iteration 37180, Loss: 0.000000589\n",
      "Iteration 37190, Loss: 0.000001613\n",
      "Iteration 37200, Loss: 0.000000707\n",
      "Iteration 37210, Loss: 0.000000475\n",
      "Iteration 37220, Loss: 0.000000387\n",
      "Iteration 37230, Loss: 0.000000352\n",
      "Iteration 37240, Loss: 0.000000348\n",
      "Iteration 37250, Loss: 0.000000347\n",
      "Iteration 37260, Loss: 0.000000365\n",
      "Iteration 37270, Loss: 0.000001254\n",
      "Iteration 37280, Loss: 0.000000749\n",
      "Iteration 37290, Loss: 0.000000673\n",
      "Iteration 37300, Loss: 0.000000365\n",
      "Iteration 37310, Loss: 0.000000388\n",
      "Iteration 37320, Loss: 0.000000453\n",
      "Iteration 37330, Loss: 0.000001237\n",
      "Iteration 37340, Loss: 0.000000350\n",
      "Iteration 37350, Loss: 0.000000369\n",
      "Iteration 37360, Loss: 0.000000393\n",
      "Iteration 37370, Loss: 0.000000375\n",
      "Iteration 37380, Loss: 0.000000392\n",
      "Iteration 37390, Loss: 0.000001137\n",
      "Iteration 37400, Loss: 0.000000589\n",
      "Iteration 37410, Loss: 0.000000432\n",
      "Iteration 37420, Loss: 0.000000370\n",
      "Iteration 37430, Loss: 0.000000374\n",
      "Iteration 37440, Loss: 0.000001010\n",
      "Iteration 37450, Loss: 0.000000532\n",
      "Iteration 37460, Loss: 0.000000435\n",
      "Iteration 37470, Loss: 0.000000432\n",
      "Iteration 37480, Loss: 0.000000400\n",
      "Iteration 37490, Loss: 0.000000359\n",
      "Iteration 37500, Loss: 0.000000370\n",
      "Iteration 37510, Loss: 0.000000717\n",
      "Iteration 37520, Loss: 0.000000486\n",
      "Iteration 37530, Loss: 0.000000392\n",
      "Iteration 37540, Loss: 0.000000384\n",
      "Iteration 37550, Loss: 0.000000372\n",
      "Iteration 37560, Loss: 0.000000360\n",
      "Iteration 37570, Loss: 0.000000455\n",
      "Iteration 37580, Loss: 0.000001413\n",
      "Iteration 37590, Loss: 0.000000468\n",
      "Iteration 37600, Loss: 0.000000397\n",
      "Iteration 37610, Loss: 0.000000430\n",
      "Iteration 37620, Loss: 0.000000689\n",
      "Iteration 37630, Loss: 0.000000509\n",
      "Iteration 37640, Loss: 0.000000411\n",
      "Iteration 37650, Loss: 0.000000455\n",
      "Iteration 37660, Loss: 0.000000476\n",
      "Iteration 37670, Loss: 0.000000402\n",
      "Iteration 37680, Loss: 0.000000794\n",
      "Iteration 37690, Loss: 0.000000988\n",
      "Iteration 37700, Loss: 0.000000593\n",
      "Iteration 37710, Loss: 0.000000433\n",
      "Iteration 37720, Loss: 0.000000376\n",
      "Iteration 37730, Loss: 0.000000364\n",
      "Iteration 37740, Loss: 0.000000365\n",
      "Iteration 37750, Loss: 0.000000658\n",
      "Iteration 37760, Loss: 0.000000698\n",
      "Iteration 37770, Loss: 0.000000793\n",
      "Iteration 37780, Loss: 0.000000480\n",
      "Iteration 37790, Loss: 0.000000440\n",
      "Iteration 37800, Loss: 0.000000368\n",
      "Iteration 37810, Loss: 0.000000352\n",
      "Iteration 37820, Loss: 0.000000359\n",
      "Iteration 37830, Loss: 0.000000584\n",
      "Iteration 37840, Loss: 0.000001842\n",
      "Iteration 37850, Loss: 0.000000904\n",
      "Iteration 37860, Loss: 0.000000565\n",
      "Iteration 37870, Loss: 0.000000429\n",
      "Iteration 37880, Loss: 0.000000373\n",
      "Iteration 37890, Loss: 0.000000382\n",
      "Iteration 37900, Loss: 0.000000669\n",
      "Iteration 37910, Loss: 0.000000478\n",
      "Iteration 37920, Loss: 0.000000479\n",
      "Iteration 37930, Loss: 0.000000401\n",
      "Iteration 37940, Loss: 0.000000363\n",
      "Iteration 37950, Loss: 0.000000353\n",
      "Iteration 37960, Loss: 0.000000398\n",
      "Iteration 37970, Loss: 0.000001786\n",
      "Iteration 37980, Loss: 0.000000674\n",
      "Iteration 37990, Loss: 0.000000648\n",
      "Iteration 38000, Loss: 0.000000476\n",
      "Iteration 38010, Loss: 0.000000464\n",
      "Iteration 38020, Loss: 0.000000587\n",
      "Iteration 38030, Loss: 0.000000399\n",
      "Iteration 38040, Loss: 0.000000357\n",
      "Iteration 38050, Loss: 0.000000363\n",
      "Iteration 38060, Loss: 0.000000402\n",
      "Iteration 38070, Loss: 0.000000861\n",
      "Iteration 38080, Loss: 0.000000476\n",
      "Iteration 38090, Loss: 0.000000726\n",
      "Iteration 38100, Loss: 0.000000437\n",
      "Iteration 38110, Loss: 0.000000425\n",
      "Iteration 38120, Loss: 0.000000537\n",
      "Iteration 38130, Loss: 0.000001399\n",
      "Iteration 38140, Loss: 0.000000548\n",
      "Iteration 38150, Loss: 0.000000371\n",
      "Iteration 38160, Loss: 0.000000355\n",
      "Iteration 38170, Loss: 0.000000365\n",
      "Iteration 38180, Loss: 0.000000365\n",
      "Iteration 38190, Loss: 0.000000748\n",
      "Iteration 38200, Loss: 0.000000551\n",
      "Iteration 38210, Loss: 0.000000578\n",
      "Iteration 38220, Loss: 0.000000579\n",
      "Iteration 38230, Loss: 0.000000456\n",
      "Iteration 38240, Loss: 0.000000406\n",
      "Iteration 38250, Loss: 0.000000521\n",
      "Iteration 38260, Loss: 0.000000960\n",
      "Iteration 38270, Loss: 0.000000420\n",
      "Iteration 38280, Loss: 0.000000553\n",
      "Iteration 38290, Loss: 0.000000554\n",
      "Iteration 38300, Loss: 0.000000564\n",
      "Iteration 38310, Loss: 0.000000490\n",
      "Iteration 38320, Loss: 0.000000472\n",
      "Iteration 38330, Loss: 0.000000390\n",
      "Iteration 38340, Loss: 0.000000483\n",
      "Iteration 38350, Loss: 0.000001613\n",
      "Iteration 38360, Loss: 0.000000724\n",
      "Iteration 38370, Loss: 0.000000450\n",
      "Iteration 38380, Loss: 0.000000379\n",
      "Iteration 38390, Loss: 0.000000351\n",
      "Iteration 38400, Loss: 0.000000372\n",
      "Iteration 38410, Loss: 0.000000942\n",
      "Iteration 38420, Loss: 0.000000416\n",
      "Iteration 38430, Loss: 0.000000403\n",
      "Iteration 38440, Loss: 0.000000415\n",
      "Iteration 38450, Loss: 0.000000393\n",
      "Iteration 38460, Loss: 0.000000633\n",
      "Iteration 38470, Loss: 0.000001379\n",
      "Iteration 38480, Loss: 0.000000485\n",
      "Iteration 38490, Loss: 0.000000461\n",
      "Iteration 38500, Loss: 0.000000438\n",
      "Iteration 38510, Loss: 0.000000373\n",
      "Iteration 38520, Loss: 0.000000352\n",
      "Iteration 38530, Loss: 0.000000370\n",
      "Iteration 38540, Loss: 0.000000578\n",
      "Iteration 38550, Loss: 0.000000644\n",
      "Iteration 38560, Loss: 0.000000549\n",
      "Iteration 38570, Loss: 0.000000416\n",
      "Iteration 38580, Loss: 0.000000354\n",
      "Iteration 38590, Loss: 0.000000362\n",
      "Iteration 38600, Loss: 0.000000428\n",
      "Iteration 38610, Loss: 0.000001934\n",
      "Iteration 38620, Loss: 0.000000856\n",
      "Iteration 38630, Loss: 0.000000675\n",
      "Iteration 38640, Loss: 0.000000442\n",
      "Iteration 38650, Loss: 0.000000432\n",
      "Iteration 38660, Loss: 0.000000796\n",
      "Iteration 38670, Loss: 0.000000375\n",
      "Iteration 38680, Loss: 0.000000407\n",
      "Iteration 38690, Loss: 0.000000370\n",
      "Iteration 38700, Loss: 0.000000352\n",
      "Iteration 38710, Loss: 0.000000435\n",
      "Iteration 38720, Loss: 0.000000366\n",
      "Iteration 38730, Loss: 0.000000456\n",
      "Iteration 38740, Loss: 0.000001291\n",
      "Iteration 38750, Loss: 0.000001218\n",
      "Iteration 38760, Loss: 0.000000575\n",
      "Iteration 38770, Loss: 0.000000435\n",
      "Iteration 38780, Loss: 0.000000388\n",
      "Iteration 38790, Loss: 0.000000348\n",
      "Iteration 38800, Loss: 0.000000344\n",
      "Iteration 38810, Loss: 0.000000341\n",
      "Iteration 38820, Loss: 0.000000353\n",
      "Iteration 38830, Loss: 0.000000832\n",
      "Iteration 38840, Loss: 0.000001052\n",
      "Iteration 38850, Loss: 0.000000762\n",
      "Iteration 38860, Loss: 0.000000402\n",
      "Iteration 38870, Loss: 0.000000392\n",
      "Iteration 38880, Loss: 0.000000353\n",
      "Iteration 38890, Loss: 0.000000347\n",
      "Iteration 38900, Loss: 0.000000344\n",
      "Iteration 38910, Loss: 0.000000368\n",
      "Iteration 38920, Loss: 0.000000761\n",
      "Iteration 38930, Loss: 0.000001695\n",
      "Iteration 38940, Loss: 0.000000547\n",
      "Iteration 38950, Loss: 0.000000389\n",
      "Iteration 38960, Loss: 0.000000363\n",
      "Iteration 38970, Loss: 0.000000359\n",
      "Iteration 38980, Loss: 0.000000347\n",
      "Iteration 38990, Loss: 0.000000343\n",
      "Iteration 39000, Loss: 0.000000344\n",
      "Iteration 39010, Loss: 0.000000429\n",
      "Iteration 39020, Loss: 0.000000868\n",
      "Iteration 39030, Loss: 0.000000466\n",
      "Iteration 39040, Loss: 0.000000384\n",
      "Iteration 39050, Loss: 0.000000415\n",
      "Iteration 39060, Loss: 0.000000543\n",
      "Iteration 39070, Loss: 0.000000667\n",
      "Iteration 39080, Loss: 0.000001208\n",
      "Iteration 39090, Loss: 0.000000498\n",
      "Iteration 39100, Loss: 0.000000361\n",
      "Iteration 39110, Loss: 0.000000379\n",
      "Iteration 39120, Loss: 0.000000362\n",
      "Iteration 39130, Loss: 0.000000382\n",
      "Iteration 39140, Loss: 0.000000730\n",
      "Iteration 39150, Loss: 0.000000661\n",
      "Iteration 39160, Loss: 0.000000701\n",
      "Iteration 39170, Loss: 0.000000357\n",
      "Iteration 39180, Loss: 0.000000393\n",
      "Iteration 39190, Loss: 0.000000431\n",
      "Iteration 39200, Loss: 0.000000496\n",
      "Iteration 39210, Loss: 0.000000651\n",
      "Iteration 39220, Loss: 0.000000486\n",
      "Iteration 39230, Loss: 0.000000403\n",
      "Iteration 39240, Loss: 0.000000579\n",
      "Iteration 39250, Loss: 0.000000980\n",
      "Iteration 39260, Loss: 0.000000518\n",
      "Iteration 39270, Loss: 0.000000478\n",
      "Iteration 39280, Loss: 0.000000373\n",
      "Iteration 39290, Loss: 0.000001205\n",
      "Iteration 39300, Loss: 0.000000376\n",
      "Iteration 39310, Loss: 0.000000493\n",
      "Iteration 39320, Loss: 0.000000492\n",
      "Iteration 39330, Loss: 0.000000390\n",
      "Iteration 39340, Loss: 0.000000350\n",
      "Iteration 39350, Loss: 0.000000342\n",
      "Iteration 39360, Loss: 0.000000347\n",
      "Iteration 39370, Loss: 0.000000431\n",
      "Iteration 39380, Loss: 0.000000537\n",
      "Iteration 39390, Loss: 0.000000947\n",
      "Iteration 39400, Loss: 0.000000407\n",
      "Iteration 39410, Loss: 0.000000396\n",
      "Iteration 39420, Loss: 0.000000360\n",
      "Iteration 39430, Loss: 0.000000350\n",
      "Iteration 39440, Loss: 0.000000344\n",
      "Iteration 39450, Loss: 0.000000497\n",
      "Iteration 39460, Loss: 0.000003087\n",
      "Iteration 39470, Loss: 0.000000558\n",
      "Iteration 39480, Loss: 0.000000518\n",
      "Iteration 39490, Loss: 0.000000433\n",
      "Iteration 39500, Loss: 0.000000354\n",
      "Iteration 39510, Loss: 0.000000358\n",
      "Iteration 39520, Loss: 0.000000343\n",
      "Iteration 39530, Loss: 0.000000349\n",
      "Iteration 39540, Loss: 0.000000462\n",
      "Iteration 39550, Loss: 0.000001013\n",
      "Iteration 39560, Loss: 0.000000485\n",
      "Iteration 39570, Loss: 0.000000385\n",
      "Iteration 39580, Loss: 0.000000368\n",
      "Iteration 39590, Loss: 0.000000352\n",
      "Iteration 39600, Loss: 0.000000417\n",
      "Iteration 39610, Loss: 0.000001347\n",
      "Iteration 39620, Loss: 0.000000685\n",
      "Iteration 39630, Loss: 0.000000567\n",
      "Iteration 39640, Loss: 0.000001294\n",
      "Iteration 39650, Loss: 0.000000397\n",
      "Iteration 39660, Loss: 0.000000349\n",
      "Iteration 39670, Loss: 0.000000377\n",
      "Iteration 39680, Loss: 0.000000358\n",
      "Iteration 39690, Loss: 0.000000349\n",
      "Iteration 39700, Loss: 0.000000415\n",
      "Iteration 39710, Loss: 0.000000653\n",
      "Iteration 39720, Loss: 0.000001054\n",
      "Iteration 39730, Loss: 0.000000456\n",
      "Iteration 39740, Loss: 0.000000433\n",
      "Iteration 39750, Loss: 0.000000390\n",
      "Iteration 39760, Loss: 0.000000353\n",
      "Iteration 39770, Loss: 0.000000349\n",
      "Iteration 39780, Loss: 0.000000410\n",
      "Iteration 39790, Loss: 0.000001523\n",
      "Iteration 39800, Loss: 0.000001234\n",
      "Iteration 39810, Loss: 0.000000719\n",
      "Iteration 39820, Loss: 0.000000373\n",
      "Iteration 39830, Loss: 0.000000361\n",
      "Iteration 39840, Loss: 0.000000359\n",
      "Iteration 39850, Loss: 0.000000345\n",
      "Iteration 39860, Loss: 0.000000361\n",
      "Iteration 39870, Loss: 0.000000487\n",
      "Iteration 39880, Loss: 0.000001639\n",
      "Iteration 39890, Loss: 0.000000631\n",
      "Iteration 39900, Loss: 0.000000548\n",
      "Iteration 39910, Loss: 0.000000417\n",
      "Iteration 39920, Loss: 0.000000369\n",
      "Iteration 39930, Loss: 0.000000352\n",
      "Iteration 39940, Loss: 0.000000351\n",
      "Iteration 39950, Loss: 0.000000561\n",
      "Iteration 39960, Loss: 0.000000556\n",
      "Iteration 39970, Loss: 0.000000369\n",
      "Iteration 39980, Loss: 0.000000393\n",
      "Iteration 39990, Loss: 0.000000368\n",
      "Iteration 40000, Loss: 0.000000583\n",
      "Iteration 40010, Loss: 0.000001892\n",
      "Iteration 40020, Loss: 0.000000819\n",
      "Iteration 40030, Loss: 0.000000470\n",
      "Iteration 40040, Loss: 0.000000369\n",
      "Iteration 40050, Loss: 0.000000351\n",
      "Iteration 40060, Loss: 0.000000348\n",
      "Iteration 40070, Loss: 0.000000411\n",
      "Iteration 40080, Loss: 0.000001689\n",
      "Iteration 40090, Loss: 0.000000762\n",
      "Iteration 40100, Loss: 0.000000393\n",
      "Iteration 40110, Loss: 0.000000368\n",
      "Iteration 40120, Loss: 0.000000354\n",
      "Iteration 40130, Loss: 0.000000378\n",
      "Iteration 40140, Loss: 0.000001012\n",
      "Iteration 40150, Loss: 0.000000493\n",
      "Iteration 40160, Loss: 0.000000373\n",
      "Iteration 40170, Loss: 0.000000351\n",
      "Iteration 40180, Loss: 0.000000346\n",
      "Iteration 40190, Loss: 0.000000344\n",
      "Iteration 40200, Loss: 0.000000343\n",
      "Iteration 40210, Loss: 0.000000341\n",
      "Iteration 40220, Loss: 0.000000405\n",
      "Iteration 40230, Loss: 0.000001299\n",
      "Iteration 40240, Loss: 0.000000659\n",
      "Iteration 40250, Loss: 0.000000493\n",
      "Iteration 40260, Loss: 0.000000406\n",
      "Iteration 40270, Loss: 0.000000402\n",
      "Iteration 40280, Loss: 0.000000513\n",
      "Iteration 40290, Loss: 0.000001151\n",
      "Iteration 40300, Loss: 0.000000470\n",
      "Iteration 40310, Loss: 0.000000452\n",
      "Iteration 40320, Loss: 0.000000345\n",
      "Iteration 40330, Loss: 0.000000363\n",
      "Iteration 40340, Loss: 0.000000388\n",
      "Iteration 40350, Loss: 0.000000593\n",
      "Iteration 40360, Loss: 0.000001126\n",
      "Iteration 40370, Loss: 0.000000486\n",
      "Iteration 40380, Loss: 0.000000402\n",
      "Iteration 40390, Loss: 0.000000831\n",
      "Iteration 40400, Loss: 0.000000491\n",
      "Iteration 40410, Loss: 0.000000418\n",
      "Iteration 40420, Loss: 0.000000379\n",
      "Iteration 40430, Loss: 0.000000573\n",
      "Iteration 40440, Loss: 0.000001406\n",
      "Iteration 40450, Loss: 0.000000588\n",
      "Iteration 40460, Loss: 0.000000379\n",
      "Iteration 40470, Loss: 0.000000357\n",
      "Iteration 40480, Loss: 0.000000373\n",
      "Iteration 40490, Loss: 0.000000631\n",
      "Iteration 40500, Loss: 0.000000675\n",
      "Iteration 40510, Loss: 0.000000716\n",
      "Iteration 40520, Loss: 0.000000396\n",
      "Iteration 40530, Loss: 0.000000382\n",
      "Iteration 40540, Loss: 0.000000359\n",
      "Iteration 40550, Loss: 0.000000411\n",
      "Iteration 40560, Loss: 0.000001979\n",
      "Iteration 40570, Loss: 0.000000749\n",
      "Iteration 40580, Loss: 0.000000644\n",
      "Iteration 40590, Loss: 0.000000433\n",
      "Iteration 40600, Loss: 0.000000353\n",
      "Iteration 40610, Loss: 0.000000347\n",
      "Iteration 40620, Loss: 0.000000442\n",
      "Iteration 40630, Loss: 0.000000478\n",
      "Iteration 40640, Loss: 0.000000455\n",
      "Iteration 40650, Loss: 0.000000894\n",
      "Iteration 40660, Loss: 0.000000483\n",
      "Iteration 40670, Loss: 0.000000518\n",
      "Iteration 40680, Loss: 0.000000437\n",
      "Iteration 40690, Loss: 0.000000349\n",
      "Iteration 40700, Loss: 0.000000370\n",
      "Iteration 40710, Loss: 0.000000730\n",
      "Iteration 40720, Loss: 0.000001571\n",
      "Iteration 40730, Loss: 0.000000536\n",
      "Iteration 40740, Loss: 0.000000390\n",
      "Iteration 40750, Loss: 0.000000381\n",
      "Iteration 40760, Loss: 0.000000353\n",
      "Iteration 40770, Loss: 0.000000339\n",
      "Iteration 40780, Loss: 0.000000345\n",
      "Iteration 40790, Loss: 0.000000552\n",
      "Iteration 40800, Loss: 0.000000864\n",
      "Iteration 40810, Loss: 0.000000402\n",
      "Iteration 40820, Loss: 0.000000365\n",
      "Iteration 40830, Loss: 0.000000408\n",
      "Iteration 40840, Loss: 0.000000854\n",
      "Iteration 40850, Loss: 0.000000585\n",
      "Iteration 40860, Loss: 0.000000512\n",
      "Iteration 40870, Loss: 0.000000388\n",
      "Iteration 40880, Loss: 0.000000353\n",
      "Iteration 40890, Loss: 0.000000341\n",
      "Iteration 40900, Loss: 0.000000351\n",
      "Iteration 40910, Loss: 0.000000434\n",
      "Iteration 40920, Loss: 0.000001341\n",
      "Iteration 40930, Loss: 0.000000566\n",
      "Iteration 40940, Loss: 0.000000434\n",
      "Iteration 40950, Loss: 0.000000370\n",
      "Iteration 40960, Loss: 0.000000350\n",
      "Iteration 40970, Loss: 0.000000338\n",
      "Iteration 40980, Loss: 0.000000343\n",
      "Iteration 40990, Loss: 0.000000500\n",
      "Iteration 41000, Loss: 0.000001914\n",
      "Iteration 41010, Loss: 0.000000830\n",
      "Iteration 41020, Loss: 0.000000392\n",
      "Iteration 41030, Loss: 0.000000385\n",
      "Iteration 41040, Loss: 0.000000356\n",
      "Iteration 41050, Loss: 0.000000355\n",
      "Iteration 41060, Loss: 0.000000557\n",
      "Iteration 41070, Loss: 0.000001564\n",
      "Iteration 41080, Loss: 0.000000691\n",
      "Iteration 41090, Loss: 0.000000416\n",
      "Iteration 41100, Loss: 0.000000347\n",
      "Iteration 41110, Loss: 0.000000338\n",
      "Iteration 41120, Loss: 0.000000340\n",
      "Iteration 41130, Loss: 0.000000340\n",
      "Iteration 41140, Loss: 0.000000350\n",
      "Iteration 41150, Loss: 0.000000724\n",
      "Iteration 41160, Loss: 0.000001012\n",
      "Iteration 41170, Loss: 0.000000919\n",
      "Iteration 41180, Loss: 0.000000619\n",
      "Iteration 41190, Loss: 0.000000438\n",
      "Iteration 41200, Loss: 0.000000344\n",
      "Iteration 41210, Loss: 0.000000353\n",
      "Iteration 41220, Loss: 0.000000338\n",
      "Iteration 41230, Loss: 0.000000340\n",
      "Iteration 41240, Loss: 0.000000355\n",
      "Iteration 41250, Loss: 0.000000632\n",
      "Iteration 41260, Loss: 0.000001565\n",
      "Iteration 41270, Loss: 0.000000881\n",
      "Iteration 41280, Loss: 0.000000732\n",
      "Iteration 41290, Loss: 0.000000399\n",
      "Iteration 41300, Loss: 0.000000379\n",
      "Iteration 41310, Loss: 0.000000349\n",
      "Iteration 41320, Loss: 0.000000353\n",
      "Iteration 41330, Loss: 0.000000400\n",
      "Iteration 41340, Loss: 0.000000804\n",
      "Iteration 41350, Loss: 0.000000456\n",
      "Iteration 41360, Loss: 0.000000411\n",
      "Iteration 41370, Loss: 0.000000383\n",
      "Iteration 41380, Loss: 0.000000357\n",
      "Iteration 41390, Loss: 0.000000692\n",
      "Iteration 41400, Loss: 0.000001810\n",
      "Iteration 41410, Loss: 0.000000607\n",
      "Iteration 41420, Loss: 0.000000441\n",
      "Iteration 41430, Loss: 0.000000414\n",
      "Iteration 41440, Loss: 0.000000364\n",
      "Iteration 41450, Loss: 0.000000338\n",
      "Iteration 41460, Loss: 0.000000337\n",
      "Iteration 41470, Loss: 0.000000337\n",
      "Iteration 41480, Loss: 0.000000364\n",
      "Iteration 41490, Loss: 0.000001085\n",
      "Iteration 41500, Loss: 0.000000706\n",
      "Iteration 41510, Loss: 0.000000521\n",
      "Iteration 41520, Loss: 0.000000410\n",
      "Iteration 41530, Loss: 0.000000365\n",
      "Iteration 41540, Loss: 0.000000350\n",
      "Iteration 41550, Loss: 0.000000376\n",
      "Iteration 41560, Loss: 0.000000720\n",
      "Iteration 41570, Loss: 0.000000962\n",
      "Iteration 41580, Loss: 0.000000616\n",
      "Iteration 41590, Loss: 0.000000432\n",
      "Iteration 41600, Loss: 0.000000348\n",
      "Iteration 41610, Loss: 0.000000339\n",
      "Iteration 41620, Loss: 0.000000342\n",
      "Iteration 41630, Loss: 0.000000353\n",
      "Iteration 41640, Loss: 0.000000790\n",
      "Iteration 41650, Loss: 0.000001094\n",
      "Iteration 41660, Loss: 0.000000576\n",
      "Iteration 41670, Loss: 0.000000393\n",
      "Iteration 41680, Loss: 0.000000365\n",
      "Iteration 41690, Loss: 0.000000377\n",
      "Iteration 41700, Loss: 0.000000966\n",
      "Iteration 41710, Loss: 0.000000564\n",
      "Iteration 41720, Loss: 0.000000375\n",
      "Iteration 41730, Loss: 0.000000361\n",
      "Iteration 41740, Loss: 0.000000355\n",
      "Iteration 41750, Loss: 0.000000344\n",
      "Iteration 41760, Loss: 0.000000336\n",
      "Iteration 41770, Loss: 0.000000337\n",
      "Iteration 41780, Loss: 0.000000406\n",
      "Iteration 41790, Loss: 0.000001771\n",
      "Iteration 41800, Loss: 0.000000825\n",
      "Iteration 41810, Loss: 0.000000450\n",
      "Iteration 41820, Loss: 0.000000388\n",
      "Iteration 41830, Loss: 0.000000356\n",
      "Iteration 41840, Loss: 0.000000347\n",
      "Iteration 41850, Loss: 0.000000336\n",
      "Iteration 41860, Loss: 0.000000338\n",
      "Iteration 41870, Loss: 0.000000353\n",
      "Iteration 41880, Loss: 0.000000793\n",
      "Iteration 41890, Loss: 0.000001238\n",
      "Iteration 41900, Loss: 0.000000593\n",
      "Iteration 41910, Loss: 0.000000504\n",
      "Iteration 41920, Loss: 0.000000378\n",
      "Iteration 41930, Loss: 0.000000353\n",
      "Iteration 41940, Loss: 0.000000337\n",
      "Iteration 41950, Loss: 0.000000342\n",
      "Iteration 41960, Loss: 0.000000389\n",
      "Iteration 41970, Loss: 0.000001317\n",
      "Iteration 41980, Loss: 0.000000406\n",
      "Iteration 41990, Loss: 0.000000366\n",
      "Iteration 42000, Loss: 0.000000355\n",
      "Iteration 42010, Loss: 0.000000340\n",
      "Iteration 42020, Loss: 0.000000334\n",
      "Iteration 42030, Loss: 0.000000337\n",
      "Iteration 42040, Loss: 0.000000345\n",
      "Iteration 42050, Loss: 0.000000663\n",
      "Iteration 42060, Loss: 0.000000472\n",
      "Iteration 42070, Loss: 0.000000466\n",
      "Iteration 42080, Loss: 0.000000408\n",
      "Iteration 42090, Loss: 0.000000453\n",
      "Iteration 42100, Loss: 0.000001174\n",
      "Iteration 42110, Loss: 0.000000396\n",
      "Iteration 42120, Loss: 0.000000463\n",
      "Iteration 42130, Loss: 0.000000466\n",
      "Iteration 42140, Loss: 0.000000520\n",
      "Iteration 42150, Loss: 0.000000432\n",
      "Iteration 42160, Loss: 0.000000385\n",
      "Iteration 42170, Loss: 0.000000453\n",
      "Iteration 42180, Loss: 0.000000697\n",
      "Iteration 42190, Loss: 0.000001043\n",
      "Iteration 42200, Loss: 0.000000533\n",
      "Iteration 42210, Loss: 0.000000435\n",
      "Iteration 42220, Loss: 0.000000389\n",
      "Iteration 42230, Loss: 0.000000340\n",
      "Iteration 42240, Loss: 0.000000350\n",
      "Iteration 42250, Loss: 0.000000452\n",
      "Iteration 42260, Loss: 0.000001823\n",
      "Iteration 42270, Loss: 0.000000813\n",
      "Iteration 42280, Loss: 0.000000555\n",
      "Iteration 42290, Loss: 0.000000412\n",
      "Iteration 42300, Loss: 0.000000365\n",
      "Iteration 42310, Loss: 0.000000346\n",
      "Iteration 42320, Loss: 0.000000342\n",
      "Iteration 42330, Loss: 0.000000438\n",
      "Iteration 42340, Loss: 0.000000434\n",
      "Iteration 42350, Loss: 0.000002799\n",
      "Iteration 42360, Loss: 0.000000752\n",
      "Iteration 42370, Loss: 0.000000668\n",
      "Iteration 42380, Loss: 0.000000421\n",
      "Iteration 42390, Loss: 0.000000342\n",
      "Iteration 42400, Loss: 0.000000340\n",
      "Iteration 42410, Loss: 0.000000339\n",
      "Iteration 42420, Loss: 0.000000333\n",
      "Iteration 42430, Loss: 0.000000333\n",
      "Iteration 42440, Loss: 0.000000334\n",
      "Iteration 42450, Loss: 0.000000354\n",
      "Iteration 42460, Loss: 0.000001153\n",
      "Iteration 42470, Loss: 0.000000347\n",
      "Iteration 42480, Loss: 0.000000486\n",
      "Iteration 42490, Loss: 0.000000454\n",
      "Iteration 42500, Loss: 0.000000358\n",
      "Iteration 42510, Loss: 0.000000339\n",
      "Iteration 42520, Loss: 0.000000336\n",
      "Iteration 42530, Loss: 0.000000339\n",
      "Iteration 42540, Loss: 0.000000458\n",
      "Iteration 42550, Loss: 0.000001552\n",
      "Iteration 42560, Loss: 0.000000591\n",
      "Iteration 42570, Loss: 0.000000420\n",
      "Iteration 42580, Loss: 0.000000383\n",
      "Iteration 42590, Loss: 0.000000343\n",
      "Iteration 42600, Loss: 0.000000339\n",
      "Iteration 42610, Loss: 0.000000349\n",
      "Iteration 42620, Loss: 0.000000542\n",
      "Iteration 42630, Loss: 0.000000652\n",
      "Iteration 42640, Loss: 0.000000551\n",
      "Iteration 42650, Loss: 0.000002359\n",
      "Iteration 42660, Loss: 0.000000828\n",
      "Iteration 42670, Loss: 0.000000400\n",
      "Iteration 42680, Loss: 0.000000368\n",
      "Iteration 42690, Loss: 0.000000357\n",
      "Iteration 42700, Loss: 0.000000341\n",
      "Iteration 42710, Loss: 0.000000335\n",
      "Iteration 42720, Loss: 0.000000334\n",
      "Iteration 42730, Loss: 0.000000333\n",
      "Iteration 42740, Loss: 0.000000343\n",
      "Iteration 42750, Loss: 0.000000745\n",
      "Iteration 42760, Loss: 0.000000999\n",
      "Iteration 42770, Loss: 0.000000607\n",
      "Iteration 42780, Loss: 0.000000436\n",
      "Iteration 42790, Loss: 0.000000352\n",
      "Iteration 42800, Loss: 0.000000349\n",
      "Iteration 42810, Loss: 0.000000341\n",
      "Iteration 42820, Loss: 0.000000498\n",
      "Iteration 42830, Loss: 0.000000517\n",
      "Iteration 42840, Loss: 0.000001252\n",
      "Iteration 42850, Loss: 0.000000473\n",
      "Iteration 42860, Loss: 0.000000392\n",
      "Iteration 42870, Loss: 0.000000375\n",
      "Iteration 42880, Loss: 0.000000350\n",
      "Iteration 42890, Loss: 0.000000344\n",
      "Iteration 42900, Loss: 0.000000338\n",
      "Iteration 42910, Loss: 0.000000335\n",
      "Iteration 42920, Loss: 0.000000368\n",
      "Iteration 42930, Loss: 0.000001110\n",
      "Iteration 42940, Loss: 0.000000564\n",
      "Iteration 42950, Loss: 0.000000437\n",
      "Iteration 42960, Loss: 0.000000392\n",
      "Iteration 42970, Loss: 0.000000911\n",
      "Iteration 42980, Loss: 0.000000646\n",
      "Iteration 42990, Loss: 0.000000468\n",
      "Iteration 43000, Loss: 0.000000386\n",
      "Iteration 43010, Loss: 0.000000362\n",
      "Iteration 43020, Loss: 0.000000349\n",
      "Iteration 43030, Loss: 0.000000335\n",
      "Iteration 43040, Loss: 0.000000408\n",
      "Iteration 43050, Loss: 0.000001890\n",
      "Iteration 43060, Loss: 0.000000603\n",
      "Iteration 43070, Loss: 0.000000420\n",
      "Iteration 43080, Loss: 0.000000383\n",
      "Iteration 43090, Loss: 0.000000486\n",
      "Iteration 43100, Loss: 0.000001346\n",
      "Iteration 43110, Loss: 0.000000591\n",
      "Iteration 43120, Loss: 0.000000459\n",
      "Iteration 43130, Loss: 0.000000402\n",
      "Iteration 43140, Loss: 0.000000355\n",
      "Iteration 43150, Loss: 0.000000340\n",
      "Iteration 43160, Loss: 0.000000335\n",
      "Iteration 43170, Loss: 0.000000333\n",
      "Iteration 43180, Loss: 0.000000341\n",
      "Iteration 43190, Loss: 0.000000660\n",
      "Iteration 43200, Loss: 0.000001809\n",
      "Iteration 43210, Loss: 0.000000408\n",
      "Iteration 43220, Loss: 0.000000498\n",
      "Iteration 43230, Loss: 0.000000450\n",
      "Iteration 43240, Loss: 0.000000384\n",
      "Iteration 43250, Loss: 0.000000393\n",
      "Iteration 43260, Loss: 0.000000670\n",
      "Iteration 43270, Loss: 0.000000386\n",
      "Iteration 43280, Loss: 0.000000351\n",
      "Iteration 43290, Loss: 0.000000355\n",
      "Iteration 43300, Loss: 0.000000405\n",
      "Iteration 43310, Loss: 0.000000798\n",
      "Iteration 43320, Loss: 0.000000976\n",
      "Iteration 43330, Loss: 0.000000451\n",
      "Iteration 43340, Loss: 0.000000347\n",
      "Iteration 43350, Loss: 0.000000345\n",
      "Iteration 43360, Loss: 0.000000347\n",
      "Iteration 43370, Loss: 0.000000411\n",
      "Iteration 43380, Loss: 0.000001711\n",
      "Iteration 43390, Loss: 0.000000556\n",
      "Iteration 43400, Loss: 0.000000513\n",
      "Iteration 43410, Loss: 0.000000424\n",
      "Iteration 43420, Loss: 0.000000369\n",
      "Iteration 43430, Loss: 0.000000354\n",
      "Iteration 43440, Loss: 0.000000613\n",
      "Iteration 43450, Loss: 0.000000686\n",
      "Iteration 43460, Loss: 0.000000475\n",
      "Iteration 43470, Loss: 0.000000431\n",
      "Iteration 43480, Loss: 0.000000342\n",
      "Iteration 43490, Loss: 0.000000337\n",
      "Iteration 43500, Loss: 0.000000349\n",
      "Iteration 43510, Loss: 0.000000800\n",
      "Iteration 43520, Loss: 0.000001019\n",
      "Iteration 43530, Loss: 0.000000492\n",
      "Iteration 43540, Loss: 0.000000440\n",
      "Iteration 43550, Loss: 0.000000465\n",
      "Iteration 43560, Loss: 0.000000367\n",
      "Iteration 43570, Loss: 0.000000354\n",
      "Iteration 43580, Loss: 0.000000389\n",
      "Iteration 43590, Loss: 0.000000421\n",
      "Iteration 43600, Loss: 0.000000723\n",
      "Iteration 43610, Loss: 0.000000531\n",
      "Iteration 43620, Loss: 0.000000390\n",
      "Iteration 43630, Loss: 0.000000381\n",
      "Iteration 43640, Loss: 0.000000345\n",
      "Iteration 43650, Loss: 0.000000401\n",
      "Iteration 43660, Loss: 0.000001564\n",
      "Iteration 43670, Loss: 0.000000563\n",
      "Iteration 43680, Loss: 0.000000495\n",
      "Iteration 43690, Loss: 0.000000400\n",
      "Iteration 43700, Loss: 0.000000360\n",
      "Iteration 43710, Loss: 0.000000343\n",
      "Iteration 43720, Loss: 0.000000346\n",
      "Iteration 43730, Loss: 0.000000717\n",
      "Iteration 43740, Loss: 0.000000617\n",
      "Iteration 43750, Loss: 0.000000571\n",
      "Iteration 43760, Loss: 0.000000404\n",
      "Iteration 43770, Loss: 0.000000355\n",
      "Iteration 43780, Loss: 0.000000343\n",
      "Iteration 43790, Loss: 0.000000362\n",
      "Iteration 43800, Loss: 0.000000851\n",
      "Iteration 43810, Loss: 0.000000495\n",
      "Iteration 43820, Loss: 0.000001004\n",
      "Iteration 43830, Loss: 0.000000674\n",
      "Iteration 43840, Loss: 0.000000547\n",
      "Iteration 43850, Loss: 0.000000434\n",
      "Iteration 43860, Loss: 0.000000373\n",
      "Iteration 43870, Loss: 0.000000345\n",
      "Iteration 43880, Loss: 0.000000330\n",
      "Iteration 43890, Loss: 0.000000334\n",
      "Iteration 43900, Loss: 0.000000331\n",
      "Iteration 43910, Loss: 0.000000336\n",
      "Iteration 43920, Loss: 0.000000503\n",
      "Iteration 43930, Loss: 0.000001238\n",
      "Iteration 43940, Loss: 0.000000680\n",
      "Iteration 43950, Loss: 0.000000566\n",
      "Iteration 43960, Loss: 0.000000404\n",
      "Iteration 43970, Loss: 0.000000367\n",
      "Iteration 43980, Loss: 0.000000346\n",
      "Iteration 43990, Loss: 0.000000331\n",
      "Iteration 44000, Loss: 0.000000333\n",
      "Iteration 44010, Loss: 0.000000337\n",
      "Iteration 44020, Loss: 0.000000461\n",
      "Iteration 44030, Loss: 0.000001579\n",
      "Iteration 44040, Loss: 0.000000775\n",
      "Iteration 44050, Loss: 0.000000718\n",
      "Iteration 44060, Loss: 0.000000452\n",
      "Iteration 44070, Loss: 0.000000366\n",
      "Iteration 44080, Loss: 0.000000343\n",
      "Iteration 44090, Loss: 0.000000370\n",
      "Iteration 44100, Loss: 0.000000496\n",
      "Iteration 44110, Loss: 0.000001156\n",
      "Iteration 44120, Loss: 0.000000373\n",
      "Iteration 44130, Loss: 0.000000369\n",
      "Iteration 44140, Loss: 0.000000395\n",
      "Iteration 44150, Loss: 0.000000469\n",
      "Iteration 44160, Loss: 0.000000697\n",
      "Iteration 44170, Loss: 0.000000404\n",
      "Iteration 44180, Loss: 0.000000383\n",
      "Iteration 44190, Loss: 0.000000408\n",
      "Iteration 44200, Loss: 0.000001160\n",
      "Iteration 44210, Loss: 0.000000364\n",
      "Iteration 44220, Loss: 0.000000338\n",
      "Iteration 44230, Loss: 0.000000333\n",
      "Iteration 44240, Loss: 0.000000334\n",
      "Iteration 44250, Loss: 0.000000352\n",
      "Iteration 44260, Loss: 0.000000577\n",
      "Iteration 44270, Loss: 0.000001087\n",
      "Iteration 44280, Loss: 0.000000521\n",
      "Iteration 44290, Loss: 0.000000369\n",
      "Iteration 44300, Loss: 0.000000345\n",
      "Iteration 44310, Loss: 0.000000416\n",
      "Iteration 44320, Loss: 0.000001291\n",
      "Iteration 44330, Loss: 0.000000358\n",
      "Iteration 44340, Loss: 0.000000337\n",
      "Iteration 44350, Loss: 0.000000348\n",
      "Iteration 44360, Loss: 0.000000356\n",
      "Iteration 44370, Loss: 0.000000370\n",
      "Iteration 44380, Loss: 0.000000929\n",
      "Iteration 44390, Loss: 0.000000591\n",
      "Iteration 44400, Loss: 0.000000442\n",
      "Iteration 44410, Loss: 0.000000413\n",
      "Iteration 44420, Loss: 0.000000385\n",
      "Iteration 44430, Loss: 0.000000490\n",
      "Iteration 44440, Loss: 0.000000897\n",
      "Iteration 44450, Loss: 0.000000368\n",
      "Iteration 44460, Loss: 0.000000481\n",
      "Iteration 44470, Loss: 0.000000554\n",
      "Iteration 44480, Loss: 0.000000638\n",
      "Iteration 44490, Loss: 0.000000512\n",
      "Iteration 44500, Loss: 0.000000451\n",
      "Iteration 44510, Loss: 0.000000584\n",
      "Iteration 44520, Loss: 0.000000758\n",
      "Iteration 44530, Loss: 0.000000364\n",
      "Iteration 44540, Loss: 0.000000465\n",
      "Iteration 44550, Loss: 0.000000483\n",
      "Iteration 44560, Loss: 0.000000502\n",
      "Iteration 44570, Loss: 0.000000812\n",
      "Iteration 44580, Loss: 0.000000758\n",
      "Iteration 44590, Loss: 0.000000400\n",
      "Iteration 44600, Loss: 0.000000385\n",
      "Iteration 44610, Loss: 0.000000429\n",
      "Iteration 44620, Loss: 0.000000547\n",
      "Iteration 44630, Loss: 0.000000610\n",
      "Iteration 44640, Loss: 0.000000393\n",
      "Iteration 44650, Loss: 0.000000482\n",
      "Iteration 44660, Loss: 0.000000638\n",
      "Iteration 44670, Loss: 0.000000378\n",
      "Iteration 44680, Loss: 0.000000380\n",
      "Iteration 44690, Loss: 0.000000521\n",
      "Iteration 44700, Loss: 0.000001174\n",
      "Iteration 44710, Loss: 0.000001360\n",
      "Iteration 44720, Loss: 0.000000575\n",
      "Iteration 44730, Loss: 0.000000574\n",
      "Iteration 44740, Loss: 0.000000410\n",
      "Iteration 44750, Loss: 0.000000350\n",
      "Iteration 44760, Loss: 0.000000334\n",
      "Iteration 44770, Loss: 0.000000330\n",
      "Iteration 44780, Loss: 0.000000329\n",
      "Iteration 44790, Loss: 0.000000329\n",
      "Iteration 44800, Loss: 0.000000328\n",
      "Iteration 44810, Loss: 0.000000328\n",
      "Iteration 44820, Loss: 0.000000333\n",
      "Iteration 44830, Loss: 0.000000589\n",
      "Iteration 44840, Loss: 0.000000959\n",
      "Iteration 44850, Loss: 0.000000458\n",
      "Iteration 44860, Loss: 0.000000448\n",
      "Iteration 44870, Loss: 0.000000346\n",
      "Iteration 44880, Loss: 0.000000349\n",
      "Iteration 44890, Loss: 0.000000339\n",
      "Iteration 44900, Loss: 0.000000405\n",
      "Iteration 44910, Loss: 0.000001534\n",
      "Iteration 44920, Loss: 0.000000467\n",
      "Iteration 44930, Loss: 0.000000427\n",
      "Iteration 44940, Loss: 0.000000383\n",
      "Iteration 44950, Loss: 0.000000350\n",
      "Iteration 44960, Loss: 0.000000333\n",
      "Iteration 44970, Loss: 0.000000329\n",
      "Iteration 44980, Loss: 0.000000343\n",
      "Iteration 44990, Loss: 0.000000781\n",
      "Iteration 45000, Loss: 0.000000417\n",
      "Iteration 45010, Loss: 0.000000490\n",
      "Iteration 45020, Loss: 0.000000384\n",
      "Iteration 45030, Loss: 0.000000332\n",
      "Iteration 45040, Loss: 0.000000372\n",
      "Iteration 45050, Loss: 0.000001571\n",
      "Iteration 45060, Loss: 0.000000615\n",
      "Iteration 45070, Loss: 0.000000724\n",
      "Iteration 45080, Loss: 0.000000424\n",
      "Iteration 45090, Loss: 0.000000334\n",
      "Iteration 45100, Loss: 0.000000334\n",
      "Iteration 45110, Loss: 0.000000335\n",
      "Iteration 45120, Loss: 0.000000440\n",
      "Iteration 45130, Loss: 0.000001420\n",
      "Iteration 45140, Loss: 0.000000471\n",
      "Iteration 45150, Loss: 0.000000353\n",
      "Iteration 45160, Loss: 0.000000371\n",
      "Iteration 45170, Loss: 0.000000341\n",
      "Iteration 45180, Loss: 0.000000403\n",
      "Iteration 45190, Loss: 0.000000333\n",
      "Iteration 45200, Loss: 0.000000332\n",
      "Iteration 45210, Loss: 0.000000378\n",
      "Iteration 45220, Loss: 0.000002771\n",
      "Iteration 45230, Loss: 0.000001499\n",
      "Iteration 45240, Loss: 0.000000540\n",
      "Iteration 45250, Loss: 0.000000402\n",
      "Iteration 45260, Loss: 0.000000368\n",
      "Iteration 45270, Loss: 0.000000336\n",
      "Iteration 45280, Loss: 0.000000336\n",
      "Iteration 45290, Loss: 0.000000384\n",
      "Iteration 45300, Loss: 0.000000763\n",
      "Iteration 45310, Loss: 0.000000453\n",
      "Iteration 45320, Loss: 0.000000381\n",
      "Iteration 45330, Loss: 0.000000405\n",
      "Iteration 45340, Loss: 0.000000763\n",
      "Iteration 45350, Loss: 0.000000582\n",
      "Iteration 45360, Loss: 0.000000367\n",
      "Iteration 45370, Loss: 0.000000360\n",
      "Iteration 45380, Loss: 0.000000346\n",
      "Iteration 45390, Loss: 0.000000362\n",
      "Iteration 45400, Loss: 0.000000607\n",
      "Iteration 45410, Loss: 0.000001252\n",
      "Iteration 45420, Loss: 0.000000692\n",
      "Iteration 45430, Loss: 0.000000535\n",
      "Iteration 45440, Loss: 0.000001047\n",
      "Iteration 45450, Loss: 0.000000546\n",
      "Iteration 45460, Loss: 0.000000413\n",
      "Iteration 45470, Loss: 0.000000357\n",
      "Iteration 45480, Loss: 0.000000336\n",
      "Iteration 45490, Loss: 0.000000348\n",
      "Iteration 45500, Loss: 0.000000809\n",
      "Iteration 45510, Loss: 0.000001082\n",
      "Iteration 45520, Loss: 0.000000564\n",
      "Iteration 45530, Loss: 0.000000440\n",
      "Iteration 45540, Loss: 0.000000348\n",
      "Iteration 45550, Loss: 0.000000354\n",
      "Iteration 45560, Loss: 0.000000349\n",
      "Iteration 45570, Loss: 0.000000455\n",
      "Iteration 45580, Loss: 0.000001358\n",
      "Iteration 45590, Loss: 0.000000666\n",
      "Iteration 45600, Loss: 0.000000420\n",
      "Iteration 45610, Loss: 0.000000403\n",
      "Iteration 45620, Loss: 0.000000415\n",
      "Iteration 45630, Loss: 0.000000417\n",
      "Iteration 45640, Loss: 0.000001032\n",
      "Iteration 45650, Loss: 0.000000516\n",
      "Iteration 45660, Loss: 0.000000391\n",
      "Iteration 45670, Loss: 0.000000365\n",
      "Iteration 45680, Loss: 0.000000349\n",
      "Iteration 45690, Loss: 0.000000342\n",
      "Iteration 45700, Loss: 0.000000408\n",
      "Iteration 45710, Loss: 0.000000401\n",
      "Iteration 45720, Loss: 0.000000943\n",
      "Iteration 45730, Loss: 0.000000713\n",
      "Iteration 45740, Loss: 0.000000442\n",
      "Iteration 45750, Loss: 0.000000363\n",
      "Iteration 45760, Loss: 0.000000433\n",
      "Iteration 45770, Loss: 0.000000763\n",
      "Iteration 45780, Loss: 0.000000463\n",
      "Iteration 45790, Loss: 0.000000404\n",
      "Iteration 45800, Loss: 0.000000407\n",
      "Iteration 45810, Loss: 0.000000540\n",
      "Iteration 45820, Loss: 0.000000895\n",
      "Iteration 45830, Loss: 0.000000556\n",
      "Iteration 45840, Loss: 0.000000533\n",
      "Iteration 45850, Loss: 0.000000488\n",
      "Iteration 45860, Loss: 0.000000474\n",
      "Iteration 45870, Loss: 0.000000505\n",
      "Iteration 45880, Loss: 0.000000511\n",
      "Iteration 45890, Loss: 0.000000496\n",
      "Iteration 45900, Loss: 0.000000397\n",
      "Iteration 45910, Loss: 0.000000345\n",
      "Iteration 45920, Loss: 0.000000407\n",
      "Iteration 45930, Loss: 0.000000964\n",
      "Iteration 45940, Loss: 0.000001376\n",
      "Iteration 45950, Loss: 0.000000448\n",
      "Iteration 45960, Loss: 0.000000435\n",
      "Iteration 45970, Loss: 0.000000392\n",
      "Iteration 45980, Loss: 0.000000345\n",
      "Iteration 45990, Loss: 0.000000331\n",
      "Iteration 46000, Loss: 0.000000328\n",
      "Iteration 46010, Loss: 0.000000362\n",
      "Iteration 46020, Loss: 0.000001832\n",
      "Iteration 46030, Loss: 0.000000731\n",
      "Iteration 46040, Loss: 0.000000413\n",
      "Iteration 46050, Loss: 0.000000368\n",
      "Iteration 46060, Loss: 0.000000338\n",
      "Iteration 46070, Loss: 0.000000330\n",
      "Iteration 46080, Loss: 0.000000328\n",
      "Iteration 46090, Loss: 0.000000364\n",
      "Iteration 46100, Loss: 0.000001616\n",
      "Iteration 46110, Loss: 0.000000559\n",
      "Iteration 46120, Loss: 0.000000645\n",
      "Iteration 46130, Loss: 0.000000424\n",
      "Iteration 46140, Loss: 0.000000335\n",
      "Iteration 46150, Loss: 0.000000328\n",
      "Iteration 46160, Loss: 0.000000343\n",
      "Iteration 46170, Loss: 0.000000507\n",
      "Iteration 46180, Loss: 0.000000821\n",
      "Iteration 46190, Loss: 0.000000479\n",
      "Iteration 46200, Loss: 0.000000436\n",
      "Iteration 46210, Loss: 0.000000357\n",
      "Iteration 46220, Loss: 0.000000338\n",
      "Iteration 46230, Loss: 0.000000331\n",
      "Iteration 46240, Loss: 0.000000332\n",
      "Iteration 46250, Loss: 0.000000391\n",
      "Iteration 46260, Loss: 0.000001949\n",
      "Iteration 46270, Loss: 0.000000858\n",
      "Iteration 46280, Loss: 0.000000597\n",
      "Iteration 46290, Loss: 0.000000351\n",
      "Iteration 46300, Loss: 0.000000342\n",
      "Iteration 46310, Loss: 0.000000337\n",
      "Iteration 46320, Loss: 0.000000336\n",
      "Iteration 46330, Loss: 0.000000514\n",
      "Iteration 46340, Loss: 0.000001760\n",
      "Iteration 46350, Loss: 0.000000494\n",
      "Iteration 46360, Loss: 0.000000425\n",
      "Iteration 46370, Loss: 0.000000362\n",
      "Iteration 46380, Loss: 0.000000333\n",
      "Iteration 46390, Loss: 0.000000332\n",
      "Iteration 46400, Loss: 0.000000335\n",
      "Iteration 46410, Loss: 0.000000467\n",
      "Iteration 46420, Loss: 0.000000438\n",
      "Iteration 46430, Loss: 0.000000383\n",
      "Iteration 46440, Loss: 0.000002011\n",
      "Iteration 46450, Loss: 0.000001069\n",
      "Iteration 46460, Loss: 0.000000721\n",
      "Iteration 46470, Loss: 0.000000394\n",
      "Iteration 46480, Loss: 0.000000375\n",
      "Iteration 46490, Loss: 0.000000330\n",
      "Iteration 46500, Loss: 0.000000332\n",
      "Iteration 46510, Loss: 0.000000326\n",
      "Iteration 46520, Loss: 0.000000328\n",
      "Iteration 46530, Loss: 0.000000456\n",
      "Iteration 46540, Loss: 0.000000607\n",
      "Iteration 46550, Loss: 0.000000384\n",
      "Iteration 46560, Loss: 0.000000382\n",
      "Iteration 46570, Loss: 0.000000336\n",
      "Iteration 46580, Loss: 0.000000334\n",
      "Iteration 46590, Loss: 0.000000436\n",
      "Iteration 46600, Loss: 0.000001993\n",
      "Iteration 46610, Loss: 0.000001340\n",
      "Iteration 46620, Loss: 0.000000625\n",
      "Iteration 46630, Loss: 0.000000428\n",
      "Iteration 46640, Loss: 0.000000364\n",
      "Iteration 46650, Loss: 0.000000339\n",
      "Iteration 46660, Loss: 0.000000330\n",
      "Iteration 46670, Loss: 0.000000326\n",
      "Iteration 46680, Loss: 0.000000325\n",
      "Iteration 46690, Loss: 0.000000331\n",
      "Iteration 46700, Loss: 0.000000655\n",
      "Iteration 46710, Loss: 0.000001190\n",
      "Iteration 46720, Loss: 0.000000625\n",
      "Iteration 46730, Loss: 0.000000407\n",
      "Iteration 46740, Loss: 0.000000360\n",
      "Iteration 46750, Loss: 0.000000343\n",
      "Iteration 46760, Loss: 0.000000332\n",
      "Iteration 46770, Loss: 0.000000474\n",
      "Iteration 46780, Loss: 0.000000528\n",
      "Iteration 46790, Loss: 0.000001258\n",
      "Iteration 46800, Loss: 0.000000391\n",
      "Iteration 46810, Loss: 0.000000347\n",
      "Iteration 46820, Loss: 0.000000369\n",
      "Iteration 46830, Loss: 0.000000341\n",
      "Iteration 46840, Loss: 0.000000336\n",
      "Iteration 46850, Loss: 0.000000345\n",
      "Iteration 46860, Loss: 0.000000702\n",
      "Iteration 46870, Loss: 0.000000503\n",
      "Iteration 46880, Loss: 0.000000983\n",
      "Iteration 46890, Loss: 0.000000550\n",
      "Iteration 46900, Loss: 0.000000522\n",
      "Iteration 46910, Loss: 0.000000356\n",
      "Iteration 46920, Loss: 0.000000359\n",
      "Iteration 46930, Loss: 0.000000325\n",
      "Iteration 46940, Loss: 0.000000331\n",
      "Iteration 46950, Loss: 0.000000372\n",
      "Iteration 46960, Loss: 0.000001075\n",
      "Iteration 46970, Loss: 0.000000504\n",
      "Iteration 46980, Loss: 0.000000629\n",
      "Iteration 46990, Loss: 0.000000357\n",
      "Iteration 47000, Loss: 0.000000362\n",
      "Iteration 47010, Loss: 0.000000335\n",
      "Iteration 47020, Loss: 0.000000339\n",
      "Iteration 47030, Loss: 0.000000366\n",
      "Iteration 47040, Loss: 0.000000642\n",
      "Iteration 47050, Loss: 0.000001029\n",
      "Iteration 47060, Loss: 0.000000440\n",
      "Iteration 47070, Loss: 0.000000402\n",
      "Iteration 47080, Loss: 0.000000350\n",
      "Iteration 47090, Loss: 0.000000337\n",
      "Iteration 47100, Loss: 0.000000370\n",
      "Iteration 47110, Loss: 0.000000800\n",
      "Iteration 47120, Loss: 0.000000776\n",
      "Iteration 47130, Loss: 0.000000619\n",
      "Iteration 47140, Loss: 0.000000496\n",
      "Iteration 47150, Loss: 0.000000427\n",
      "Iteration 47160, Loss: 0.000000620\n",
      "Iteration 47170, Loss: 0.000000464\n",
      "Iteration 47180, Loss: 0.000000401\n",
      "Iteration 47190, Loss: 0.000000373\n",
      "Iteration 47200, Loss: 0.000000355\n",
      "Iteration 47210, Loss: 0.000001251\n",
      "Iteration 47220, Loss: 0.000000992\n",
      "Iteration 47230, Loss: 0.000000376\n",
      "Iteration 47240, Loss: 0.000000517\n",
      "Iteration 47250, Loss: 0.000000426\n",
      "Iteration 47260, Loss: 0.000000357\n",
      "Iteration 47270, Loss: 0.000000360\n",
      "Iteration 47280, Loss: 0.000000405\n",
      "Iteration 47290, Loss: 0.000000711\n",
      "Iteration 47300, Loss: 0.000000900\n",
      "Iteration 47310, Loss: 0.000000662\n",
      "Iteration 47320, Loss: 0.000000450\n",
      "Iteration 47330, Loss: 0.000000360\n",
      "Iteration 47340, Loss: 0.000000445\n",
      "Iteration 47350, Loss: 0.000000354\n",
      "Iteration 47360, Loss: 0.000000353\n",
      "Iteration 47370, Loss: 0.000000570\n",
      "Iteration 47380, Loss: 0.000001911\n",
      "Iteration 47390, Loss: 0.000000784\n",
      "Iteration 47400, Loss: 0.000000389\n",
      "Iteration 47410, Loss: 0.000000342\n",
      "Iteration 47420, Loss: 0.000000327\n",
      "Iteration 47430, Loss: 0.000000326\n",
      "Iteration 47440, Loss: 0.000000325\n",
      "Iteration 47450, Loss: 0.000000327\n",
      "Iteration 47460, Loss: 0.000000552\n",
      "Iteration 47470, Loss: 0.000001275\n",
      "Iteration 47480, Loss: 0.000000779\n",
      "Iteration 47490, Loss: 0.000000449\n",
      "Iteration 47500, Loss: 0.000000345\n",
      "Iteration 47510, Loss: 0.000000329\n",
      "Iteration 47520, Loss: 0.000000330\n",
      "Iteration 47530, Loss: 0.000000329\n",
      "Iteration 47540, Loss: 0.000000403\n",
      "Iteration 47550, Loss: 0.000001929\n",
      "Iteration 47560, Loss: 0.000000745\n",
      "Iteration 47570, Loss: 0.000000578\n",
      "Iteration 47580, Loss: 0.000000416\n",
      "Iteration 47590, Loss: 0.000000357\n",
      "Iteration 47600, Loss: 0.000000339\n",
      "Iteration 47610, Loss: 0.000000338\n",
      "Iteration 47620, Loss: 0.000000376\n",
      "Iteration 47630, Loss: 0.000000696\n",
      "Iteration 47640, Loss: 0.000001052\n",
      "Iteration 47650, Loss: 0.000000733\n",
      "Iteration 47660, Loss: 0.000000459\n",
      "Iteration 47670, Loss: 0.000000376\n",
      "Iteration 47680, Loss: 0.000000337\n",
      "Iteration 47690, Loss: 0.000000325\n",
      "Iteration 47700, Loss: 0.000000328\n",
      "Iteration 47710, Loss: 0.000000367\n",
      "Iteration 47720, Loss: 0.000000957\n",
      "Iteration 47730, Loss: 0.000000718\n",
      "Iteration 47740, Loss: 0.000000629\n",
      "Iteration 47750, Loss: 0.000000327\n",
      "Iteration 47760, Loss: 0.000000383\n",
      "Iteration 47770, Loss: 0.000000424\n",
      "Iteration 47780, Loss: 0.000000565\n",
      "Iteration 47790, Loss: 0.000000705\n",
      "Iteration 47800, Loss: 0.000000330\n",
      "Iteration 47810, Loss: 0.000000398\n",
      "Iteration 47820, Loss: 0.000000394\n",
      "Iteration 47830, Loss: 0.000000464\n",
      "Iteration 47840, Loss: 0.000001027\n",
      "Iteration 47850, Loss: 0.000000443\n",
      "Iteration 47860, Loss: 0.000000582\n",
      "Iteration 47870, Loss: 0.000000673\n",
      "Iteration 47880, Loss: 0.000000361\n",
      "Iteration 47890, Loss: 0.000000387\n",
      "Iteration 47900, Loss: 0.000000408\n",
      "Iteration 47910, Loss: 0.000000578\n",
      "Iteration 47920, Loss: 0.000000792\n",
      "Iteration 47930, Loss: 0.000000399\n",
      "Iteration 47940, Loss: 0.000000407\n",
      "Iteration 47950, Loss: 0.000000368\n",
      "Iteration 47960, Loss: 0.000000856\n",
      "Iteration 47970, Loss: 0.000001028\n",
      "Iteration 47980, Loss: 0.000000571\n",
      "Iteration 47990, Loss: 0.000000394\n",
      "Iteration 48000, Loss: 0.000000333\n",
      "Iteration 48010, Loss: 0.000000336\n",
      "Iteration 48020, Loss: 0.000000350\n",
      "Iteration 48030, Loss: 0.000000495\n",
      "Iteration 48040, Loss: 0.000001080\n",
      "Iteration 48050, Loss: 0.000000934\n",
      "Iteration 48060, Loss: 0.000000495\n",
      "Iteration 48070, Loss: 0.000000394\n",
      "Iteration 48080, Loss: 0.000000344\n",
      "Iteration 48090, Loss: 0.000000350\n",
      "Iteration 48100, Loss: 0.000000444\n",
      "Iteration 48110, Loss: 0.000001167\n",
      "Iteration 48120, Loss: 0.000000337\n",
      "Iteration 48130, Loss: 0.000000391\n",
      "Iteration 48140, Loss: 0.000000382\n",
      "Iteration 48150, Loss: 0.000000334\n",
      "Iteration 48160, Loss: 0.000000360\n",
      "Iteration 48170, Loss: 0.000000807\n",
      "Iteration 48180, Loss: 0.000000549\n",
      "Iteration 48190, Loss: 0.000001171\n",
      "Iteration 48200, Loss: 0.000000573\n",
      "Iteration 48210, Loss: 0.000000464\n",
      "Iteration 48220, Loss: 0.000000508\n",
      "Iteration 48230, Loss: 0.000000585\n",
      "Iteration 48240, Loss: 0.000000426\n",
      "Iteration 48250, Loss: 0.000000332\n",
      "Iteration 48260, Loss: 0.000000324\n",
      "Iteration 48270, Loss: 0.000000344\n",
      "Iteration 48280, Loss: 0.000001069\n",
      "Iteration 48290, Loss: 0.000000472\n",
      "Iteration 48300, Loss: 0.000000541\n",
      "Iteration 48310, Loss: 0.000000534\n",
      "Iteration 48320, Loss: 0.000000380\n",
      "Iteration 48330, Loss: 0.000000332\n",
      "Iteration 48340, Loss: 0.000000348\n",
      "Iteration 48350, Loss: 0.000000592\n",
      "Iteration 48360, Loss: 0.000000436\n",
      "Iteration 48370, Loss: 0.000000394\n",
      "Iteration 48380, Loss: 0.000000354\n",
      "Iteration 48390, Loss: 0.000000396\n",
      "Iteration 48400, Loss: 0.000000675\n",
      "Iteration 48410, Loss: 0.000000355\n",
      "Iteration 48420, Loss: 0.000000394\n",
      "Iteration 48430, Loss: 0.000000377\n",
      "Iteration 48440, Loss: 0.000000966\n",
      "Iteration 48450, Loss: 0.000000677\n",
      "Iteration 48460, Loss: 0.000000483\n",
      "Iteration 48470, Loss: 0.000000394\n",
      "Iteration 48480, Loss: 0.000000360\n",
      "Iteration 48490, Loss: 0.000000346\n",
      "Iteration 48500, Loss: 0.000000568\n",
      "Iteration 48510, Loss: 0.000000853\n",
      "Iteration 48520, Loss: 0.000000446\n",
      "Iteration 48530, Loss: 0.000000346\n",
      "Iteration 48540, Loss: 0.000000349\n",
      "Iteration 48550, Loss: 0.000000721\n",
      "Iteration 48560, Loss: 0.000001476\n",
      "Iteration 48570, Loss: 0.000000639\n",
      "Iteration 48580, Loss: 0.000000375\n",
      "Iteration 48590, Loss: 0.000000343\n",
      "Iteration 48600, Loss: 0.000000327\n",
      "Iteration 48610, Loss: 0.000000326\n",
      "Iteration 48620, Loss: 0.000000344\n",
      "Iteration 48630, Loss: 0.000000640\n",
      "Iteration 48640, Loss: 0.000001011\n",
      "Iteration 48650, Loss: 0.000000540\n",
      "Iteration 48660, Loss: 0.000000385\n",
      "Iteration 48670, Loss: 0.000000358\n",
      "Iteration 48680, Loss: 0.000000333\n",
      "Iteration 48690, Loss: 0.000000392\n",
      "Iteration 48700, Loss: 0.000001579\n",
      "Iteration 48710, Loss: 0.000000612\n",
      "Iteration 48720, Loss: 0.000000515\n",
      "Iteration 48730, Loss: 0.000000349\n",
      "Iteration 48740, Loss: 0.000000331\n",
      "Iteration 48750, Loss: 0.000000330\n",
      "Iteration 48760, Loss: 0.000000365\n",
      "Iteration 48770, Loss: 0.000001353\n",
      "Iteration 48780, Loss: 0.000000474\n",
      "Iteration 48790, Loss: 0.000000622\n",
      "Iteration 48800, Loss: 0.000000469\n",
      "Iteration 48810, Loss: 0.000000345\n",
      "Iteration 48820, Loss: 0.000000337\n",
      "Iteration 48830, Loss: 0.000000326\n",
      "Iteration 48840, Loss: 0.000000329\n",
      "Iteration 48850, Loss: 0.000000457\n",
      "Iteration 48860, Loss: 0.000000813\n",
      "Iteration 48870, Loss: 0.000000515\n",
      "Iteration 48880, Loss: 0.000000381\n",
      "Iteration 48890, Loss: 0.000000344\n",
      "Iteration 48900, Loss: 0.000000330\n",
      "Iteration 48910, Loss: 0.000000323\n",
      "Iteration 48920, Loss: 0.000000339\n",
      "Iteration 48930, Loss: 0.000002221\n",
      "Iteration 48940, Loss: 0.000001660\n",
      "Iteration 48950, Loss: 0.000000613\n",
      "Iteration 48960, Loss: 0.000000409\n",
      "Iteration 48970, Loss: 0.000000335\n",
      "Iteration 48980, Loss: 0.000000329\n",
      "Iteration 48990, Loss: 0.000000324\n",
      "Iteration 49000, Loss: 0.000000322\n",
      "Iteration 49010, Loss: 0.000000321\n",
      "Iteration 49020, Loss: 0.000000333\n",
      "Iteration 49030, Loss: 0.000000509\n",
      "Iteration 49040, Loss: 0.000000444\n",
      "Iteration 49050, Loss: 0.000000941\n",
      "Iteration 49060, Loss: 0.000000516\n",
      "Iteration 49070, Loss: 0.000000384\n",
      "Iteration 49080, Loss: 0.000000344\n",
      "Iteration 49090, Loss: 0.000000337\n",
      "Iteration 49100, Loss: 0.000000333\n",
      "Iteration 49110, Loss: 0.000000325\n",
      "Iteration 49120, Loss: 0.000000361\n",
      "Iteration 49130, Loss: 0.000000824\n",
      "Iteration 49140, Loss: 0.000000479\n",
      "Iteration 49150, Loss: 0.000000427\n",
      "Iteration 49160, Loss: 0.000000652\n",
      "Iteration 49170, Loss: 0.000000658\n",
      "Iteration 49180, Loss: 0.000000359\n",
      "Iteration 49190, Loss: 0.000000402\n",
      "Iteration 49200, Loss: 0.000000329\n",
      "Iteration 49210, Loss: 0.000000472\n",
      "Iteration 49220, Loss: 0.000000866\n",
      "Iteration 49230, Loss: 0.000000496\n",
      "Iteration 49240, Loss: 0.000000515\n",
      "Iteration 49250, Loss: 0.000002162\n",
      "Iteration 49260, Loss: 0.000000931\n",
      "Iteration 49270, Loss: 0.000000510\n",
      "Iteration 49280, Loss: 0.000000358\n",
      "Iteration 49290, Loss: 0.000000330\n",
      "Iteration 49300, Loss: 0.000000323\n",
      "Iteration 49310, Loss: 0.000000321\n",
      "Iteration 49320, Loss: 0.000000320\n",
      "Iteration 49330, Loss: 0.000000319\n",
      "Iteration 49340, Loss: 0.000000320\n",
      "Iteration 49350, Loss: 0.000000329\n",
      "Iteration 49360, Loss: 0.000000938\n",
      "Iteration 49370, Loss: 0.000001350\n",
      "Iteration 49380, Loss: 0.000000677\n",
      "Iteration 49390, Loss: 0.000000466\n",
      "Iteration 49400, Loss: 0.000000383\n",
      "Iteration 49410, Loss: 0.000000334\n",
      "Iteration 49420, Loss: 0.000000355\n",
      "Iteration 49430, Loss: 0.000003781\n",
      "Iteration 49440, Loss: 0.000001878\n",
      "Iteration 49450, Loss: 0.000000524\n",
      "Iteration 49460, Loss: 0.000000364\n",
      "Iteration 49470, Loss: 0.000000376\n",
      "Iteration 49480, Loss: 0.000000330\n",
      "Iteration 49490, Loss: 0.000000322\n",
      "Iteration 49500, Loss: 0.000000322\n",
      "Iteration 49510, Loss: 0.000000319\n",
      "Iteration 49520, Loss: 0.000000319\n",
      "Iteration 49530, Loss: 0.000000319\n",
      "Iteration 49540, Loss: 0.000000319\n",
      "Iteration 49550, Loss: 0.000000319\n",
      "Iteration 49560, Loss: 0.000000322\n",
      "Iteration 49570, Loss: 0.000000581\n",
      "Iteration 49580, Loss: 0.000000553\n",
      "Iteration 49590, Loss: 0.000000639\n",
      "Iteration 49600, Loss: 0.000000356\n",
      "Iteration 49610, Loss: 0.000000359\n",
      "Iteration 49620, Loss: 0.000000321\n",
      "Iteration 49630, Loss: 0.000000324\n",
      "Iteration 49640, Loss: 0.000000319\n",
      "Iteration 49650, Loss: 0.000000348\n",
      "Iteration 49660, Loss: 0.000000430\n",
      "Iteration 49670, Loss: 0.000001299\n",
      "Iteration 49680, Loss: 0.000000367\n",
      "Iteration 49690, Loss: 0.000000483\n",
      "Iteration 49700, Loss: 0.000000435\n",
      "Iteration 49710, Loss: 0.000000355\n",
      "Iteration 49720, Loss: 0.000000328\n",
      "Iteration 49730, Loss: 0.000000325\n",
      "Iteration 49740, Loss: 0.000000377\n",
      "Iteration 49750, Loss: 0.000000542\n",
      "Iteration 49760, Loss: 0.000000894\n",
      "Iteration 49770, Loss: 0.000000475\n",
      "Iteration 49780, Loss: 0.000000368\n",
      "Iteration 49790, Loss: 0.000000335\n",
      "Iteration 49800, Loss: 0.000000326\n",
      "Iteration 49810, Loss: 0.000000464\n",
      "Iteration 49820, Loss: 0.000002677\n",
      "Iteration 49830, Loss: 0.000000954\n",
      "Iteration 49840, Loss: 0.000000336\n",
      "Iteration 49850, Loss: 0.000000373\n",
      "Iteration 49860, Loss: 0.000000347\n",
      "Iteration 49870, Loss: 0.000000328\n",
      "Iteration 49880, Loss: 0.000000374\n",
      "Iteration 49890, Loss: 0.000001505\n",
      "Iteration 49900, Loss: 0.000000759\n",
      "Iteration 49910, Loss: 0.000000475\n",
      "Iteration 49920, Loss: 0.000000525\n",
      "Iteration 49930, Loss: 0.000000339\n",
      "Iteration 49940, Loss: 0.000000359\n",
      "Iteration 49950, Loss: 0.000000336\n",
      "Iteration 49960, Loss: 0.000000327\n",
      "Iteration 49970, Loss: 0.000000355\n",
      "Iteration 49980, Loss: 0.000000979\n",
      "Iteration 49990, Loss: 0.000000546\n",
      "Iteration 50000, Loss: 0.000000456\n",
      "Iteration 50010, Loss: 0.000000401\n",
      "Iteration 50020, Loss: 0.000000344\n",
      "Iteration 50030, Loss: 0.000000325\n",
      "Iteration 50040, Loss: 0.000000335\n",
      "Iteration 50050, Loss: 0.000000646\n",
      "Iteration 50060, Loss: 0.000001478\n",
      "Iteration 50070, Loss: 0.000000642\n",
      "Iteration 50080, Loss: 0.000000415\n",
      "Iteration 50090, Loss: 0.000000361\n",
      "Iteration 50100, Loss: 0.000000331\n",
      "Iteration 50110, Loss: 0.000000328\n",
      "Iteration 50120, Loss: 0.000000368\n",
      "Iteration 50130, Loss: 0.000001373\n",
      "Iteration 50140, Loss: 0.000000686\n",
      "Iteration 50150, Loss: 0.000000446\n",
      "Iteration 50160, Loss: 0.000000397\n",
      "Iteration 50170, Loss: 0.000001142\n",
      "Iteration 50180, Loss: 0.000000332\n",
      "Iteration 50190, Loss: 0.000000347\n",
      "Iteration 50200, Loss: 0.000000355\n",
      "Iteration 50210, Loss: 0.000000381\n",
      "Iteration 50220, Loss: 0.000000393\n",
      "Iteration 50230, Loss: 0.000000414\n",
      "Iteration 50240, Loss: 0.000000337\n",
      "Iteration 50250, Loss: 0.000000333\n",
      "Iteration 50260, Loss: 0.000000397\n",
      "Iteration 50270, Loss: 0.000001375\n",
      "Iteration 50280, Loss: 0.000000511\n",
      "Iteration 50290, Loss: 0.000000405\n",
      "Iteration 50300, Loss: 0.000000383\n",
      "Iteration 50310, Loss: 0.000000351\n",
      "Iteration 50320, Loss: 0.000000335\n",
      "Iteration 50330, Loss: 0.000000452\n",
      "Iteration 50340, Loss: 0.000000717\n",
      "Iteration 50350, Loss: 0.000000779\n",
      "Iteration 50360, Loss: 0.000000425\n",
      "Iteration 50370, Loss: 0.000000490\n",
      "Iteration 50380, Loss: 0.000000676\n",
      "Iteration 50390, Loss: 0.000000402\n",
      "Iteration 50400, Loss: 0.000000346\n",
      "Iteration 50410, Loss: 0.000000400\n",
      "Iteration 50420, Loss: 0.000000565\n",
      "Iteration 50430, Loss: 0.000000740\n",
      "Iteration 50440, Loss: 0.000000389\n",
      "Iteration 50450, Loss: 0.000000599\n",
      "Iteration 50460, Loss: 0.000000490\n",
      "Iteration 50470, Loss: 0.000000850\n",
      "Iteration 50480, Loss: 0.000000435\n",
      "Iteration 50490, Loss: 0.000000400\n",
      "Iteration 50500, Loss: 0.000000355\n",
      "Iteration 50510, Loss: 0.000000350\n",
      "Iteration 50520, Loss: 0.000000553\n",
      "Iteration 50530, Loss: 0.000000716\n",
      "Iteration 50540, Loss: 0.000000774\n",
      "Iteration 50550, Loss: 0.000000975\n",
      "Iteration 50560, Loss: 0.000000619\n",
      "Iteration 50570, Loss: 0.000000532\n",
      "Iteration 50580, Loss: 0.000000412\n",
      "Iteration 50590, Loss: 0.000000349\n",
      "Iteration 50600, Loss: 0.000000320\n",
      "Iteration 50610, Loss: 0.000000321\n",
      "Iteration 50620, Loss: 0.000000317\n",
      "Iteration 50630, Loss: 0.000000322\n",
      "Iteration 50640, Loss: 0.000000418\n",
      "Iteration 50650, Loss: 0.000001154\n",
      "Iteration 50660, Loss: 0.000000565\n",
      "Iteration 50670, Loss: 0.000000355\n",
      "Iteration 50680, Loss: 0.000000355\n",
      "Iteration 50690, Loss: 0.000000338\n",
      "Iteration 50700, Loss: 0.000000327\n",
      "Iteration 50710, Loss: 0.000000341\n",
      "Iteration 50720, Loss: 0.000000701\n",
      "Iteration 50730, Loss: 0.000000400\n",
      "Iteration 50740, Loss: 0.000000392\n",
      "Iteration 50750, Loss: 0.000000560\n",
      "Iteration 50760, Loss: 0.000000795\n",
      "Iteration 50770, Loss: 0.000000375\n",
      "Iteration 50780, Loss: 0.000000428\n",
      "Iteration 50790, Loss: 0.000000337\n",
      "Iteration 50800, Loss: 0.000000319\n",
      "Iteration 50810, Loss: 0.000000341\n",
      "Iteration 50820, Loss: 0.000000692\n",
      "Iteration 50830, Loss: 0.000001311\n",
      "Iteration 50840, Loss: 0.000000581\n",
      "Iteration 50850, Loss: 0.000000389\n",
      "Iteration 50860, Loss: 0.000000333\n",
      "Iteration 50870, Loss: 0.000000355\n",
      "Iteration 50880, Loss: 0.000000630\n",
      "Iteration 50890, Loss: 0.000000482\n",
      "Iteration 50900, Loss: 0.000000456\n",
      "Iteration 50910, Loss: 0.000000525\n",
      "Iteration 50920, Loss: 0.000000408\n",
      "Iteration 50930, Loss: 0.000000358\n",
      "Iteration 50940, Loss: 0.000000345\n",
      "Iteration 50950, Loss: 0.000000368\n",
      "Iteration 50960, Loss: 0.000001232\n",
      "Iteration 50970, Loss: 0.000000414\n",
      "Iteration 50980, Loss: 0.000000382\n",
      "Iteration 50990, Loss: 0.000000386\n",
      "Iteration 51000, Loss: 0.000000349\n",
      "Iteration 51010, Loss: 0.000000325\n",
      "Iteration 51020, Loss: 0.000000319\n",
      "Iteration 51030, Loss: 0.000000363\n",
      "Iteration 51040, Loss: 0.000002112\n",
      "Iteration 51050, Loss: 0.000000789\n",
      "Iteration 51060, Loss: 0.000000465\n",
      "Iteration 51070, Loss: 0.000000500\n",
      "Iteration 51080, Loss: 0.000000690\n",
      "Iteration 51090, Loss: 0.000000376\n",
      "Iteration 51100, Loss: 0.000000332\n",
      "Iteration 51110, Loss: 0.000000360\n",
      "Iteration 51120, Loss: 0.000000612\n",
      "Iteration 51130, Loss: 0.000001255\n",
      "Iteration 51140, Loss: 0.000000646\n",
      "Iteration 51150, Loss: 0.000000423\n",
      "Iteration 51160, Loss: 0.000000334\n",
      "Iteration 51170, Loss: 0.000000317\n",
      "Iteration 51180, Loss: 0.000000330\n",
      "Iteration 51190, Loss: 0.000000455\n",
      "Iteration 51200, Loss: 0.000001025\n",
      "Iteration 51210, Loss: 0.000000681\n",
      "Iteration 51220, Loss: 0.000000442\n",
      "Iteration 51230, Loss: 0.000000364\n",
      "Iteration 51240, Loss: 0.000000330\n",
      "Iteration 51250, Loss: 0.000000515\n",
      "Iteration 51260, Loss: 0.000001777\n",
      "Iteration 51270, Loss: 0.000000800\n",
      "Iteration 51280, Loss: 0.000000504\n",
      "Iteration 51290, Loss: 0.000000388\n",
      "Iteration 51300, Loss: 0.000000357\n",
      "Iteration 51310, Loss: 0.000000547\n",
      "Iteration 51320, Loss: 0.000000449\n",
      "Iteration 51330, Loss: 0.000000357\n",
      "Iteration 51340, Loss: 0.000000334\n",
      "Iteration 51350, Loss: 0.000000344\n",
      "Iteration 51360, Loss: 0.000000902\n",
      "Iteration 51370, Loss: 0.000000544\n",
      "Iteration 51380, Loss: 0.000000475\n",
      "Iteration 51390, Loss: 0.000000402\n",
      "Iteration 51400, Loss: 0.000000392\n",
      "Iteration 51410, Loss: 0.000000736\n",
      "Iteration 51420, Loss: 0.000000580\n",
      "Iteration 51430, Loss: 0.000000361\n",
      "Iteration 51440, Loss: 0.000000379\n",
      "Iteration 51450, Loss: 0.000000512\n",
      "Iteration 51460, Loss: 0.000000677\n",
      "Iteration 51470, Loss: 0.000000344\n",
      "Iteration 51480, Loss: 0.000000367\n",
      "Iteration 51490, Loss: 0.000000457\n",
      "Iteration 51500, Loss: 0.000000560\n",
      "Iteration 51510, Loss: 0.000000482\n",
      "Iteration 51520, Loss: 0.000000332\n",
      "Iteration 51530, Loss: 0.000000503\n",
      "Iteration 51540, Loss: 0.000000585\n",
      "Iteration 51550, Loss: 0.000001512\n",
      "Iteration 51560, Loss: 0.000000710\n",
      "Iteration 51570, Loss: 0.000000511\n",
      "Iteration 51580, Loss: 0.000000466\n",
      "Iteration 51590, Loss: 0.000000746\n",
      "Iteration 51600, Loss: 0.000000363\n",
      "Iteration 51610, Loss: 0.000000403\n",
      "Iteration 51620, Loss: 0.000000345\n",
      "Iteration 51630, Loss: 0.000000432\n",
      "Iteration 51640, Loss: 0.000000817\n",
      "Iteration 51650, Loss: 0.000000650\n",
      "Iteration 51660, Loss: 0.000000425\n",
      "Iteration 51670, Loss: 0.000000401\n",
      "Iteration 51680, Loss: 0.000000328\n",
      "Iteration 51690, Loss: 0.000000340\n",
      "Iteration 51700, Loss: 0.000000403\n",
      "Iteration 51710, Loss: 0.000001608\n",
      "Iteration 51720, Loss: 0.000000597\n",
      "Iteration 51730, Loss: 0.000000522\n",
      "Iteration 51740, Loss: 0.000000415\n",
      "Iteration 51750, Loss: 0.000000349\n",
      "Iteration 51760, Loss: 0.000000326\n",
      "Iteration 51770, Loss: 0.000000318\n",
      "Iteration 51780, Loss: 0.000000322\n",
      "Iteration 51790, Loss: 0.000000703\n",
      "Iteration 51800, Loss: 0.000000966\n",
      "Iteration 51810, Loss: 0.000000831\n",
      "Iteration 51820, Loss: 0.000000425\n",
      "Iteration 51830, Loss: 0.000000360\n",
      "Iteration 51840, Loss: 0.000000347\n",
      "Iteration 51850, Loss: 0.000000358\n",
      "Iteration 51860, Loss: 0.000000692\n",
      "Iteration 51870, Loss: 0.000000344\n",
      "Iteration 51880, Loss: 0.000000380\n",
      "Iteration 51890, Loss: 0.000000782\n",
      "Iteration 51900, Loss: 0.000000650\n",
      "Iteration 51910, Loss: 0.000000518\n",
      "Iteration 51920, Loss: 0.000000352\n",
      "Iteration 51930, Loss: 0.000000337\n",
      "Iteration 51940, Loss: 0.000000317\n",
      "Iteration 51950, Loss: 0.000000324\n",
      "Iteration 51960, Loss: 0.000000449\n",
      "Iteration 51970, Loss: 0.000001315\n",
      "Iteration 51980, Loss: 0.000000935\n",
      "Iteration 51990, Loss: 0.000000605\n",
      "Iteration 52000, Loss: 0.000000388\n",
      "Iteration 52010, Loss: 0.000000333\n",
      "Iteration 52020, Loss: 0.000000330\n",
      "Iteration 52030, Loss: 0.000000317\n",
      "Iteration 52040, Loss: 0.000000315\n",
      "Iteration 52050, Loss: 0.000000314\n",
      "Iteration 52060, Loss: 0.000000317\n",
      "Iteration 52070, Loss: 0.000000545\n",
      "Iteration 52080, Loss: 0.000002616\n",
      "Iteration 52090, Loss: 0.000000400\n",
      "Iteration 52100, Loss: 0.000000651\n",
      "Iteration 52110, Loss: 0.000000349\n",
      "Iteration 52120, Loss: 0.000000351\n",
      "Iteration 52130, Loss: 0.000000320\n",
      "Iteration 52140, Loss: 0.000000319\n",
      "Iteration 52150, Loss: 0.000000316\n",
      "Iteration 52160, Loss: 0.000000423\n",
      "Iteration 52170, Loss: 0.000001613\n",
      "Iteration 52180, Loss: 0.000000420\n",
      "Iteration 52190, Loss: 0.000000468\n",
      "Iteration 52200, Loss: 0.000000333\n",
      "Iteration 52210, Loss: 0.000000332\n",
      "Iteration 52220, Loss: 0.000000356\n",
      "Iteration 52230, Loss: 0.000000983\n",
      "Iteration 52240, Loss: 0.000000397\n",
      "Iteration 52250, Loss: 0.000000356\n",
      "Iteration 52260, Loss: 0.000000349\n",
      "Iteration 52270, Loss: 0.000000324\n",
      "Iteration 52280, Loss: 0.000000321\n",
      "Iteration 52290, Loss: 0.000000334\n",
      "Iteration 52300, Loss: 0.000000903\n",
      "Iteration 52310, Loss: 0.000001165\n",
      "Iteration 52320, Loss: 0.000000456\n",
      "Iteration 52330, Loss: 0.000000392\n",
      "Iteration 52340, Loss: 0.000000373\n",
      "Iteration 52350, Loss: 0.000000319\n",
      "Iteration 52360, Loss: 0.000000319\n",
      "Iteration 52370, Loss: 0.000000334\n",
      "Iteration 52380, Loss: 0.000000516\n",
      "Iteration 52390, Loss: 0.000001531\n",
      "Iteration 52400, Loss: 0.000000658\n",
      "Iteration 52410, Loss: 0.000000428\n",
      "Iteration 52420, Loss: 0.000000342\n",
      "Iteration 52430, Loss: 0.000000315\n",
      "Iteration 52440, Loss: 0.000000332\n",
      "Iteration 52450, Loss: 0.000000783\n",
      "Iteration 52460, Loss: 0.000000445\n",
      "Iteration 52470, Loss: 0.000000539\n",
      "Iteration 52480, Loss: 0.000000373\n",
      "Iteration 52490, Loss: 0.000000339\n",
      "Iteration 52500, Loss: 0.000000520\n",
      "Iteration 52510, Loss: 0.000001483\n",
      "Iteration 52520, Loss: 0.000000704\n",
      "Iteration 52530, Loss: 0.000000458\n",
      "Iteration 52540, Loss: 0.000000355\n",
      "Iteration 52550, Loss: 0.000000322\n",
      "Iteration 52560, Loss: 0.000000316\n",
      "Iteration 52570, Loss: 0.000000321\n",
      "Iteration 52580, Loss: 0.000000375\n",
      "Iteration 52590, Loss: 0.000001522\n",
      "Iteration 52600, Loss: 0.000000722\n",
      "Iteration 52610, Loss: 0.000000443\n",
      "Iteration 52620, Loss: 0.000000355\n",
      "Iteration 52630, Loss: 0.000000327\n",
      "Iteration 52640, Loss: 0.000000323\n",
      "Iteration 52650, Loss: 0.000000383\n",
      "Iteration 52660, Loss: 0.000001542\n",
      "Iteration 52670, Loss: 0.000000452\n",
      "Iteration 52680, Loss: 0.000000442\n",
      "Iteration 52690, Loss: 0.000000379\n",
      "Iteration 52700, Loss: 0.000000334\n",
      "Iteration 52710, Loss: 0.000000319\n",
      "Iteration 52720, Loss: 0.000000318\n",
      "Iteration 52730, Loss: 0.000000350\n",
      "Iteration 52740, Loss: 0.000001636\n",
      "Iteration 52750, Loss: 0.000000846\n",
      "Iteration 52760, Loss: 0.000000483\n",
      "Iteration 52770, Loss: 0.000000410\n",
      "Iteration 52780, Loss: 0.000000335\n",
      "Iteration 52790, Loss: 0.000000320\n",
      "Iteration 52800, Loss: 0.000000318\n",
      "Iteration 52810, Loss: 0.000000317\n",
      "Iteration 52820, Loss: 0.000000339\n",
      "Iteration 52830, Loss: 0.000000805\n",
      "Iteration 52840, Loss: 0.000000807\n",
      "Iteration 52850, Loss: 0.000000443\n",
      "Iteration 52860, Loss: 0.000000350\n",
      "Iteration 52870, Loss: 0.000000336\n",
      "Iteration 52880, Loss: 0.000000368\n",
      "Iteration 52890, Loss: 0.000000612\n",
      "Iteration 52900, Loss: 0.000000453\n",
      "Iteration 52910, Loss: 0.000000366\n",
      "Iteration 52920, Loss: 0.000000356\n",
      "Iteration 52930, Loss: 0.000000336\n",
      "Iteration 52940, Loss: 0.000000369\n",
      "Iteration 52950, Loss: 0.000000642\n",
      "Iteration 52960, Loss: 0.000000619\n",
      "Iteration 52970, Loss: 0.000001998\n",
      "Iteration 52980, Loss: 0.000000705\n",
      "Iteration 52990, Loss: 0.000000516\n",
      "Iteration 53000, Loss: 0.000000390\n",
      "Iteration 53010, Loss: 0.000000340\n",
      "Iteration 53020, Loss: 0.000000323\n",
      "Iteration 53030, Loss: 0.000000316\n",
      "Iteration 53040, Loss: 0.000000313\n",
      "Iteration 53050, Loss: 0.000000317\n",
      "Iteration 53060, Loss: 0.000000552\n",
      "Iteration 53070, Loss: 0.000000629\n",
      "Iteration 53080, Loss: 0.000000468\n",
      "Iteration 53090, Loss: 0.000000973\n",
      "Iteration 53100, Loss: 0.000000380\n",
      "Iteration 53110, Loss: 0.000000511\n",
      "Iteration 53120, Loss: 0.000000367\n",
      "Iteration 53130, Loss: 0.000000380\n",
      "Iteration 53140, Loss: 0.000000539\n",
      "Iteration 53150, Loss: 0.000000536\n",
      "Iteration 53160, Loss: 0.000000564\n",
      "Iteration 53170, Loss: 0.000000953\n",
      "Iteration 53180, Loss: 0.000000349\n",
      "Iteration 53190, Loss: 0.000000394\n",
      "Iteration 53200, Loss: 0.000000338\n",
      "Iteration 53210, Loss: 0.000000359\n",
      "Iteration 53220, Loss: 0.000000522\n",
      "Iteration 53230, Loss: 0.000000990\n",
      "Iteration 53240, Loss: 0.000000749\n",
      "Iteration 53250, Loss: 0.000000543\n",
      "Iteration 53260, Loss: 0.000000409\n",
      "Iteration 53270, Loss: 0.000000334\n",
      "Iteration 53280, Loss: 0.000000318\n",
      "Iteration 53290, Loss: 0.000000317\n",
      "Iteration 53300, Loss: 0.000000370\n",
      "Iteration 53310, Loss: 0.000001792\n",
      "Iteration 53320, Loss: 0.000001069\n",
      "Iteration 53330, Loss: 0.000000451\n",
      "Iteration 53340, Loss: 0.000000370\n",
      "Iteration 53350, Loss: 0.000000338\n",
      "Iteration 53360, Loss: 0.000000415\n",
      "Iteration 53370, Loss: 0.000001065\n",
      "Iteration 53380, Loss: 0.000000347\n",
      "Iteration 53390, Loss: 0.000000420\n",
      "Iteration 53400, Loss: 0.000000424\n",
      "Iteration 53410, Loss: 0.000000384\n",
      "Iteration 53420, Loss: 0.000000397\n",
      "Iteration 53430, Loss: 0.000000377\n",
      "Iteration 53440, Loss: 0.000000503\n",
      "Iteration 53450, Loss: 0.000000756\n",
      "Iteration 53460, Loss: 0.000000445\n",
      "Iteration 53470, Loss: 0.000000506\n",
      "Iteration 53480, Loss: 0.000000554\n",
      "Iteration 53490, Loss: 0.000000411\n",
      "Iteration 53500, Loss: 0.000000329\n",
      "Iteration 53510, Loss: 0.000000337\n",
      "Iteration 53520, Loss: 0.000000523\n",
      "Iteration 53530, Loss: 0.000001808\n",
      "Iteration 53540, Loss: 0.000001011\n",
      "Iteration 53550, Loss: 0.000000494\n",
      "Iteration 53560, Loss: 0.000000358\n",
      "Iteration 53570, Loss: 0.000000340\n",
      "Iteration 53580, Loss: 0.000000383\n",
      "Iteration 53590, Loss: 0.000000651\n",
      "Iteration 53600, Loss: 0.000000384\n",
      "Iteration 53610, Loss: 0.000000436\n",
      "Iteration 53620, Loss: 0.000000776\n",
      "Iteration 53630, Loss: 0.000000661\n",
      "Iteration 53640, Loss: 0.000000505\n",
      "Iteration 53650, Loss: 0.000000339\n",
      "Iteration 53660, Loss: 0.000000331\n",
      "Iteration 53670, Loss: 0.000000319\n",
      "Iteration 53680, Loss: 0.000000394\n",
      "Iteration 53690, Loss: 0.000001271\n",
      "Iteration 53700, Loss: 0.000000763\n",
      "Iteration 53710, Loss: 0.000000690\n",
      "Iteration 53720, Loss: 0.000000393\n",
      "Iteration 53730, Loss: 0.000000451\n",
      "Iteration 53740, Loss: 0.000000325\n",
      "Iteration 53750, Loss: 0.000000319\n",
      "Iteration 53760, Loss: 0.000000365\n",
      "Iteration 53770, Loss: 0.000001139\n",
      "Iteration 53780, Loss: 0.000000332\n",
      "Iteration 53790, Loss: 0.000000366\n",
      "Iteration 53800, Loss: 0.000000421\n",
      "Iteration 53810, Loss: 0.000000423\n",
      "Iteration 53820, Loss: 0.000000626\n",
      "Iteration 53830, Loss: 0.000000366\n",
      "Iteration 53840, Loss: 0.000000380\n",
      "Iteration 53850, Loss: 0.000000430\n",
      "Iteration 53860, Loss: 0.000000588\n",
      "Iteration 53870, Loss: 0.000000623\n",
      "Iteration 53880, Loss: 0.000000493\n",
      "Iteration 53890, Loss: 0.000000414\n",
      "Iteration 53900, Loss: 0.000000567\n",
      "Iteration 53910, Loss: 0.000000688\n",
      "Iteration 53920, Loss: 0.000000563\n",
      "Iteration 53930, Loss: 0.000000335\n",
      "Iteration 53940, Loss: 0.000000393\n",
      "Iteration 53950, Loss: 0.000000459\n",
      "Iteration 53960, Loss: 0.000000700\n",
      "Iteration 53970, Loss: 0.000000506\n",
      "Iteration 53980, Loss: 0.000000684\n",
      "Iteration 53990, Loss: 0.000000499\n",
      "Iteration 54000, Loss: 0.000000504\n",
      "Iteration 54010, Loss: 0.000000330\n",
      "Iteration 54020, Loss: 0.000000342\n",
      "Iteration 54030, Loss: 0.000000511\n",
      "Iteration 54040, Loss: 0.000002452\n",
      "Iteration 54050, Loss: 0.000000919\n",
      "Iteration 54060, Loss: 0.000000444\n",
      "Iteration 54070, Loss: 0.000000341\n",
      "Iteration 54080, Loss: 0.000000345\n",
      "Iteration 54090, Loss: 0.000000332\n",
      "Iteration 54100, Loss: 0.000000351\n",
      "Iteration 54110, Loss: 0.000000715\n",
      "Iteration 54120, Loss: 0.000000464\n",
      "Iteration 54130, Loss: 0.000000403\n",
      "Iteration 54140, Loss: 0.000000348\n",
      "Iteration 54150, Loss: 0.000000329\n",
      "Iteration 54160, Loss: 0.000000364\n",
      "Iteration 54170, Loss: 0.000000882\n",
      "Iteration 54180, Loss: 0.000000463\n",
      "Iteration 54190, Loss: 0.000000346\n",
      "Iteration 54200, Loss: 0.000000334\n",
      "Iteration 54210, Loss: 0.000000366\n",
      "Iteration 54220, Loss: 0.000000948\n",
      "Iteration 54230, Loss: 0.000000499\n",
      "Iteration 54240, Loss: 0.000000478\n",
      "Iteration 54250, Loss: 0.000000389\n",
      "Iteration 54260, Loss: 0.000000382\n",
      "Iteration 54270, Loss: 0.000000346\n",
      "Iteration 54280, Loss: 0.000000695\n",
      "Iteration 54290, Loss: 0.000000610\n",
      "Iteration 54300, Loss: 0.000000426\n",
      "Iteration 54310, Loss: 0.000000383\n",
      "Iteration 54320, Loss: 0.000000332\n",
      "Iteration 54330, Loss: 0.000000325\n",
      "Iteration 54340, Loss: 0.000000355\n",
      "Iteration 54350, Loss: 0.000000809\n",
      "Iteration 54360, Loss: 0.000001060\n",
      "Iteration 54370, Loss: 0.000000556\n",
      "Iteration 54380, Loss: 0.000000401\n",
      "Iteration 54390, Loss: 0.000000345\n",
      "Iteration 54400, Loss: 0.000000324\n",
      "Iteration 54410, Loss: 0.000000312\n",
      "Iteration 54420, Loss: 0.000000313\n",
      "Iteration 54430, Loss: 0.000000496\n",
      "Iteration 54440, Loss: 0.000001543\n",
      "Iteration 54450, Loss: 0.000000583\n",
      "Iteration 54460, Loss: 0.000000439\n",
      "Iteration 54470, Loss: 0.000000377\n",
      "Iteration 54480, Loss: 0.000000319\n",
      "Iteration 54490, Loss: 0.000000316\n",
      "Iteration 54500, Loss: 0.000000313\n",
      "Iteration 54510, Loss: 0.000000347\n",
      "Iteration 54520, Loss: 0.000001193\n",
      "Iteration 54530, Loss: 0.000000342\n",
      "Iteration 54540, Loss: 0.000000384\n",
      "Iteration 54550, Loss: 0.000000408\n",
      "Iteration 54560, Loss: 0.000000358\n",
      "Iteration 54570, Loss: 0.000000331\n",
      "Iteration 54580, Loss: 0.000000359\n",
      "Iteration 54590, Loss: 0.000001039\n",
      "Iteration 54600, Loss: 0.000000462\n",
      "Iteration 54610, Loss: 0.000000425\n",
      "Iteration 54620, Loss: 0.000000365\n",
      "Iteration 54630, Loss: 0.000000345\n",
      "Iteration 54640, Loss: 0.000000322\n",
      "Iteration 54650, Loss: 0.000000360\n",
      "Iteration 54660, Loss: 0.000000794\n",
      "Iteration 54670, Loss: 0.000000890\n",
      "Iteration 54680, Loss: 0.000000531\n",
      "Iteration 54690, Loss: 0.000000389\n",
      "Iteration 54700, Loss: 0.000000348\n",
      "Iteration 54710, Loss: 0.000000327\n",
      "Iteration 54720, Loss: 0.000000357\n",
      "Iteration 54730, Loss: 0.000000857\n",
      "Iteration 54740, Loss: 0.000000583\n",
      "Iteration 54750, Loss: 0.000000370\n",
      "Iteration 54760, Loss: 0.000000349\n",
      "Iteration 54770, Loss: 0.000000328\n",
      "Iteration 54780, Loss: 0.000000347\n",
      "Iteration 54790, Loss: 0.000001491\n",
      "Iteration 54800, Loss: 0.000000562\n",
      "Iteration 54810, Loss: 0.000000700\n",
      "Iteration 54820, Loss: 0.000000405\n",
      "Iteration 54830, Loss: 0.000000318\n",
      "Iteration 54840, Loss: 0.000000320\n",
      "Iteration 54850, Loss: 0.000000347\n",
      "Iteration 54860, Loss: 0.000001348\n",
      "Iteration 54870, Loss: 0.000000659\n",
      "Iteration 54880, Loss: 0.000000381\n",
      "Iteration 54890, Loss: 0.000000348\n",
      "Iteration 54900, Loss: 0.000000326\n",
      "Iteration 54910, Loss: 0.000000316\n",
      "Iteration 54920, Loss: 0.000000436\n",
      "Iteration 54930, Loss: 0.000001141\n",
      "Iteration 54940, Loss: 0.000000424\n",
      "Iteration 54950, Loss: 0.000000415\n",
      "Iteration 54960, Loss: 0.000000338\n",
      "Iteration 54970, Loss: 0.000000338\n",
      "Iteration 54980, Loss: 0.000000318\n",
      "Iteration 54990, Loss: 0.000000330\n",
      "Iteration 55000, Loss: 0.000000539\n",
      "Iteration 55010, Loss: 0.000001283\n",
      "Iteration 55020, Loss: 0.000000824\n",
      "Iteration 55030, Loss: 0.000000435\n",
      "Iteration 55040, Loss: 0.000000361\n",
      "Iteration 55050, Loss: 0.000000336\n",
      "Iteration 55060, Loss: 0.000000327\n",
      "Iteration 55070, Loss: 0.000000388\n",
      "Iteration 55080, Loss: 0.000000978\n",
      "Iteration 55090, Loss: 0.000000364\n",
      "Iteration 55100, Loss: 0.000000453\n",
      "Iteration 55110, Loss: 0.000000414\n",
      "Iteration 55120, Loss: 0.000000403\n",
      "Iteration 55130, Loss: 0.000000648\n",
      "Iteration 55140, Loss: 0.000000330\n",
      "Iteration 55150, Loss: 0.000000373\n",
      "Iteration 55160, Loss: 0.000000318\n",
      "Iteration 55170, Loss: 0.000000465\n",
      "Iteration 55180, Loss: 0.000002529\n",
      "Iteration 55190, Loss: 0.000000970\n",
      "Iteration 55200, Loss: 0.000000429\n",
      "Iteration 55210, Loss: 0.000000373\n",
      "Iteration 55220, Loss: 0.000000318\n",
      "Iteration 55230, Loss: 0.000000321\n",
      "Iteration 55240, Loss: 0.000000433\n",
      "Iteration 55250, Loss: 0.000001420\n",
      "Iteration 55260, Loss: 0.000000572\n",
      "Iteration 55270, Loss: 0.000000321\n",
      "Iteration 55280, Loss: 0.000000321\n",
      "Iteration 55290, Loss: 0.000000332\n",
      "Iteration 55300, Loss: 0.000000433\n",
      "Iteration 55310, Loss: 0.000000744\n",
      "Iteration 55320, Loss: 0.000000453\n",
      "Iteration 55330, Loss: 0.000000464\n",
      "Iteration 55340, Loss: 0.000000929\n",
      "Iteration 55350, Loss: 0.000000362\n",
      "Iteration 55360, Loss: 0.000000439\n",
      "Iteration 55370, Loss: 0.000000319\n",
      "Iteration 55380, Loss: 0.000000355\n",
      "Iteration 55390, Loss: 0.000000496\n",
      "Iteration 55400, Loss: 0.000000652\n",
      "Iteration 55410, Loss: 0.000000874\n",
      "Iteration 55420, Loss: 0.000000540\n",
      "Iteration 55430, Loss: 0.000000455\n",
      "Iteration 55440, Loss: 0.000000316\n",
      "Iteration 55450, Loss: 0.000000335\n",
      "Iteration 55460, Loss: 0.000000368\n",
      "Iteration 55470, Loss: 0.000000698\n",
      "Iteration 55480, Loss: 0.000000795\n",
      "Iteration 55490, Loss: 0.000000873\n",
      "Iteration 55500, Loss: 0.000000522\n",
      "Iteration 55510, Loss: 0.000000403\n",
      "Iteration 55520, Loss: 0.000000344\n",
      "Iteration 55530, Loss: 0.000000316\n",
      "Iteration 55540, Loss: 0.000000312\n",
      "Iteration 55550, Loss: 0.000000312\n",
      "Iteration 55560, Loss: 0.000000348\n",
      "Iteration 55570, Loss: 0.000000806\n",
      "Iteration 55580, Loss: 0.000000802\n",
      "Iteration 55590, Loss: 0.000000774\n",
      "Iteration 55600, Loss: 0.000000417\n",
      "Iteration 55610, Loss: 0.000000382\n",
      "Iteration 55620, Loss: 0.000000491\n",
      "Iteration 55630, Loss: 0.000000346\n",
      "Iteration 55640, Loss: 0.000000309\n",
      "Iteration 55650, Loss: 0.000000316\n",
      "Iteration 55660, Loss: 0.000000445\n",
      "Iteration 55670, Loss: 0.000002199\n",
      "Iteration 55680, Loss: 0.000000957\n",
      "Iteration 55690, Loss: 0.000000512\n",
      "Iteration 55700, Loss: 0.000000340\n",
      "Iteration 55710, Loss: 0.000000311\n",
      "Iteration 55720, Loss: 0.000000312\n",
      "Iteration 55730, Loss: 0.000000399\n",
      "Iteration 55740, Loss: 0.000000484\n",
      "Iteration 55750, Loss: 0.000000640\n",
      "Iteration 55760, Loss: 0.000001137\n",
      "Iteration 55770, Loss: 0.000000545\n",
      "Iteration 55780, Loss: 0.000000386\n",
      "Iteration 55790, Loss: 0.000000335\n",
      "Iteration 55800, Loss: 0.000000323\n",
      "Iteration 55810, Loss: 0.000000313\n",
      "Iteration 55820, Loss: 0.000000309\n",
      "Iteration 55830, Loss: 0.000000320\n",
      "Iteration 55840, Loss: 0.000000690\n",
      "Iteration 55850, Loss: 0.000001053\n",
      "Iteration 55860, Loss: 0.000000476\n",
      "Iteration 55870, Loss: 0.000000395\n",
      "Iteration 55880, Loss: 0.000000337\n",
      "Iteration 55890, Loss: 0.000000319\n",
      "Iteration 55900, Loss: 0.000000311\n",
      "Iteration 55910, Loss: 0.000000308\n",
      "Iteration 55920, Loss: 0.000000309\n",
      "Iteration 55930, Loss: 0.000000367\n",
      "Iteration 55940, Loss: 0.000002619\n",
      "Iteration 55950, Loss: 0.000001020\n",
      "Iteration 55960, Loss: 0.000000410\n",
      "Iteration 55970, Loss: 0.000000359\n",
      "Iteration 55980, Loss: 0.000000334\n",
      "Iteration 55990, Loss: 0.000000312\n",
      "Iteration 56000, Loss: 0.000000313\n",
      "Iteration 56010, Loss: 0.000000374\n",
      "Iteration 56020, Loss: 0.000001797\n",
      "Iteration 56030, Loss: 0.000000744\n",
      "Iteration 56040, Loss: 0.000000374\n",
      "Iteration 56050, Loss: 0.000000361\n",
      "Iteration 56060, Loss: 0.000000331\n",
      "Iteration 56070, Loss: 0.000000315\n",
      "Iteration 56080, Loss: 0.000000307\n",
      "Iteration 56090, Loss: 0.000000337\n",
      "Iteration 56100, Loss: 0.000000404\n",
      "Iteration 56110, Loss: 0.000000613\n",
      "Iteration 56120, Loss: 0.000001861\n",
      "Iteration 56130, Loss: 0.000000375\n",
      "Iteration 56140, Loss: 0.000000520\n",
      "Iteration 56150, Loss: 0.000000370\n",
      "Iteration 56160, Loss: 0.000000317\n",
      "Iteration 56170, Loss: 0.000000317\n",
      "Iteration 56180, Loss: 0.000000310\n",
      "Iteration 56190, Loss: 0.000000307\n",
      "Iteration 56200, Loss: 0.000000306\n",
      "Iteration 56210, Loss: 0.000000306\n",
      "Iteration 56220, Loss: 0.000000324\n",
      "Iteration 56230, Loss: 0.000001388\n",
      "Iteration 56240, Loss: 0.000000981\n",
      "Iteration 56250, Loss: 0.000000356\n",
      "Iteration 56260, Loss: 0.000000400\n",
      "Iteration 56270, Loss: 0.000000323\n",
      "Iteration 56280, Loss: 0.000000333\n",
      "Iteration 56290, Loss: 0.000000595\n",
      "Iteration 56300, Loss: 0.000001207\n",
      "Iteration 56310, Loss: 0.000000640\n",
      "Iteration 56320, Loss: 0.000000435\n",
      "Iteration 56330, Loss: 0.000000348\n",
      "Iteration 56340, Loss: 0.000000311\n",
      "Iteration 56350, Loss: 0.000000312\n",
      "Iteration 56360, Loss: 0.000000351\n",
      "Iteration 56370, Loss: 0.000000957\n",
      "Iteration 56380, Loss: 0.000000726\n",
      "Iteration 56390, Loss: 0.000000367\n",
      "Iteration 56400, Loss: 0.000000348\n",
      "Iteration 56410, Loss: 0.000000474\n",
      "Iteration 56420, Loss: 0.000002233\n",
      "Iteration 56430, Loss: 0.000000953\n",
      "Iteration 56440, Loss: 0.000000483\n",
      "Iteration 56450, Loss: 0.000000327\n",
      "Iteration 56460, Loss: 0.000000309\n",
      "Iteration 56470, Loss: 0.000000307\n",
      "Iteration 56480, Loss: 0.000000307\n",
      "Iteration 56490, Loss: 0.000000307\n",
      "Iteration 56500, Loss: 0.000000316\n",
      "Iteration 56510, Loss: 0.000001159\n",
      "Iteration 56520, Loss: 0.000000980\n",
      "Iteration 56530, Loss: 0.000000364\n",
      "Iteration 56540, Loss: 0.000000329\n",
      "Iteration 56550, Loss: 0.000000329\n",
      "Iteration 56560, Loss: 0.000000360\n",
      "Iteration 56570, Loss: 0.000001763\n",
      "Iteration 56580, Loss: 0.000000690\n",
      "Iteration 56590, Loss: 0.000000614\n",
      "Iteration 56600, Loss: 0.000000373\n",
      "Iteration 56610, Loss: 0.000000326\n",
      "Iteration 56620, Loss: 0.000000313\n",
      "Iteration 56630, Loss: 0.000000307\n",
      "Iteration 56640, Loss: 0.000000306\n",
      "Iteration 56650, Loss: 0.000000305\n",
      "Iteration 56660, Loss: 0.000000311\n",
      "Iteration 56670, Loss: 0.000001054\n",
      "Iteration 56680, Loss: 0.000000969\n",
      "Iteration 56690, Loss: 0.000000471\n",
      "Iteration 56700, Loss: 0.000000383\n",
      "Iteration 56710, Loss: 0.000000353\n",
      "Iteration 56720, Loss: 0.000000332\n",
      "Iteration 56730, Loss: 0.000000470\n",
      "Iteration 56740, Loss: 0.000001441\n",
      "Iteration 56750, Loss: 0.000000545\n",
      "Iteration 56760, Loss: 0.000000358\n",
      "Iteration 56770, Loss: 0.000000309\n",
      "Iteration 56780, Loss: 0.000000313\n",
      "Iteration 56790, Loss: 0.000000315\n",
      "Iteration 56800, Loss: 0.000000307\n",
      "Iteration 56810, Loss: 0.000000312\n",
      "Iteration 56820, Loss: 0.000000501\n",
      "Iteration 56830, Loss: 0.000001596\n",
      "Iteration 56840, Loss: 0.000001166\n",
      "Iteration 56850, Loss: 0.000000490\n",
      "Iteration 56860, Loss: 0.000000345\n",
      "Iteration 56870, Loss: 0.000000331\n",
      "Iteration 56880, Loss: 0.000000318\n",
      "Iteration 56890, Loss: 0.000000315\n",
      "Iteration 56900, Loss: 0.000000325\n",
      "Iteration 56910, Loss: 0.000000529\n",
      "Iteration 56920, Loss: 0.000001544\n",
      "Iteration 56930, Loss: 0.000000703\n",
      "Iteration 56940, Loss: 0.000000450\n",
      "Iteration 56950, Loss: 0.000000355\n",
      "Iteration 56960, Loss: 0.000000315\n",
      "Iteration 56970, Loss: 0.000000305\n",
      "Iteration 56980, Loss: 0.000000309\n",
      "Iteration 56990, Loss: 0.000000317\n",
      "Iteration 57000, Loss: 0.000000720\n",
      "Iteration 57010, Loss: 0.000000721\n",
      "Iteration 57020, Loss: 0.000000468\n",
      "Iteration 57030, Loss: 0.000000479\n",
      "Iteration 57040, Loss: 0.000001789\n",
      "Iteration 57050, Loss: 0.000000594\n",
      "Iteration 57060, Loss: 0.000000452\n",
      "Iteration 57070, Loss: 0.000000358\n",
      "Iteration 57080, Loss: 0.000000313\n",
      "Iteration 57090, Loss: 0.000000307\n",
      "Iteration 57100, Loss: 0.000000305\n",
      "Iteration 57110, Loss: 0.000000307\n",
      "Iteration 57120, Loss: 0.000000306\n",
      "Iteration 57130, Loss: 0.000000308\n",
      "Iteration 57140, Loss: 0.000000477\n",
      "Iteration 57150, Loss: 0.000000770\n",
      "Iteration 57160, Loss: 0.000000420\n",
      "Iteration 57170, Loss: 0.000000388\n",
      "Iteration 57180, Loss: 0.000000318\n",
      "Iteration 57190, Loss: 0.000000332\n",
      "Iteration 57200, Loss: 0.000000881\n",
      "Iteration 57210, Loss: 0.000000766\n",
      "Iteration 57220, Loss: 0.000000708\n",
      "Iteration 57230, Loss: 0.000000429\n",
      "Iteration 57240, Loss: 0.000000338\n",
      "Iteration 57250, Loss: 0.000000330\n",
      "Iteration 57260, Loss: 0.000000305\n",
      "Iteration 57270, Loss: 0.000000307\n",
      "Iteration 57280, Loss: 0.000000308\n",
      "Iteration 57290, Loss: 0.000000426\n",
      "Iteration 57300, Loss: 0.000000386\n",
      "Iteration 57310, Loss: 0.000001700\n",
      "Iteration 57320, Loss: 0.000000727\n",
      "Iteration 57330, Loss: 0.000000445\n",
      "Iteration 57340, Loss: 0.000000361\n",
      "Iteration 57350, Loss: 0.000000328\n",
      "Iteration 57360, Loss: 0.000000314\n",
      "Iteration 57370, Loss: 0.000000305\n",
      "Iteration 57380, Loss: 0.000000305\n",
      "Iteration 57390, Loss: 0.000000304\n",
      "Iteration 57400, Loss: 0.000000304\n",
      "Iteration 57410, Loss: 0.000000327\n",
      "Iteration 57420, Loss: 0.000001077\n",
      "Iteration 57430, Loss: 0.000001402\n",
      "Iteration 57440, Loss: 0.000000390\n",
      "Iteration 57450, Loss: 0.000000616\n",
      "Iteration 57460, Loss: 0.000000430\n",
      "Iteration 57470, Loss: 0.000000368\n",
      "Iteration 57480, Loss: 0.000000373\n",
      "Iteration 57490, Loss: 0.000000317\n",
      "Iteration 57500, Loss: 0.000000321\n",
      "Iteration 57510, Loss: 0.000000597\n",
      "Iteration 57520, Loss: 0.000000458\n",
      "Iteration 57530, Loss: 0.000000362\n",
      "Iteration 57540, Loss: 0.000000439\n",
      "Iteration 57550, Loss: 0.000000986\n",
      "Iteration 57560, Loss: 0.000000355\n",
      "Iteration 57570, Loss: 0.000000435\n",
      "Iteration 57580, Loss: 0.000000355\n",
      "Iteration 57590, Loss: 0.000000307\n",
      "Iteration 57600, Loss: 0.000000314\n",
      "Iteration 57610, Loss: 0.000000335\n",
      "Iteration 57620, Loss: 0.000000532\n",
      "Iteration 57630, Loss: 0.000001511\n",
      "Iteration 57640, Loss: 0.000000709\n",
      "Iteration 57650, Loss: 0.000000709\n",
      "Iteration 57660, Loss: 0.000000396\n",
      "Iteration 57670, Loss: 0.000000352\n",
      "Iteration 57680, Loss: 0.000000343\n",
      "Iteration 57690, Loss: 0.000000366\n",
      "Iteration 57700, Loss: 0.000000697\n",
      "Iteration 57710, Loss: 0.000000777\n",
      "Iteration 57720, Loss: 0.000000511\n",
      "Iteration 57730, Loss: 0.000000344\n",
      "Iteration 57740, Loss: 0.000000407\n",
      "Iteration 57750, Loss: 0.000000854\n",
      "Iteration 57760, Loss: 0.000000400\n",
      "Iteration 57770, Loss: 0.000000349\n",
      "Iteration 57780, Loss: 0.000000342\n",
      "Iteration 57790, Loss: 0.000000316\n",
      "Iteration 57800, Loss: 0.000000306\n",
      "Iteration 57810, Loss: 0.000000326\n",
      "Iteration 57820, Loss: 0.000003091\n",
      "Iteration 57830, Loss: 0.000002231\n",
      "Iteration 57840, Loss: 0.000000591\n",
      "Iteration 57850, Loss: 0.000000408\n",
      "Iteration 57860, Loss: 0.000000368\n",
      "Iteration 57870, Loss: 0.000000319\n",
      "Iteration 57880, Loss: 0.000000308\n",
      "Iteration 57890, Loss: 0.000000305\n",
      "Iteration 57900, Loss: 0.000000304\n",
      "Iteration 57910, Loss: 0.000000315\n",
      "Iteration 57920, Loss: 0.000001104\n",
      "Iteration 57930, Loss: 0.000000723\n",
      "Iteration 57940, Loss: 0.000000450\n",
      "Iteration 57950, Loss: 0.000000328\n",
      "Iteration 57960, Loss: 0.000000328\n",
      "Iteration 57970, Loss: 0.000000308\n",
      "Iteration 57980, Loss: 0.000000388\n",
      "Iteration 57990, Loss: 0.000001250\n",
      "Iteration 58000, Loss: 0.000000509\n",
      "Iteration 58010, Loss: 0.000000378\n",
      "Iteration 58020, Loss: 0.000000337\n",
      "Iteration 58030, Loss: 0.000000309\n",
      "Iteration 58040, Loss: 0.000000308\n",
      "Iteration 58050, Loss: 0.000000310\n",
      "Iteration 58060, Loss: 0.000000438\n",
      "Iteration 58070, Loss: 0.000002315\n",
      "Iteration 58080, Loss: 0.000000944\n",
      "Iteration 58090, Loss: 0.000000419\n",
      "Iteration 58100, Loss: 0.000000310\n",
      "Iteration 58110, Loss: 0.000000307\n",
      "Iteration 58120, Loss: 0.000000305\n",
      "Iteration 58130, Loss: 0.000000303\n",
      "Iteration 58140, Loss: 0.000000309\n",
      "Iteration 58150, Loss: 0.000000520\n",
      "Iteration 58160, Loss: 0.000000970\n",
      "Iteration 58170, Loss: 0.000000438\n",
      "Iteration 58180, Loss: 0.000000378\n",
      "Iteration 58190, Loss: 0.000000330\n",
      "Iteration 58200, Loss: 0.000000317\n",
      "Iteration 58210, Loss: 0.000000369\n",
      "Iteration 58220, Loss: 0.000002035\n",
      "Iteration 58230, Loss: 0.000000879\n",
      "Iteration 58240, Loss: 0.000000591\n",
      "Iteration 58250, Loss: 0.000000339\n",
      "Iteration 58260, Loss: 0.000000306\n",
      "Iteration 58270, Loss: 0.000000306\n",
      "Iteration 58280, Loss: 0.000000320\n",
      "Iteration 58290, Loss: 0.000001087\n",
      "Iteration 58300, Loss: 0.000000578\n",
      "Iteration 58310, Loss: 0.000000408\n",
      "Iteration 58320, Loss: 0.000000372\n",
      "Iteration 58330, Loss: 0.000000310\n",
      "Iteration 58340, Loss: 0.000000306\n",
      "Iteration 58350, Loss: 0.000000304\n",
      "Iteration 58360, Loss: 0.000000302\n",
      "Iteration 58370, Loss: 0.000000302\n",
      "Iteration 58380, Loss: 0.000000327\n",
      "Iteration 58390, Loss: 0.000002143\n",
      "Iteration 58400, Loss: 0.000001593\n",
      "Iteration 58410, Loss: 0.000000548\n",
      "Iteration 58420, Loss: 0.000000428\n",
      "Iteration 58430, Loss: 0.000000342\n",
      "Iteration 58440, Loss: 0.000000319\n",
      "Iteration 58450, Loss: 0.000000310\n",
      "Iteration 58460, Loss: 0.000000315\n",
      "Iteration 58470, Loss: 0.000000614\n",
      "Iteration 58480, Loss: 0.000000434\n",
      "Iteration 58490, Loss: 0.000000333\n",
      "Iteration 58500, Loss: 0.000000366\n",
      "Iteration 58510, Loss: 0.000000329\n",
      "Iteration 58520, Loss: 0.000000309\n",
      "Iteration 58530, Loss: 0.000000310\n",
      "Iteration 58540, Loss: 0.000000311\n",
      "Iteration 58550, Loss: 0.000000356\n",
      "Iteration 58560, Loss: 0.000000662\n",
      "Iteration 58570, Loss: 0.000000515\n",
      "Iteration 58580, Loss: 0.000000417\n",
      "Iteration 58590, Loss: 0.000000363\n",
      "Iteration 58600, Loss: 0.000000392\n",
      "Iteration 58610, Loss: 0.000000682\n",
      "Iteration 58620, Loss: 0.000001040\n",
      "Iteration 58630, Loss: 0.000000607\n",
      "Iteration 58640, Loss: 0.000000399\n",
      "Iteration 58650, Loss: 0.000000310\n",
      "Iteration 58660, Loss: 0.000000317\n",
      "Iteration 58670, Loss: 0.000000308\n",
      "Iteration 58680, Loss: 0.000000329\n",
      "Iteration 58690, Loss: 0.000000831\n",
      "Iteration 58700, Loss: 0.000001164\n",
      "Iteration 58710, Loss: 0.000000473\n",
      "Iteration 58720, Loss: 0.000000426\n",
      "Iteration 58730, Loss: 0.000000326\n",
      "Iteration 58740, Loss: 0.000000321\n",
      "Iteration 58750, Loss: 0.000000329\n",
      "Iteration 58760, Loss: 0.000000702\n",
      "Iteration 58770, Loss: 0.000000939\n",
      "Iteration 58780, Loss: 0.000000525\n",
      "Iteration 58790, Loss: 0.000000372\n",
      "Iteration 58800, Loss: 0.000000334\n",
      "Iteration 58810, Loss: 0.000000321\n",
      "Iteration 58820, Loss: 0.000000341\n",
      "Iteration 58830, Loss: 0.000000475\n",
      "Iteration 58840, Loss: 0.000001028\n",
      "Iteration 58850, Loss: 0.000000641\n",
      "Iteration 58860, Loss: 0.000000509\n",
      "Iteration 58870, Loss: 0.000000337\n",
      "Iteration 58880, Loss: 0.000000317\n",
      "Iteration 58890, Loss: 0.000000303\n",
      "Iteration 58900, Loss: 0.000000312\n",
      "Iteration 58910, Loss: 0.000000373\n",
      "Iteration 58920, Loss: 0.000001219\n",
      "Iteration 58930, Loss: 0.000000323\n",
      "Iteration 58940, Loss: 0.000000312\n",
      "Iteration 58950, Loss: 0.000000309\n",
      "Iteration 58960, Loss: 0.000000319\n",
      "Iteration 58970, Loss: 0.000000584\n",
      "Iteration 58980, Loss: 0.000000623\n",
      "Iteration 58990, Loss: 0.000000365\n",
      "Iteration 59000, Loss: 0.000000371\n",
      "Iteration 59010, Loss: 0.000000316\n",
      "Iteration 59020, Loss: 0.000000311\n",
      "Iteration 59030, Loss: 0.000000350\n",
      "Iteration 59040, Loss: 0.000001077\n",
      "Iteration 59050, Loss: 0.000000584\n",
      "Iteration 59060, Loss: 0.000000332\n",
      "Iteration 59070, Loss: 0.000000356\n",
      "Iteration 59080, Loss: 0.000000346\n",
      "Iteration 59090, Loss: 0.000000326\n",
      "Iteration 59100, Loss: 0.000000351\n",
      "Iteration 59110, Loss: 0.000000807\n",
      "Iteration 59120, Loss: 0.000000411\n",
      "Iteration 59130, Loss: 0.000000491\n",
      "Iteration 59140, Loss: 0.000000450\n",
      "Iteration 59150, Loss: 0.000000361\n",
      "Iteration 59160, Loss: 0.000000322\n",
      "Iteration 59170, Loss: 0.000000379\n",
      "Iteration 59180, Loss: 0.000001218\n",
      "Iteration 59190, Loss: 0.000000351\n",
      "Iteration 59200, Loss: 0.000000327\n",
      "Iteration 59210, Loss: 0.000000311\n",
      "Iteration 59220, Loss: 0.000000303\n",
      "Iteration 59230, Loss: 0.000000315\n",
      "Iteration 59240, Loss: 0.000000502\n",
      "Iteration 59250, Loss: 0.000001524\n",
      "Iteration 59260, Loss: 0.000000491\n",
      "Iteration 59270, Loss: 0.000000387\n",
      "Iteration 59280, Loss: 0.000000349\n",
      "Iteration 59290, Loss: 0.000000345\n",
      "Iteration 59300, Loss: 0.000000407\n",
      "Iteration 59310, Loss: 0.000000660\n",
      "Iteration 59320, Loss: 0.000000588\n",
      "Iteration 59330, Loss: 0.000000346\n",
      "Iteration 59340, Loss: 0.000000346\n",
      "Iteration 59350, Loss: 0.000000391\n",
      "Iteration 59360, Loss: 0.000000748\n",
      "Iteration 59370, Loss: 0.000000562\n",
      "Iteration 59380, Loss: 0.000000455\n",
      "Iteration 59390, Loss: 0.000000362\n",
      "Iteration 59400, Loss: 0.000000636\n",
      "Iteration 59410, Loss: 0.000000582\n",
      "Iteration 59420, Loss: 0.000000436\n",
      "Iteration 59430, Loss: 0.000000331\n",
      "Iteration 59440, Loss: 0.000000383\n",
      "Iteration 59450, Loss: 0.000001287\n",
      "Iteration 59460, Loss: 0.000000389\n",
      "Iteration 59470, Loss: 0.000000391\n",
      "Iteration 59480, Loss: 0.000000416\n",
      "Iteration 59490, Loss: 0.000000353\n",
      "Iteration 59500, Loss: 0.000000323\n",
      "Iteration 59510, Loss: 0.000000415\n",
      "Iteration 59520, Loss: 0.000001305\n",
      "Iteration 59530, Loss: 0.000000695\n",
      "Iteration 59540, Loss: 0.000000379\n",
      "Iteration 59550, Loss: 0.000000317\n",
      "Iteration 59560, Loss: 0.000000307\n",
      "Iteration 59570, Loss: 0.000000361\n",
      "Iteration 59580, Loss: 0.000001769\n",
      "Iteration 59590, Loss: 0.000000551\n",
      "Iteration 59600, Loss: 0.000000456\n",
      "Iteration 59610, Loss: 0.000000378\n",
      "Iteration 59620, Loss: 0.000000333\n",
      "Iteration 59630, Loss: 0.000000310\n",
      "Iteration 59640, Loss: 0.000000309\n",
      "Iteration 59650, Loss: 0.000000452\n",
      "Iteration 59660, Loss: 0.000000947\n",
      "Iteration 59670, Loss: 0.000000336\n",
      "Iteration 59680, Loss: 0.000000355\n",
      "Iteration 59690, Loss: 0.000000331\n",
      "Iteration 59700, Loss: 0.000000305\n",
      "Iteration 59710, Loss: 0.000000313\n",
      "Iteration 59720, Loss: 0.000000616\n",
      "Iteration 59730, Loss: 0.000001583\n",
      "Iteration 59740, Loss: 0.000000557\n",
      "Iteration 59750, Loss: 0.000000324\n",
      "Iteration 59760, Loss: 0.000000323\n",
      "Iteration 59770, Loss: 0.000000327\n",
      "Iteration 59780, Loss: 0.000000516\n",
      "Iteration 59790, Loss: 0.000001108\n",
      "Iteration 59800, Loss: 0.000000482\n",
      "Iteration 59810, Loss: 0.000000333\n",
      "Iteration 59820, Loss: 0.000000311\n",
      "Iteration 59830, Loss: 0.000000306\n",
      "Iteration 59840, Loss: 0.000000302\n",
      "Iteration 59850, Loss: 0.000000303\n",
      "Iteration 59860, Loss: 0.000000343\n",
      "Iteration 59870, Loss: 0.000001090\n",
      "Iteration 59880, Loss: 0.000001678\n",
      "Iteration 59890, Loss: 0.000000528\n",
      "Iteration 59900, Loss: 0.000000388\n",
      "Iteration 59910, Loss: 0.000000317\n",
      "Iteration 59920, Loss: 0.000000317\n",
      "Iteration 59930, Loss: 0.000000307\n",
      "Iteration 59940, Loss: 0.000000303\n",
      "Iteration 59950, Loss: 0.000000301\n",
      "Iteration 59960, Loss: 0.000000312\n",
      "Iteration 59970, Loss: 0.000000652\n",
      "Iteration 59980, Loss: 0.000001472\n",
      "Iteration 59990, Loss: 0.000000431\n",
      "Iteration 60000, Loss: 0.000000376\n",
      "Iteration 60010, Loss: 0.000000358\n",
      "Iteration 60020, Loss: 0.000000614\n",
      "Iteration 60030, Loss: 0.000000364\n",
      "Iteration 60040, Loss: 0.000000366\n",
      "Iteration 60050, Loss: 0.000000412\n",
      "Iteration 60060, Loss: 0.000000319\n",
      "Iteration 60070, Loss: 0.000000315\n",
      "Iteration 60080, Loss: 0.000000445\n",
      "Iteration 60090, Loss: 0.000002045\n",
      "Iteration 60100, Loss: 0.000000746\n",
      "Iteration 60110, Loss: 0.000000381\n",
      "Iteration 60120, Loss: 0.000000339\n",
      "Iteration 60130, Loss: 0.000000321\n",
      "Iteration 60140, Loss: 0.000000306\n",
      "Iteration 60150, Loss: 0.000000302\n",
      "Iteration 60160, Loss: 0.000000314\n",
      "Iteration 60170, Loss: 0.000000541\n",
      "Iteration 60180, Loss: 0.000001075\n",
      "Iteration 60190, Loss: 0.000001263\n",
      "Iteration 60200, Loss: 0.000000429\n",
      "Iteration 60210, Loss: 0.000000381\n",
      "Iteration 60220, Loss: 0.000000349\n",
      "Iteration 60230, Loss: 0.000000305\n",
      "Iteration 60240, Loss: 0.000000310\n",
      "Iteration 60250, Loss: 0.000000313\n",
      "Iteration 60260, Loss: 0.000000402\n",
      "Iteration 60270, Loss: 0.000001440\n",
      "Iteration 60280, Loss: 0.000000422\n",
      "Iteration 60290, Loss: 0.000000374\n",
      "Iteration 60300, Loss: 0.000000310\n",
      "Iteration 60310, Loss: 0.000000310\n",
      "Iteration 60320, Loss: 0.000000315\n",
      "Iteration 60330, Loss: 0.000000300\n",
      "Iteration 60340, Loss: 0.000000303\n",
      "Iteration 60350, Loss: 0.000000316\n",
      "Iteration 60360, Loss: 0.000001019\n",
      "Iteration 60370, Loss: 0.000000904\n",
      "Iteration 60380, Loss: 0.000000430\n",
      "Iteration 60390, Loss: 0.000000458\n",
      "Iteration 60400, Loss: 0.000000931\n",
      "Iteration 60410, Loss: 0.000000366\n",
      "Iteration 60420, Loss: 0.000000403\n",
      "Iteration 60430, Loss: 0.000000344\n",
      "Iteration 60440, Loss: 0.000000313\n",
      "Iteration 60450, Loss: 0.000000307\n",
      "Iteration 60460, Loss: 0.000000302\n",
      "Iteration 60470, Loss: 0.000000362\n",
      "Iteration 60480, Loss: 0.000002531\n",
      "Iteration 60490, Loss: 0.000001296\n",
      "Iteration 60500, Loss: 0.000000671\n",
      "Iteration 60510, Loss: 0.000000331\n",
      "Iteration 60520, Loss: 0.000000332\n",
      "Iteration 60530, Loss: 0.000000320\n",
      "Iteration 60540, Loss: 0.000000322\n",
      "Iteration 60550, Loss: 0.000000438\n",
      "Iteration 60560, Loss: 0.000000355\n",
      "Iteration 60570, Loss: 0.000000913\n",
      "Iteration 60580, Loss: 0.000000387\n",
      "Iteration 60590, Loss: 0.000000439\n",
      "Iteration 60600, Loss: 0.000000368\n",
      "Iteration 60610, Loss: 0.000000311\n",
      "Iteration 60620, Loss: 0.000000302\n",
      "Iteration 60630, Loss: 0.000000299\n",
      "Iteration 60640, Loss: 0.000000300\n",
      "Iteration 60650, Loss: 0.000000365\n",
      "Iteration 60660, Loss: 0.000001164\n",
      "Iteration 60670, Loss: 0.000000528\n",
      "Iteration 60680, Loss: 0.000000505\n",
      "Iteration 60690, Loss: 0.000000448\n",
      "Iteration 60700, Loss: 0.000000335\n",
      "Iteration 60710, Loss: 0.000000306\n",
      "Iteration 60720, Loss: 0.000000299\n",
      "Iteration 60730, Loss: 0.000000298\n",
      "Iteration 60740, Loss: 0.000000299\n",
      "Iteration 60750, Loss: 0.000000336\n",
      "Iteration 60760, Loss: 0.000001214\n",
      "Iteration 60770, Loss: 0.000000635\n",
      "Iteration 60780, Loss: 0.000000333\n",
      "Iteration 60790, Loss: 0.000000336\n",
      "Iteration 60800, Loss: 0.000000308\n",
      "Iteration 60810, Loss: 0.000000306\n",
      "Iteration 60820, Loss: 0.000000522\n",
      "Iteration 60830, Loss: 0.000002071\n",
      "Iteration 60840, Loss: 0.000000580\n",
      "Iteration 60850, Loss: 0.000000316\n",
      "Iteration 60860, Loss: 0.000000357\n",
      "Iteration 60870, Loss: 0.000000329\n",
      "Iteration 60880, Loss: 0.000000396\n",
      "Iteration 60890, Loss: 0.000000404\n",
      "Iteration 60900, Loss: 0.000000657\n",
      "Iteration 60910, Loss: 0.000001009\n",
      "Iteration 60920, Loss: 0.000000614\n",
      "Iteration 60930, Loss: 0.000000382\n",
      "Iteration 60940, Loss: 0.000000366\n",
      "Iteration 60950, Loss: 0.000000311\n",
      "Iteration 60960, Loss: 0.000000301\n",
      "Iteration 60970, Loss: 0.000000298\n",
      "Iteration 60980, Loss: 0.000000298\n",
      "Iteration 60990, Loss: 0.000000297\n",
      "Iteration 61000, Loss: 0.000000305\n",
      "Iteration 61010, Loss: 0.000000662\n",
      "Iteration 61020, Loss: 0.000000508\n",
      "Iteration 61030, Loss: 0.000000399\n",
      "Iteration 61040, Loss: 0.000000329\n",
      "Iteration 61050, Loss: 0.000000309\n",
      "Iteration 61060, Loss: 0.000000312\n",
      "Iteration 61070, Loss: 0.000000651\n",
      "Iteration 61080, Loss: 0.000001417\n",
      "Iteration 61090, Loss: 0.000000310\n",
      "Iteration 61100, Loss: 0.000000451\n",
      "Iteration 61110, Loss: 0.000000373\n",
      "Iteration 61120, Loss: 0.000000301\n",
      "Iteration 61130, Loss: 0.000000299\n",
      "Iteration 61140, Loss: 0.000000304\n",
      "Iteration 61150, Loss: 0.000000432\n",
      "Iteration 61160, Loss: 0.000000888\n",
      "Iteration 61170, Loss: 0.000000484\n",
      "Iteration 61180, Loss: 0.000000364\n",
      "Iteration 61190, Loss: 0.000000519\n",
      "Iteration 61200, Loss: 0.000000678\n",
      "Iteration 61210, Loss: 0.000000435\n",
      "Iteration 61220, Loss: 0.000000351\n",
      "Iteration 61230, Loss: 0.000000337\n",
      "Iteration 61240, Loss: 0.000000463\n",
      "Iteration 61250, Loss: 0.000001309\n",
      "Iteration 61260, Loss: 0.000000457\n",
      "Iteration 61270, Loss: 0.000000325\n",
      "Iteration 61280, Loss: 0.000000351\n",
      "Iteration 61290, Loss: 0.000000421\n",
      "Iteration 61300, Loss: 0.000000434\n",
      "Iteration 61310, Loss: 0.000000341\n",
      "Iteration 61320, Loss: 0.000000361\n",
      "Iteration 61330, Loss: 0.000000750\n",
      "Iteration 61340, Loss: 0.000000362\n",
      "Iteration 61350, Loss: 0.000000571\n",
      "Iteration 61360, Loss: 0.000001526\n",
      "Iteration 61370, Loss: 0.000000673\n",
      "Iteration 61380, Loss: 0.000000407\n",
      "Iteration 61390, Loss: 0.000000312\n",
      "Iteration 61400, Loss: 0.000000314\n",
      "Iteration 61410, Loss: 0.000000317\n",
      "Iteration 61420, Loss: 0.000000426\n",
      "Iteration 61430, Loss: 0.000000436\n",
      "Iteration 61440, Loss: 0.000000748\n",
      "Iteration 61450, Loss: 0.000000400\n",
      "Iteration 61460, Loss: 0.000000326\n",
      "Iteration 61470, Loss: 0.000000670\n",
      "Iteration 61480, Loss: 0.000001293\n",
      "Iteration 61490, Loss: 0.000000450\n",
      "Iteration 61500, Loss: 0.000000315\n",
      "Iteration 61510, Loss: 0.000000318\n",
      "Iteration 61520, Loss: 0.000000360\n",
      "Iteration 61530, Loss: 0.000000906\n",
      "Iteration 61540, Loss: 0.000000372\n",
      "Iteration 61550, Loss: 0.000000333\n",
      "Iteration 61560, Loss: 0.000000327\n",
      "Iteration 61570, Loss: 0.000000326\n",
      "Iteration 61580, Loss: 0.000000385\n",
      "Iteration 61590, Loss: 0.000000429\n",
      "Iteration 61600, Loss: 0.000000393\n",
      "Iteration 61610, Loss: 0.000001207\n",
      "Iteration 61620, Loss: 0.000000392\n",
      "Iteration 61630, Loss: 0.000000376\n",
      "Iteration 61640, Loss: 0.000000339\n",
      "Iteration 61650, Loss: 0.000000300\n",
      "Iteration 61660, Loss: 0.000000312\n",
      "Iteration 61670, Loss: 0.000000432\n",
      "Iteration 61680, Loss: 0.000001698\n",
      "Iteration 61690, Loss: 0.000000777\n",
      "Iteration 61700, Loss: 0.000000358\n",
      "Iteration 61710, Loss: 0.000000357\n",
      "Iteration 61720, Loss: 0.000000316\n",
      "Iteration 61730, Loss: 0.000000317\n",
      "Iteration 61740, Loss: 0.000000506\n",
      "Iteration 61750, Loss: 0.000000505\n",
      "Iteration 61760, Loss: 0.000001023\n",
      "Iteration 61770, Loss: 0.000000545\n",
      "Iteration 61780, Loss: 0.000000405\n",
      "Iteration 61790, Loss: 0.000000362\n",
      "Iteration 61800, Loss: 0.000000324\n",
      "Iteration 61810, Loss: 0.000000310\n",
      "Iteration 61820, Loss: 0.000000300\n",
      "Iteration 61830, Loss: 0.000000298\n",
      "Iteration 61840, Loss: 0.000000306\n",
      "Iteration 61850, Loss: 0.000000510\n",
      "Iteration 61860, Loss: 0.000000696\n",
      "Iteration 61870, Loss: 0.000001191\n",
      "Iteration 61880, Loss: 0.000000542\n",
      "Iteration 61890, Loss: 0.000000468\n",
      "Iteration 61900, Loss: 0.000000356\n",
      "Iteration 61910, Loss: 0.000000313\n",
      "Iteration 61920, Loss: 0.000000302\n",
      "Iteration 61930, Loss: 0.000000301\n",
      "Iteration 61940, Loss: 0.000000310\n",
      "Iteration 61950, Loss: 0.000000581\n",
      "Iteration 61960, Loss: 0.000001850\n",
      "Iteration 61970, Loss: 0.000000662\n",
      "Iteration 61980, Loss: 0.000000334\n",
      "Iteration 61990, Loss: 0.000000363\n",
      "Iteration 62000, Loss: 0.000000327\n",
      "Iteration 62010, Loss: 0.000000328\n",
      "Iteration 62020, Loss: 0.000000631\n",
      "Iteration 62030, Loss: 0.000000676\n",
      "Iteration 62040, Loss: 0.000000388\n",
      "Iteration 62050, Loss: 0.000000311\n",
      "Iteration 62060, Loss: 0.000000311\n",
      "Iteration 62070, Loss: 0.000000342\n",
      "Iteration 62080, Loss: 0.000000980\n",
      "Iteration 62090, Loss: 0.000000450\n",
      "Iteration 62100, Loss: 0.000000430\n",
      "Iteration 62110, Loss: 0.000000329\n",
      "Iteration 62120, Loss: 0.000000321\n",
      "Iteration 62130, Loss: 0.000000320\n",
      "Iteration 62140, Loss: 0.000000382\n",
      "Iteration 62150, Loss: 0.000001052\n",
      "Iteration 62160, Loss: 0.000000350\n",
      "Iteration 62170, Loss: 0.000000448\n",
      "Iteration 62180, Loss: 0.000000529\n",
      "Iteration 62190, Loss: 0.000000422\n",
      "Iteration 62200, Loss: 0.000000311\n",
      "Iteration 62210, Loss: 0.000000315\n",
      "Iteration 62220, Loss: 0.000000363\n",
      "Iteration 62230, Loss: 0.000000810\n",
      "Iteration 62240, Loss: 0.000000760\n",
      "Iteration 62250, Loss: 0.000000511\n",
      "Iteration 62260, Loss: 0.000000470\n",
      "Iteration 62270, Loss: 0.000000482\n",
      "Iteration 62280, Loss: 0.000000470\n",
      "Iteration 62290, Loss: 0.000000381\n",
      "Iteration 62300, Loss: 0.000000401\n",
      "Iteration 62310, Loss: 0.000000741\n",
      "Iteration 62320, Loss: 0.000000533\n",
      "Iteration 62330, Loss: 0.000000776\n",
      "Iteration 62340, Loss: 0.000000512\n",
      "Iteration 62350, Loss: 0.000000446\n",
      "Iteration 62360, Loss: 0.000000328\n",
      "Iteration 62370, Loss: 0.000000321\n",
      "Iteration 62380, Loss: 0.000000390\n",
      "Iteration 62390, Loss: 0.000000824\n",
      "Iteration 62400, Loss: 0.000000666\n",
      "Iteration 62410, Loss: 0.000000916\n",
      "Iteration 62420, Loss: 0.000000564\n",
      "Iteration 62430, Loss: 0.000000335\n",
      "Iteration 62440, Loss: 0.000000346\n",
      "Iteration 62450, Loss: 0.000000302\n",
      "Iteration 62460, Loss: 0.000000306\n",
      "Iteration 62470, Loss: 0.000000311\n",
      "Iteration 62480, Loss: 0.000000421\n",
      "Iteration 62490, Loss: 0.000001521\n",
      "Iteration 62500, Loss: 0.000000529\n",
      "Iteration 62510, Loss: 0.000000664\n",
      "Iteration 62520, Loss: 0.000000328\n",
      "Iteration 62530, Loss: 0.000000343\n",
      "Iteration 62540, Loss: 0.000000302\n",
      "Iteration 62550, Loss: 0.000000333\n",
      "Iteration 62560, Loss: 0.000000811\n",
      "Iteration 62570, Loss: 0.000000393\n",
      "Iteration 62580, Loss: 0.000000384\n",
      "Iteration 62590, Loss: 0.000000377\n",
      "Iteration 62600, Loss: 0.000000388\n",
      "Iteration 62610, Loss: 0.000000515\n",
      "Iteration 62620, Loss: 0.000000679\n",
      "Iteration 62630, Loss: 0.000000297\n",
      "Iteration 62640, Loss: 0.000000399\n",
      "Iteration 62650, Loss: 0.000000566\n",
      "Iteration 62660, Loss: 0.000000588\n",
      "Iteration 62670, Loss: 0.000001095\n",
      "Iteration 62680, Loss: 0.000000354\n",
      "Iteration 62690, Loss: 0.000000396\n",
      "Iteration 62700, Loss: 0.000000359\n",
      "Iteration 62710, Loss: 0.000000314\n",
      "Iteration 62720, Loss: 0.000000326\n",
      "Iteration 62730, Loss: 0.000000629\n",
      "Iteration 62740, Loss: 0.000000969\n",
      "Iteration 62750, Loss: 0.000000541\n",
      "Iteration 62760, Loss: 0.000000441\n",
      "Iteration 62770, Loss: 0.000000501\n",
      "Iteration 62780, Loss: 0.000000414\n",
      "Iteration 62790, Loss: 0.000000356\n",
      "Iteration 62800, Loss: 0.000000368\n",
      "Iteration 62810, Loss: 0.000000512\n",
      "Iteration 62820, Loss: 0.000001097\n",
      "Iteration 62830, Loss: 0.000000423\n",
      "Iteration 62840, Loss: 0.000000376\n",
      "Iteration 62850, Loss: 0.000000361\n",
      "Iteration 62860, Loss: 0.000000410\n",
      "Iteration 62870, Loss: 0.000000357\n",
      "Iteration 62880, Loss: 0.000000378\n",
      "Iteration 62890, Loss: 0.000001440\n",
      "Iteration 62900, Loss: 0.000000959\n",
      "Iteration 62910, Loss: 0.000000507\n",
      "Iteration 62920, Loss: 0.000000355\n",
      "Iteration 62930, Loss: 0.000000355\n",
      "Iteration 62940, Loss: 0.000000370\n",
      "Iteration 62950, Loss: 0.000000524\n",
      "Iteration 62960, Loss: 0.000000768\n",
      "Iteration 62970, Loss: 0.000000304\n",
      "Iteration 62980, Loss: 0.000000401\n",
      "Iteration 62990, Loss: 0.000000369\n",
      "Iteration 63000, Loss: 0.000000583\n",
      "Iteration 63010, Loss: 0.000000822\n",
      "Iteration 63020, Loss: 0.000000334\n",
      "Iteration 63030, Loss: 0.000000407\n",
      "Iteration 63040, Loss: 0.000000471\n",
      "Iteration 63050, Loss: 0.000000528\n",
      "Iteration 63060, Loss: 0.000000455\n",
      "Iteration 63070, Loss: 0.000000655\n",
      "Iteration 63080, Loss: 0.000000375\n",
      "Iteration 63090, Loss: 0.000000340\n",
      "Iteration 63100, Loss: 0.000000466\n",
      "Iteration 63110, Loss: 0.000000709\n",
      "Iteration 63120, Loss: 0.000000422\n",
      "Iteration 63130, Loss: 0.000000848\n",
      "Iteration 63140, Loss: 0.000000456\n",
      "Iteration 63150, Loss: 0.000000422\n",
      "Iteration 63160, Loss: 0.000000336\n",
      "Iteration 63170, Loss: 0.000000322\n",
      "Iteration 63180, Loss: 0.000000460\n",
      "Iteration 63190, Loss: 0.000000564\n",
      "Iteration 63200, Loss: 0.000000579\n",
      "Iteration 63210, Loss: 0.000000973\n",
      "Iteration 63220, Loss: 0.000000939\n",
      "Iteration 63230, Loss: 0.000000575\n",
      "Iteration 63240, Loss: 0.000000349\n",
      "Iteration 63250, Loss: 0.000000389\n",
      "Iteration 63260, Loss: 0.000000325\n",
      "Iteration 63270, Loss: 0.000000344\n",
      "Iteration 63280, Loss: 0.000000470\n",
      "Iteration 63290, Loss: 0.000000550\n",
      "Iteration 63300, Loss: 0.000000353\n",
      "Iteration 63310, Loss: 0.000000320\n",
      "Iteration 63320, Loss: 0.000000445\n",
      "Iteration 63330, Loss: 0.000001086\n",
      "Iteration 63340, Loss: 0.000000794\n",
      "Iteration 63350, Loss: 0.000000527\n",
      "Iteration 63360, Loss: 0.000000380\n",
      "Iteration 63370, Loss: 0.000000327\n",
      "Iteration 63380, Loss: 0.000000345\n",
      "Iteration 63390, Loss: 0.000000832\n",
      "Iteration 63400, Loss: 0.000000690\n",
      "Iteration 63410, Loss: 0.000000494\n",
      "Iteration 63420, Loss: 0.000000391\n",
      "Iteration 63430, Loss: 0.000000343\n",
      "Iteration 63440, Loss: 0.000000321\n",
      "Iteration 63450, Loss: 0.000000370\n",
      "Iteration 63460, Loss: 0.000001058\n",
      "Iteration 63470, Loss: 0.000000530\n",
      "Iteration 63480, Loss: 0.000000392\n",
      "Iteration 63490, Loss: 0.000000355\n",
      "Iteration 63500, Loss: 0.000000559\n",
      "Iteration 63510, Loss: 0.000001020\n",
      "Iteration 63520, Loss: 0.000000408\n",
      "Iteration 63530, Loss: 0.000000362\n",
      "Iteration 63540, Loss: 0.000000336\n",
      "Iteration 63550, Loss: 0.000000300\n",
      "Iteration 63560, Loss: 0.000000298\n",
      "Iteration 63570, Loss: 0.000000439\n",
      "Iteration 63580, Loss: 0.000002827\n",
      "Iteration 63590, Loss: 0.000000505\n",
      "Iteration 63600, Loss: 0.000000513\n",
      "Iteration 63610, Loss: 0.000000352\n",
      "Iteration 63620, Loss: 0.000000300\n",
      "Iteration 63630, Loss: 0.000000301\n",
      "Iteration 63640, Loss: 0.000000297\n",
      "Iteration 63650, Loss: 0.000000317\n",
      "Iteration 63660, Loss: 0.000000933\n",
      "Iteration 63670, Loss: 0.000000468\n",
      "Iteration 63680, Loss: 0.000000393\n",
      "Iteration 63690, Loss: 0.000000357\n",
      "Iteration 63700, Loss: 0.000000315\n",
      "Iteration 63710, Loss: 0.000000300\n",
      "Iteration 63720, Loss: 0.000000314\n",
      "Iteration 63730, Loss: 0.000000550\n",
      "Iteration 63740, Loss: 0.000000374\n",
      "Iteration 63750, Loss: 0.000000331\n",
      "Iteration 63760, Loss: 0.000000317\n",
      "Iteration 63770, Loss: 0.000000371\n",
      "Iteration 63780, Loss: 0.000002284\n",
      "Iteration 63790, Loss: 0.000001025\n",
      "Iteration 63800, Loss: 0.000000699\n",
      "Iteration 63810, Loss: 0.000000401\n",
      "Iteration 63820, Loss: 0.000000310\n",
      "Iteration 63830, Loss: 0.000000297\n",
      "Iteration 63840, Loss: 0.000000295\n",
      "Iteration 63850, Loss: 0.000000307\n",
      "Iteration 63860, Loss: 0.000000651\n",
      "Iteration 63870, Loss: 0.000000436\n",
      "Iteration 63880, Loss: 0.000000365\n",
      "Iteration 63890, Loss: 0.000000336\n",
      "Iteration 63900, Loss: 0.000000310\n",
      "Iteration 63910, Loss: 0.000000299\n",
      "Iteration 63920, Loss: 0.000000301\n",
      "Iteration 63930, Loss: 0.000000342\n",
      "Iteration 63940, Loss: 0.000000849\n",
      "Iteration 63950, Loss: 0.000001181\n",
      "Iteration 63960, Loss: 0.000000547\n",
      "Iteration 63970, Loss: 0.000000678\n",
      "Iteration 63980, Loss: 0.000000357\n",
      "Iteration 63990, Loss: 0.000000330\n",
      "Iteration 64000, Loss: 0.000000316\n",
      "Iteration 64010, Loss: 0.000000295\n",
      "Iteration 64020, Loss: 0.000000295\n",
      "Iteration 64030, Loss: 0.000000302\n",
      "Iteration 64040, Loss: 0.000000390\n",
      "Iteration 64050, Loss: 0.000001430\n",
      "Iteration 64060, Loss: 0.000000462\n",
      "Iteration 64070, Loss: 0.000000373\n",
      "Iteration 64080, Loss: 0.000000345\n",
      "Iteration 64090, Loss: 0.000000357\n",
      "Iteration 64100, Loss: 0.000000607\n",
      "Iteration 64110, Loss: 0.000000630\n",
      "Iteration 64120, Loss: 0.000000378\n",
      "Iteration 64130, Loss: 0.000000339\n",
      "Iteration 64140, Loss: 0.000000394\n",
      "Iteration 64150, Loss: 0.000000531\n",
      "Iteration 64160, Loss: 0.000000369\n",
      "Iteration 64170, Loss: 0.000000630\n",
      "Iteration 64180, Loss: 0.000000987\n",
      "Iteration 64190, Loss: 0.000000566\n",
      "Iteration 64200, Loss: 0.000000369\n",
      "Iteration 64210, Loss: 0.000000298\n",
      "Iteration 64220, Loss: 0.000000304\n",
      "Iteration 64230, Loss: 0.000000335\n",
      "Iteration 64240, Loss: 0.000001155\n",
      "Iteration 64250, Loss: 0.000000523\n",
      "Iteration 64260, Loss: 0.000000490\n",
      "Iteration 64270, Loss: 0.000000686\n",
      "Iteration 64280, Loss: 0.000000609\n",
      "Iteration 64290, Loss: 0.000000389\n",
      "Iteration 64300, Loss: 0.000000316\n",
      "Iteration 64310, Loss: 0.000000326\n",
      "Iteration 64320, Loss: 0.000000554\n",
      "Iteration 64330, Loss: 0.000000591\n",
      "Iteration 64340, Loss: 0.000000780\n",
      "Iteration 64350, Loss: 0.000000616\n",
      "Iteration 64360, Loss: 0.000000368\n",
      "Iteration 64370, Loss: 0.000000352\n",
      "Iteration 64380, Loss: 0.000000316\n",
      "Iteration 64390, Loss: 0.000000341\n",
      "Iteration 64400, Loss: 0.000000832\n",
      "Iteration 64410, Loss: 0.000000674\n",
      "Iteration 64420, Loss: 0.000000504\n",
      "Iteration 64430, Loss: 0.000000386\n",
      "Iteration 64440, Loss: 0.000000333\n",
      "Iteration 64450, Loss: 0.000000304\n",
      "Iteration 64460, Loss: 0.000000321\n",
      "Iteration 64470, Loss: 0.000000912\n",
      "Iteration 64480, Loss: 0.000001094\n",
      "Iteration 64490, Loss: 0.000000466\n",
      "Iteration 64500, Loss: 0.000000385\n",
      "Iteration 64510, Loss: 0.000000348\n",
      "Iteration 64520, Loss: 0.000000575\n",
      "Iteration 64530, Loss: 0.000000895\n",
      "Iteration 64540, Loss: 0.000000397\n",
      "Iteration 64550, Loss: 0.000000306\n",
      "Iteration 64560, Loss: 0.000000333\n",
      "Iteration 64570, Loss: 0.000000305\n",
      "Iteration 64580, Loss: 0.000000354\n",
      "Iteration 64590, Loss: 0.000000500\n",
      "Iteration 64600, Loss: 0.000000734\n",
      "Iteration 64610, Loss: 0.000001004\n",
      "Iteration 64620, Loss: 0.000000889\n",
      "Iteration 64630, Loss: 0.000000505\n",
      "Iteration 64640, Loss: 0.000000350\n",
      "Iteration 64650, Loss: 0.000000307\n",
      "Iteration 64660, Loss: 0.000000303\n",
      "Iteration 64670, Loss: 0.000000297\n",
      "Iteration 64680, Loss: 0.000000291\n",
      "Iteration 64690, Loss: 0.000000291\n",
      "Iteration 64700, Loss: 0.000000294\n",
      "Iteration 64710, Loss: 0.000000467\n",
      "Iteration 64720, Loss: 0.000001249\n",
      "Iteration 64730, Loss: 0.000000472\n",
      "Iteration 64740, Loss: 0.000000538\n",
      "Iteration 64750, Loss: 0.000000618\n",
      "Iteration 64760, Loss: 0.000000317\n",
      "Iteration 64770, Loss: 0.000000324\n",
      "Iteration 64780, Loss: 0.000000416\n",
      "Iteration 64790, Loss: 0.000000737\n",
      "Iteration 64800, Loss: 0.000000393\n",
      "Iteration 64810, Loss: 0.000000383\n",
      "Iteration 64820, Loss: 0.000000334\n",
      "Iteration 64830, Loss: 0.000000351\n",
      "Iteration 64840, Loss: 0.000000416\n",
      "Iteration 64850, Loss: 0.000001494\n",
      "Iteration 64860, Loss: 0.000000645\n",
      "Iteration 64870, Loss: 0.000000435\n",
      "Iteration 64880, Loss: 0.000000346\n",
      "Iteration 64890, Loss: 0.000000308\n",
      "Iteration 64900, Loss: 0.000000304\n",
      "Iteration 64910, Loss: 0.000000870\n",
      "Iteration 64920, Loss: 0.000000467\n",
      "Iteration 64930, Loss: 0.000000675\n",
      "Iteration 64940, Loss: 0.000000402\n",
      "Iteration 64950, Loss: 0.000000329\n",
      "Iteration 64960, Loss: 0.000000311\n",
      "Iteration 64970, Loss: 0.000000293\n",
      "Iteration 64980, Loss: 0.000000298\n",
      "Iteration 64990, Loss: 0.000000507\n",
      "Iteration 65000, Loss: 0.000000366\n",
      "Iteration 65010, Loss: 0.000000303\n",
      "Iteration 65020, Loss: 0.000000313\n",
      "Iteration 65030, Loss: 0.000000638\n",
      "Iteration 65040, Loss: 0.000000726\n",
      "Iteration 65050, Loss: 0.000000485\n",
      "Iteration 65060, Loss: 0.000000344\n",
      "Iteration 65070, Loss: 0.000000323\n",
      "Iteration 65080, Loss: 0.000000302\n",
      "Iteration 65090, Loss: 0.000000324\n",
      "Iteration 65100, Loss: 0.000000819\n",
      "Iteration 65110, Loss: 0.000000383\n",
      "Iteration 65120, Loss: 0.000000486\n",
      "Iteration 65130, Loss: 0.000001440\n",
      "Iteration 65140, Loss: 0.000000519\n",
      "Iteration 65150, Loss: 0.000000341\n",
      "Iteration 65160, Loss: 0.000000293\n",
      "Iteration 65170, Loss: 0.000000302\n",
      "Iteration 65180, Loss: 0.000000300\n",
      "Iteration 65190, Loss: 0.000000361\n",
      "Iteration 65200, Loss: 0.000001429\n",
      "Iteration 65210, Loss: 0.000000814\n",
      "Iteration 65220, Loss: 0.000000435\n",
      "Iteration 65230, Loss: 0.000000307\n",
      "Iteration 65240, Loss: 0.000000309\n",
      "Iteration 65250, Loss: 0.000000576\n",
      "Iteration 65260, Loss: 0.000001568\n",
      "Iteration 65270, Loss: 0.000000652\n",
      "Iteration 65280, Loss: 0.000000356\n",
      "Iteration 65290, Loss: 0.000000299\n",
      "Iteration 65300, Loss: 0.000000292\n",
      "Iteration 65310, Loss: 0.000000300\n",
      "Iteration 65320, Loss: 0.000000429\n",
      "Iteration 65330, Loss: 0.000000526\n",
      "Iteration 65340, Loss: 0.000000367\n",
      "Iteration 65350, Loss: 0.000000320\n",
      "Iteration 65360, Loss: 0.000000313\n",
      "Iteration 65370, Loss: 0.000000469\n",
      "Iteration 65380, Loss: 0.000001261\n",
      "Iteration 65390, Loss: 0.000000505\n",
      "Iteration 65400, Loss: 0.000000508\n",
      "Iteration 65410, Loss: 0.000000563\n",
      "Iteration 65420, Loss: 0.000000414\n",
      "Iteration 65430, Loss: 0.000000355\n",
      "Iteration 65440, Loss: 0.000000351\n",
      "Iteration 65450, Loss: 0.000000349\n",
      "Iteration 65460, Loss: 0.000000623\n",
      "Iteration 65470, Loss: 0.000000802\n",
      "Iteration 65480, Loss: 0.000000429\n",
      "Iteration 65490, Loss: 0.000000330\n",
      "Iteration 65500, Loss: 0.000000308\n",
      "Iteration 65510, Loss: 0.000000329\n",
      "Iteration 65520, Loss: 0.000000702\n",
      "Iteration 65530, Loss: 0.000000632\n",
      "Iteration 65540, Loss: 0.000000905\n",
      "Iteration 65550, Loss: 0.000000553\n",
      "Iteration 65560, Loss: 0.000000588\n",
      "Iteration 65570, Loss: 0.000000362\n",
      "Iteration 65580, Loss: 0.000000461\n",
      "Iteration 65590, Loss: 0.000000345\n",
      "Iteration 65600, Loss: 0.000000499\n",
      "Iteration 65610, Loss: 0.000000364\n",
      "Iteration 65620, Loss: 0.000000340\n",
      "Iteration 65630, Loss: 0.000000537\n",
      "Iteration 65640, Loss: 0.000000495\n",
      "Iteration 65650, Loss: 0.000000339\n",
      "Iteration 65660, Loss: 0.000000412\n",
      "Iteration 65670, Loss: 0.000000620\n",
      "Iteration 65680, Loss: 0.000000565\n",
      "Iteration 65690, Loss: 0.000000666\n",
      "Iteration 65700, Loss: 0.000000434\n",
      "Iteration 65710, Loss: 0.000000443\n",
      "Iteration 65720, Loss: 0.000000385\n",
      "Iteration 65730, Loss: 0.000000487\n",
      "Iteration 65740, Loss: 0.000000931\n",
      "Iteration 65750, Loss: 0.000000341\n",
      "Iteration 65760, Loss: 0.000000385\n",
      "Iteration 65770, Loss: 0.000000390\n",
      "Iteration 65780, Loss: 0.000000492\n",
      "Iteration 65790, Loss: 0.000000583\n",
      "Iteration 65800, Loss: 0.000000785\n",
      "Iteration 65810, Loss: 0.000000409\n",
      "Iteration 65820, Loss: 0.000000428\n",
      "Iteration 65830, Loss: 0.000000331\n",
      "Iteration 65840, Loss: 0.000000311\n",
      "Iteration 65850, Loss: 0.000000378\n",
      "Iteration 65860, Loss: 0.000000861\n",
      "Iteration 65870, Loss: 0.000000743\n",
      "Iteration 65880, Loss: 0.000001474\n",
      "Iteration 65890, Loss: 0.000000647\n",
      "Iteration 65900, Loss: 0.000000393\n",
      "Iteration 65910, Loss: 0.000000324\n",
      "Iteration 65920, Loss: 0.000000297\n",
      "Iteration 65930, Loss: 0.000000295\n",
      "Iteration 65940, Loss: 0.000000291\n",
      "Iteration 65950, Loss: 0.000000348\n",
      "Iteration 65960, Loss: 0.000000776\n",
      "Iteration 65970, Loss: 0.000000462\n",
      "Iteration 65980, Loss: 0.000000706\n",
      "Iteration 65990, Loss: 0.000000718\n",
      "Iteration 66000, Loss: 0.000000470\n",
      "Iteration 66010, Loss: 0.000000295\n",
      "Iteration 66020, Loss: 0.000000340\n",
      "Iteration 66030, Loss: 0.000000301\n",
      "Iteration 66040, Loss: 0.000000440\n",
      "Iteration 66050, Loss: 0.000001064\n",
      "Iteration 66060, Loss: 0.000000822\n",
      "Iteration 66070, Loss: 0.000000346\n",
      "Iteration 66080, Loss: 0.000000364\n",
      "Iteration 66090, Loss: 0.000000338\n",
      "Iteration 66100, Loss: 0.000000336\n",
      "Iteration 66110, Loss: 0.000000531\n",
      "Iteration 66120, Loss: 0.000001183\n",
      "Iteration 66130, Loss: 0.000000491\n",
      "Iteration 66140, Loss: 0.000000335\n",
      "Iteration 66150, Loss: 0.000000319\n",
      "Iteration 66160, Loss: 0.000000301\n",
      "Iteration 66170, Loss: 0.000000332\n",
      "Iteration 66180, Loss: 0.000001322\n",
      "Iteration 66190, Loss: 0.000000832\n",
      "Iteration 66200, Loss: 0.000000408\n",
      "Iteration 66210, Loss: 0.000000336\n",
      "Iteration 66220, Loss: 0.000000320\n",
      "Iteration 66230, Loss: 0.000000300\n",
      "Iteration 66240, Loss: 0.000000373\n",
      "Iteration 66250, Loss: 0.000001500\n",
      "Iteration 66260, Loss: 0.000000509\n",
      "Iteration 66270, Loss: 0.000000392\n",
      "Iteration 66280, Loss: 0.000000336\n",
      "Iteration 66290, Loss: 0.000000301\n",
      "Iteration 66300, Loss: 0.000000294\n",
      "Iteration 66310, Loss: 0.000000323\n",
      "Iteration 66320, Loss: 0.000001244\n",
      "Iteration 66330, Loss: 0.000000425\n",
      "Iteration 66340, Loss: 0.000000504\n",
      "Iteration 66350, Loss: 0.000000358\n",
      "Iteration 66360, Loss: 0.000000311\n",
      "Iteration 66370, Loss: 0.000000298\n",
      "Iteration 66380, Loss: 0.000000291\n",
      "Iteration 66390, Loss: 0.000000294\n",
      "Iteration 66400, Loss: 0.000000476\n",
      "Iteration 66410, Loss: 0.000000377\n",
      "Iteration 66420, Loss: 0.000000382\n",
      "Iteration 66430, Loss: 0.000002426\n",
      "Iteration 66440, Loss: 0.000001049\n",
      "Iteration 66450, Loss: 0.000000625\n",
      "Iteration 66460, Loss: 0.000000412\n",
      "Iteration 66470, Loss: 0.000000337\n",
      "Iteration 66480, Loss: 0.000000310\n",
      "Iteration 66490, Loss: 0.000000297\n",
      "Iteration 66500, Loss: 0.000000293\n",
      "Iteration 66510, Loss: 0.000000309\n",
      "Iteration 66520, Loss: 0.000000633\n",
      "Iteration 66530, Loss: 0.000000479\n",
      "Iteration 66540, Loss: 0.000000432\n",
      "Iteration 66550, Loss: 0.000000399\n",
      "Iteration 66560, Loss: 0.000000316\n",
      "Iteration 66570, Loss: 0.000000295\n",
      "Iteration 66580, Loss: 0.000000309\n",
      "Iteration 66590, Loss: 0.000000725\n",
      "Iteration 66600, Loss: 0.000001002\n",
      "Iteration 66610, Loss: 0.000000374\n",
      "Iteration 66620, Loss: 0.000000335\n",
      "Iteration 66630, Loss: 0.000000333\n",
      "Iteration 66640, Loss: 0.000000306\n",
      "Iteration 66650, Loss: 0.000000294\n",
      "Iteration 66660, Loss: 0.000000292\n",
      "Iteration 66670, Loss: 0.000000351\n",
      "Iteration 66680, Loss: 0.000001662\n",
      "Iteration 66690, Loss: 0.000000779\n",
      "Iteration 66700, Loss: 0.000000457\n",
      "Iteration 66710, Loss: 0.000000378\n",
      "Iteration 66720, Loss: 0.000000318\n",
      "Iteration 66730, Loss: 0.000000292\n",
      "Iteration 66740, Loss: 0.000000292\n",
      "Iteration 66750, Loss: 0.000000289\n",
      "Iteration 66760, Loss: 0.000000289\n",
      "Iteration 66770, Loss: 0.000000341\n",
      "Iteration 66780, Loss: 0.000001430\n",
      "Iteration 66790, Loss: 0.000000494\n",
      "Iteration 66800, Loss: 0.000000436\n",
      "Iteration 66810, Loss: 0.000000400\n",
      "Iteration 66820, Loss: 0.000000330\n",
      "Iteration 66830, Loss: 0.000000301\n",
      "Iteration 66840, Loss: 0.000000300\n",
      "Iteration 66850, Loss: 0.000000515\n",
      "Iteration 66860, Loss: 0.000000674\n",
      "Iteration 66870, Loss: 0.000000332\n",
      "Iteration 66880, Loss: 0.000000321\n",
      "Iteration 66890, Loss: 0.000000313\n",
      "Iteration 66900, Loss: 0.000000295\n",
      "Iteration 66910, Loss: 0.000000350\n",
      "Iteration 66920, Loss: 0.000003508\n",
      "Iteration 66930, Loss: 0.000001164\n",
      "Iteration 66940, Loss: 0.000000458\n",
      "Iteration 66950, Loss: 0.000000345\n",
      "Iteration 66960, Loss: 0.000000310\n",
      "Iteration 66970, Loss: 0.000000292\n",
      "Iteration 66980, Loss: 0.000000289\n",
      "Iteration 66990, Loss: 0.000000287\n",
      "Iteration 67000, Loss: 0.000000286\n",
      "Iteration 67010, Loss: 0.000000285\n",
      "Iteration 67020, Loss: 0.000000285\n",
      "Iteration 67030, Loss: 0.000000286\n",
      "Iteration 67040, Loss: 0.000000319\n",
      "Iteration 67050, Loss: 0.000001876\n",
      "Iteration 67060, Loss: 0.000001143\n",
      "Iteration 67070, Loss: 0.000000364\n",
      "Iteration 67080, Loss: 0.000000419\n",
      "Iteration 67090, Loss: 0.000000304\n",
      "Iteration 67100, Loss: 0.000000295\n",
      "Iteration 67110, Loss: 0.000000287\n",
      "Iteration 67120, Loss: 0.000000295\n",
      "Iteration 67130, Loss: 0.000000673\n",
      "Iteration 67140, Loss: 0.000001153\n",
      "Iteration 67150, Loss: 0.000000386\n",
      "Iteration 67160, Loss: 0.000000509\n",
      "Iteration 67170, Loss: 0.000000287\n",
      "Iteration 67180, Loss: 0.000000312\n",
      "Iteration 67190, Loss: 0.000000293\n",
      "Iteration 67200, Loss: 0.000000286\n",
      "Iteration 67210, Loss: 0.000000285\n",
      "Iteration 67220, Loss: 0.000000291\n",
      "Iteration 67230, Loss: 0.000000531\n",
      "Iteration 67240, Loss: 0.000000538\n",
      "Iteration 67250, Loss: 0.000000380\n",
      "Iteration 67260, Loss: 0.000000337\n",
      "Iteration 67270, Loss: 0.000000301\n",
      "Iteration 67280, Loss: 0.000000290\n",
      "Iteration 67290, Loss: 0.000000298\n",
      "Iteration 67300, Loss: 0.000000526\n",
      "Iteration 67310, Loss: 0.000001453\n",
      "Iteration 67320, Loss: 0.000000676\n",
      "Iteration 67330, Loss: 0.000000420\n",
      "Iteration 67340, Loss: 0.000000336\n",
      "Iteration 67350, Loss: 0.000000323\n",
      "Iteration 67360, Loss: 0.000000636\n",
      "Iteration 67370, Loss: 0.000000379\n",
      "Iteration 67380, Loss: 0.000000344\n",
      "Iteration 67390, Loss: 0.000000364\n",
      "Iteration 67400, Loss: 0.000000356\n",
      "Iteration 67410, Loss: 0.000000517\n",
      "Iteration 67420, Loss: 0.000000868\n",
      "Iteration 67430, Loss: 0.000000327\n",
      "Iteration 67440, Loss: 0.000000342\n",
      "Iteration 67450, Loss: 0.000000309\n",
      "Iteration 67460, Loss: 0.000000363\n",
      "Iteration 67470, Loss: 0.000000640\n",
      "Iteration 67480, Loss: 0.000000397\n",
      "Iteration 67490, Loss: 0.000000519\n",
      "Iteration 67500, Loss: 0.000001454\n",
      "Iteration 67510, Loss: 0.000000688\n",
      "Iteration 67520, Loss: 0.000000470\n",
      "Iteration 67530, Loss: 0.000000364\n",
      "Iteration 67540, Loss: 0.000000309\n",
      "Iteration 67550, Loss: 0.000000293\n",
      "Iteration 67560, Loss: 0.000000288\n",
      "Iteration 67570, Loss: 0.000000319\n",
      "Iteration 67580, Loss: 0.000000696\n",
      "Iteration 67590, Loss: 0.000001636\n",
      "Iteration 67600, Loss: 0.000000529\n",
      "Iteration 67610, Loss: 0.000000418\n",
      "Iteration 67620, Loss: 0.000000361\n",
      "Iteration 67630, Loss: 0.000000291\n",
      "Iteration 67640, Loss: 0.000000298\n",
      "Iteration 67650, Loss: 0.000000289\n",
      "Iteration 67660, Loss: 0.000000292\n",
      "Iteration 67670, Loss: 0.000000389\n",
      "Iteration 67680, Loss: 0.000001631\n",
      "Iteration 67690, Loss: 0.000000579\n",
      "Iteration 67700, Loss: 0.000000400\n",
      "Iteration 67710, Loss: 0.000000319\n",
      "Iteration 67720, Loss: 0.000000293\n",
      "Iteration 67730, Loss: 0.000000302\n",
      "Iteration 67740, Loss: 0.000000759\n",
      "Iteration 67750, Loss: 0.000000518\n",
      "Iteration 67760, Loss: 0.000000474\n",
      "Iteration 67770, Loss: 0.000000350\n",
      "Iteration 67780, Loss: 0.000000310\n",
      "Iteration 67790, Loss: 0.000000295\n",
      "Iteration 67800, Loss: 0.000000293\n",
      "Iteration 67810, Loss: 0.000000361\n",
      "Iteration 67820, Loss: 0.000001388\n",
      "Iteration 67830, Loss: 0.000001011\n",
      "Iteration 67840, Loss: 0.000000432\n",
      "Iteration 67850, Loss: 0.000000331\n",
      "Iteration 67860, Loss: 0.000000311\n",
      "Iteration 67870, Loss: 0.000000288\n",
      "Iteration 67880, Loss: 0.000000296\n",
      "Iteration 67890, Loss: 0.000000344\n",
      "Iteration 67900, Loss: 0.000001046\n",
      "Iteration 67910, Loss: 0.000000319\n",
      "Iteration 67920, Loss: 0.000000316\n",
      "Iteration 67930, Loss: 0.000000314\n",
      "Iteration 67940, Loss: 0.000000370\n",
      "Iteration 67950, Loss: 0.000001445\n",
      "Iteration 67960, Loss: 0.000000542\n",
      "Iteration 67970, Loss: 0.000000310\n",
      "Iteration 67980, Loss: 0.000000333\n",
      "Iteration 67990, Loss: 0.000000290\n",
      "Iteration 68000, Loss: 0.000000285\n",
      "Iteration 68010, Loss: 0.000000295\n",
      "Iteration 68020, Loss: 0.000000801\n",
      "Iteration 68030, Loss: 0.000000706\n",
      "Iteration 68040, Loss: 0.000000475\n",
      "Iteration 68050, Loss: 0.000000512\n",
      "Iteration 68060, Loss: 0.000000388\n",
      "Iteration 68070, Loss: 0.000000295\n",
      "Iteration 68080, Loss: 0.000000290\n",
      "Iteration 68090, Loss: 0.000000298\n",
      "Iteration 68100, Loss: 0.000000510\n",
      "Iteration 68110, Loss: 0.000000531\n",
      "Iteration 68120, Loss: 0.000000355\n",
      "Iteration 68130, Loss: 0.000000316\n",
      "Iteration 68140, Loss: 0.000000295\n",
      "Iteration 68150, Loss: 0.000000292\n",
      "Iteration 68160, Loss: 0.000000286\n",
      "Iteration 68170, Loss: 0.000000316\n",
      "Iteration 68180, Loss: 0.000001400\n",
      "Iteration 68190, Loss: 0.000000946\n",
      "Iteration 68200, Loss: 0.000000376\n",
      "Iteration 68210, Loss: 0.000000389\n",
      "Iteration 68220, Loss: 0.000000346\n",
      "Iteration 68230, Loss: 0.000000644\n",
      "Iteration 68240, Loss: 0.000000621\n",
      "Iteration 68250, Loss: 0.000000396\n",
      "Iteration 68260, Loss: 0.000000302\n",
      "Iteration 68270, Loss: 0.000000311\n",
      "Iteration 68280, Loss: 0.000000312\n",
      "Iteration 68290, Loss: 0.000000350\n",
      "Iteration 68300, Loss: 0.000001016\n",
      "Iteration 68310, Loss: 0.000000556\n",
      "Iteration 68320, Loss: 0.000000393\n",
      "Iteration 68330, Loss: 0.000000394\n",
      "Iteration 68340, Loss: 0.000000312\n",
      "Iteration 68350, Loss: 0.000000301\n",
      "Iteration 68360, Loss: 0.000000300\n",
      "Iteration 68370, Loss: 0.000000380\n",
      "Iteration 68380, Loss: 0.000001004\n",
      "Iteration 68390, Loss: 0.000000495\n",
      "Iteration 68400, Loss: 0.000000389\n",
      "Iteration 68410, Loss: 0.000000320\n",
      "Iteration 68420, Loss: 0.000000297\n",
      "Iteration 68430, Loss: 0.000000304\n",
      "Iteration 68440, Loss: 0.000000787\n",
      "Iteration 68450, Loss: 0.000000956\n",
      "Iteration 68460, Loss: 0.000000469\n",
      "Iteration 68470, Loss: 0.000000368\n",
      "Iteration 68480, Loss: 0.000000330\n",
      "Iteration 68490, Loss: 0.000000304\n",
      "Iteration 68500, Loss: 0.000000336\n",
      "Iteration 68510, Loss: 0.000001007\n",
      "Iteration 68520, Loss: 0.000000470\n",
      "Iteration 68530, Loss: 0.000000315\n",
      "Iteration 68540, Loss: 0.000000298\n",
      "Iteration 68550, Loss: 0.000000294\n",
      "Iteration 68560, Loss: 0.000000286\n",
      "Iteration 68570, Loss: 0.000000286\n",
      "Iteration 68580, Loss: 0.000000411\n",
      "Iteration 68590, Loss: 0.000003144\n",
      "Iteration 68600, Loss: 0.000000622\n",
      "Iteration 68610, Loss: 0.000000545\n",
      "Iteration 68620, Loss: 0.000000306\n",
      "Iteration 68630, Loss: 0.000000321\n",
      "Iteration 68640, Loss: 0.000000289\n",
      "Iteration 68650, Loss: 0.000000285\n",
      "Iteration 68660, Loss: 0.000000287\n",
      "Iteration 68670, Loss: 0.000000375\n",
      "Iteration 68680, Loss: 0.000001679\n",
      "Iteration 68690, Loss: 0.000000597\n",
      "Iteration 68700, Loss: 0.000000351\n",
      "Iteration 68710, Loss: 0.000000329\n",
      "Iteration 68720, Loss: 0.000000290\n",
      "Iteration 68730, Loss: 0.000000288\n",
      "Iteration 68740, Loss: 0.000000325\n",
      "Iteration 68750, Loss: 0.000001254\n",
      "Iteration 68760, Loss: 0.000000387\n",
      "Iteration 68770, Loss: 0.000000360\n",
      "Iteration 68780, Loss: 0.000000306\n",
      "Iteration 68790, Loss: 0.000000288\n",
      "Iteration 68800, Loss: 0.000000287\n",
      "Iteration 68810, Loss: 0.000000292\n",
      "Iteration 68820, Loss: 0.000000436\n",
      "Iteration 68830, Loss: 0.000000404\n",
      "Iteration 68840, Loss: 0.000000317\n",
      "Iteration 68850, Loss: 0.000000340\n",
      "Iteration 68860, Loss: 0.000001450\n",
      "Iteration 68870, Loss: 0.000000422\n",
      "Iteration 68880, Loss: 0.000000479\n",
      "Iteration 68890, Loss: 0.000000401\n",
      "Iteration 68900, Loss: 0.000000321\n",
      "Iteration 68910, Loss: 0.000000306\n",
      "Iteration 68920, Loss: 0.000000570\n",
      "Iteration 68930, Loss: 0.000000820\n",
      "Iteration 68940, Loss: 0.000000369\n",
      "Iteration 68950, Loss: 0.000000350\n",
      "Iteration 68960, Loss: 0.000000304\n",
      "Iteration 68970, Loss: 0.000000287\n",
      "Iteration 68980, Loss: 0.000000297\n",
      "Iteration 68990, Loss: 0.000000608\n",
      "Iteration 69000, Loss: 0.000000393\n",
      "Iteration 69010, Loss: 0.000000760\n",
      "Iteration 69020, Loss: 0.000000465\n",
      "Iteration 69030, Loss: 0.000000399\n",
      "Iteration 69040, Loss: 0.000000305\n",
      "Iteration 69050, Loss: 0.000000308\n",
      "Iteration 69060, Loss: 0.000000429\n",
      "Iteration 69070, Loss: 0.000000722\n",
      "Iteration 69080, Loss: 0.000001401\n",
      "Iteration 69090, Loss: 0.000000465\n",
      "Iteration 69100, Loss: 0.000000356\n",
      "Iteration 69110, Loss: 0.000000338\n",
      "Iteration 69120, Loss: 0.000000319\n",
      "Iteration 69130, Loss: 0.000000293\n",
      "Iteration 69140, Loss: 0.000000291\n",
      "Iteration 69150, Loss: 0.000000303\n",
      "Iteration 69160, Loss: 0.000000521\n",
      "Iteration 69170, Loss: 0.000001918\n",
      "Iteration 69180, Loss: 0.000000640\n",
      "Iteration 69190, Loss: 0.000000307\n",
      "Iteration 69200, Loss: 0.000000325\n",
      "Iteration 69210, Loss: 0.000000299\n",
      "Iteration 69220, Loss: 0.000000286\n",
      "Iteration 69230, Loss: 0.000000287\n",
      "Iteration 69240, Loss: 0.000000382\n",
      "Iteration 69250, Loss: 0.000001234\n",
      "Iteration 69260, Loss: 0.000001227\n",
      "Iteration 69270, Loss: 0.000000425\n",
      "Iteration 69280, Loss: 0.000000474\n",
      "Iteration 69290, Loss: 0.000000343\n",
      "Iteration 69300, Loss: 0.000000300\n",
      "Iteration 69310, Loss: 0.000000293\n",
      "Iteration 69320, Loss: 0.000000294\n",
      "Iteration 69330, Loss: 0.000000309\n",
      "Iteration 69340, Loss: 0.000000565\n",
      "Iteration 69350, Loss: 0.000001245\n",
      "Iteration 69360, Loss: 0.000000621\n",
      "Iteration 69370, Loss: 0.000000400\n",
      "Iteration 69380, Loss: 0.000000312\n",
      "Iteration 69390, Loss: 0.000000282\n",
      "Iteration 69400, Loss: 0.000000293\n",
      "Iteration 69410, Loss: 0.000000500\n",
      "Iteration 69420, Loss: 0.000001126\n",
      "Iteration 69430, Loss: 0.000000417\n",
      "Iteration 69440, Loss: 0.000000404\n",
      "Iteration 69450, Loss: 0.000000299\n",
      "Iteration 69460, Loss: 0.000000314\n",
      "Iteration 69470, Loss: 0.000000644\n",
      "Iteration 69480, Loss: 0.000001051\n",
      "Iteration 69490, Loss: 0.000000621\n",
      "Iteration 69500, Loss: 0.000000511\n",
      "Iteration 69510, Loss: 0.000000395\n",
      "Iteration 69520, Loss: 0.000000305\n",
      "Iteration 69530, Loss: 0.000000288\n",
      "Iteration 69540, Loss: 0.000000292\n",
      "Iteration 69550, Loss: 0.000000320\n",
      "Iteration 69560, Loss: 0.000000382\n",
      "Iteration 69570, Loss: 0.000000898\n",
      "Iteration 69580, Loss: 0.000000391\n",
      "Iteration 69590, Loss: 0.000000342\n",
      "Iteration 69600, Loss: 0.000000587\n",
      "Iteration 69610, Loss: 0.000001146\n",
      "Iteration 69620, Loss: 0.000000563\n",
      "Iteration 69630, Loss: 0.000000334\n",
      "Iteration 69640, Loss: 0.000000286\n",
      "Iteration 69650, Loss: 0.000000308\n",
      "Iteration 69660, Loss: 0.000000346\n",
      "Iteration 69670, Loss: 0.000000410\n",
      "Iteration 69680, Loss: 0.000000662\n",
      "Iteration 69690, Loss: 0.000000357\n",
      "Iteration 69700, Loss: 0.000000788\n",
      "Iteration 69710, Loss: 0.000000758\n",
      "Iteration 69720, Loss: 0.000000430\n",
      "Iteration 69730, Loss: 0.000000345\n",
      "Iteration 69740, Loss: 0.000000309\n",
      "Iteration 69750, Loss: 0.000000296\n",
      "Iteration 69760, Loss: 0.000000293\n",
      "Iteration 69770, Loss: 0.000000372\n",
      "Iteration 69780, Loss: 0.000000414\n",
      "Iteration 69790, Loss: 0.000000800\n",
      "Iteration 69800, Loss: 0.000000458\n",
      "Iteration 69810, Loss: 0.000000463\n",
      "Iteration 69820, Loss: 0.000000875\n",
      "Iteration 69830, Loss: 0.000000460\n",
      "Iteration 69840, Loss: 0.000000469\n",
      "Iteration 69850, Loss: 0.000000342\n",
      "Iteration 69860, Loss: 0.000000296\n",
      "Iteration 69870, Loss: 0.000000304\n",
      "Iteration 69880, Loss: 0.000000306\n",
      "Iteration 69890, Loss: 0.000000494\n",
      "Iteration 69900, Loss: 0.000001285\n",
      "Iteration 69910, Loss: 0.000000630\n",
      "Iteration 69920, Loss: 0.000000428\n",
      "Iteration 69930, Loss: 0.000000370\n",
      "Iteration 69940, Loss: 0.000000349\n",
      "Iteration 69950, Loss: 0.000000305\n",
      "Iteration 69960, Loss: 0.000000291\n",
      "Iteration 69970, Loss: 0.000000522\n",
      "Iteration 69980, Loss: 0.000002529\n",
      "Iteration 69990, Loss: 0.000000523\n",
      "Iteration 70000, Loss: 0.000000621\n",
      "Iteration 70010, Loss: 0.000000373\n",
      "Iteration 70020, Loss: 0.000000326\n",
      "Iteration 70030, Loss: 0.000000297\n",
      "Iteration 70040, Loss: 0.000000284\n",
      "Iteration 70050, Loss: 0.000000284\n",
      "Iteration 70060, Loss: 0.000000282\n",
      "Iteration 70070, Loss: 0.000000289\n",
      "Iteration 70080, Loss: 0.000000481\n",
      "Iteration 70090, Loss: 0.000001241\n",
      "Iteration 70100, Loss: 0.000000448\n",
      "Iteration 70110, Loss: 0.000000342\n",
      "Iteration 70120, Loss: 0.000000319\n",
      "Iteration 70130, Loss: 0.000000294\n",
      "Iteration 70140, Loss: 0.000000288\n",
      "Iteration 70150, Loss: 0.000000281\n",
      "Iteration 70160, Loss: 0.000000281\n",
      "Iteration 70170, Loss: 0.000000284\n",
      "Iteration 70180, Loss: 0.000000498\n",
      "Iteration 70190, Loss: 0.000001840\n",
      "Iteration 70200, Loss: 0.000000664\n",
      "Iteration 70210, Loss: 0.000000338\n",
      "Iteration 70220, Loss: 0.000000324\n",
      "Iteration 70230, Loss: 0.000000299\n",
      "Iteration 70240, Loss: 0.000000285\n",
      "Iteration 70250, Loss: 0.000000281\n",
      "Iteration 70260, Loss: 0.000000285\n",
      "Iteration 70270, Loss: 0.000000822\n",
      "Iteration 70280, Loss: 0.000000939\n",
      "Iteration 70290, Loss: 0.000000411\n",
      "Iteration 70300, Loss: 0.000000362\n",
      "Iteration 70310, Loss: 0.000000312\n",
      "Iteration 70320, Loss: 0.000000289\n",
      "Iteration 70330, Loss: 0.000000289\n",
      "Iteration 70340, Loss: 0.000000382\n",
      "Iteration 70350, Loss: 0.000002219\n",
      "Iteration 70360, Loss: 0.000001007\n",
      "Iteration 70370, Loss: 0.000000533\n",
      "Iteration 70380, Loss: 0.000000303\n",
      "Iteration 70390, Loss: 0.000000282\n",
      "Iteration 70400, Loss: 0.000000283\n",
      "Iteration 70410, Loss: 0.000000280\n",
      "Iteration 70420, Loss: 0.000000280\n",
      "Iteration 70430, Loss: 0.000000284\n",
      "Iteration 70440, Loss: 0.000000336\n",
      "Iteration 70450, Loss: 0.000000533\n",
      "Iteration 70460, Loss: 0.000000500\n",
      "Iteration 70470, Loss: 0.000000475\n",
      "Iteration 70480, Loss: 0.000000726\n",
      "Iteration 70490, Loss: 0.000000430\n",
      "Iteration 70500, Loss: 0.000000354\n",
      "Iteration 70510, Loss: 0.000000321\n",
      "Iteration 70520, Loss: 0.000000284\n",
      "Iteration 70530, Loss: 0.000000280\n",
      "Iteration 70540, Loss: 0.000000281\n",
      "Iteration 70550, Loss: 0.000000315\n",
      "Iteration 70560, Loss: 0.000001578\n",
      "Iteration 70570, Loss: 0.000001420\n",
      "Iteration 70580, Loss: 0.000000713\n",
      "Iteration 70590, Loss: 0.000000375\n",
      "Iteration 70600, Loss: 0.000000317\n",
      "Iteration 70610, Loss: 0.000000300\n",
      "Iteration 70620, Loss: 0.000000288\n",
      "Iteration 70630, Loss: 0.000000280\n",
      "Iteration 70640, Loss: 0.000000280\n",
      "Iteration 70650, Loss: 0.000000295\n",
      "Iteration 70660, Loss: 0.000000996\n",
      "Iteration 70670, Loss: 0.000000546\n",
      "Iteration 70680, Loss: 0.000000475\n",
      "Iteration 70690, Loss: 0.000000312\n",
      "Iteration 70700, Loss: 0.000000292\n",
      "Iteration 70710, Loss: 0.000000341\n",
      "Iteration 70720, Loss: 0.000001116\n",
      "Iteration 70730, Loss: 0.000000286\n",
      "Iteration 70740, Loss: 0.000000283\n",
      "Iteration 70750, Loss: 0.000000283\n",
      "Iteration 70760, Loss: 0.000000289\n",
      "Iteration 70770, Loss: 0.000000311\n",
      "Iteration 70780, Loss: 0.000000385\n",
      "Iteration 70790, Loss: 0.000000306\n",
      "Iteration 70800, Loss: 0.000000291\n",
      "Iteration 70810, Loss: 0.000000284\n",
      "Iteration 70820, Loss: 0.000000340\n",
      "Iteration 70830, Loss: 0.000002275\n",
      "Iteration 70840, Loss: 0.000001142\n",
      "Iteration 70850, Loss: 0.000000481\n",
      "Iteration 70860, Loss: 0.000000312\n",
      "Iteration 70870, Loss: 0.000000313\n",
      "Iteration 70880, Loss: 0.000000316\n",
      "Iteration 70890, Loss: 0.000000773\n",
      "Iteration 70900, Loss: 0.000000336\n",
      "Iteration 70910, Loss: 0.000000306\n",
      "Iteration 70920, Loss: 0.000000296\n",
      "Iteration 70930, Loss: 0.000000289\n",
      "Iteration 70940, Loss: 0.000000297\n",
      "Iteration 70950, Loss: 0.000000692\n",
      "Iteration 70960, Loss: 0.000000303\n",
      "Iteration 70970, Loss: 0.000000353\n",
      "Iteration 70980, Loss: 0.000000344\n",
      "Iteration 70990, Loss: 0.000000298\n",
      "Iteration 71000, Loss: 0.000000310\n",
      "Iteration 71010, Loss: 0.000000517\n",
      "Iteration 71020, Loss: 0.000002921\n",
      "Iteration 71030, Loss: 0.000001310\n",
      "Iteration 71040, Loss: 0.000000403\n",
      "Iteration 71050, Loss: 0.000000408\n",
      "Iteration 71060, Loss: 0.000000323\n",
      "Iteration 71070, Loss: 0.000000286\n",
      "Iteration 71080, Loss: 0.000000285\n",
      "Iteration 71090, Loss: 0.000000282\n",
      "Iteration 71100, Loss: 0.000000300\n",
      "Iteration 71110, Loss: 0.000000901\n",
      "Iteration 71120, Loss: 0.000000412\n",
      "Iteration 71130, Loss: 0.000000434\n",
      "Iteration 71140, Loss: 0.000000335\n",
      "Iteration 71150, Loss: 0.000000289\n",
      "Iteration 71160, Loss: 0.000000282\n",
      "Iteration 71170, Loss: 0.000000284\n",
      "Iteration 71180, Loss: 0.000000400\n",
      "Iteration 71190, Loss: 0.000000666\n",
      "Iteration 71200, Loss: 0.000000564\n",
      "Iteration 71210, Loss: 0.000000335\n",
      "Iteration 71220, Loss: 0.000000347\n",
      "Iteration 71230, Loss: 0.000000308\n",
      "Iteration 71240, Loss: 0.000000336\n",
      "Iteration 71250, Loss: 0.000000889\n",
      "Iteration 71260, Loss: 0.000000564\n",
      "Iteration 71270, Loss: 0.000000416\n",
      "Iteration 71280, Loss: 0.000000321\n",
      "Iteration 71290, Loss: 0.000000297\n",
      "Iteration 71300, Loss: 0.000000286\n",
      "Iteration 71310, Loss: 0.000000290\n",
      "Iteration 71320, Loss: 0.000000712\n",
      "Iteration 71330, Loss: 0.000000803\n",
      "Iteration 71340, Loss: 0.000000613\n",
      "Iteration 71350, Loss: 0.000000317\n",
      "Iteration 71360, Loss: 0.000000343\n",
      "Iteration 71370, Loss: 0.000000281\n",
      "Iteration 71380, Loss: 0.000000293\n",
      "Iteration 71390, Loss: 0.000000407\n",
      "Iteration 71400, Loss: 0.000000618\n",
      "Iteration 71410, Loss: 0.000000873\n",
      "Iteration 71420, Loss: 0.000000532\n",
      "Iteration 71430, Loss: 0.000000466\n",
      "Iteration 71440, Loss: 0.000000323\n",
      "Iteration 71450, Loss: 0.000000283\n",
      "Iteration 71460, Loss: 0.000000288\n",
      "Iteration 71470, Loss: 0.000000298\n",
      "Iteration 71480, Loss: 0.000000377\n",
      "Iteration 71490, Loss: 0.000001170\n",
      "Iteration 71500, Loss: 0.000000320\n",
      "Iteration 71510, Loss: 0.000000315\n",
      "Iteration 71520, Loss: 0.000000325\n",
      "Iteration 71530, Loss: 0.000000320\n",
      "Iteration 71540, Loss: 0.000000370\n",
      "Iteration 71550, Loss: 0.000000828\n",
      "Iteration 71560, Loss: 0.000000431\n",
      "Iteration 71570, Loss: 0.000000340\n",
      "Iteration 71580, Loss: 0.000000317\n",
      "Iteration 71590, Loss: 0.000000600\n",
      "Iteration 71600, Loss: 0.000001326\n",
      "Iteration 71610, Loss: 0.000000598\n",
      "Iteration 71620, Loss: 0.000000584\n",
      "Iteration 71630, Loss: 0.000000518\n",
      "Iteration 71640, Loss: 0.000000374\n",
      "Iteration 71650, Loss: 0.000000290\n",
      "Iteration 71660, Loss: 0.000000290\n",
      "Iteration 71670, Loss: 0.000000292\n",
      "Iteration 71680, Loss: 0.000000498\n",
      "Iteration 71690, Loss: 0.000000478\n",
      "Iteration 71700, Loss: 0.000000725\n",
      "Iteration 71710, Loss: 0.000000538\n",
      "Iteration 71720, Loss: 0.000000404\n",
      "Iteration 71730, Loss: 0.000000425\n",
      "Iteration 71740, Loss: 0.000000957\n",
      "Iteration 71750, Loss: 0.000000504\n",
      "Iteration 71760, Loss: 0.000000434\n",
      "Iteration 71770, Loss: 0.000000308\n",
      "Iteration 71780, Loss: 0.000000310\n",
      "Iteration 71790, Loss: 0.000000283\n",
      "Iteration 71800, Loss: 0.000000277\n",
      "Iteration 71810, Loss: 0.000000285\n",
      "Iteration 71820, Loss: 0.000000445\n",
      "Iteration 71830, Loss: 0.000002523\n",
      "Iteration 71840, Loss: 0.000000600\n",
      "Iteration 71850, Loss: 0.000000504\n",
      "Iteration 71860, Loss: 0.000000302\n",
      "Iteration 71870, Loss: 0.000000317\n",
      "Iteration 71880, Loss: 0.000000280\n",
      "Iteration 71890, Loss: 0.000000282\n",
      "Iteration 71900, Loss: 0.000000285\n",
      "Iteration 71910, Loss: 0.000000427\n",
      "Iteration 71920, Loss: 0.000000993\n",
      "Iteration 71930, Loss: 0.000000671\n",
      "Iteration 71940, Loss: 0.000000892\n",
      "Iteration 71950, Loss: 0.000000390\n",
      "Iteration 71960, Loss: 0.000000362\n",
      "Iteration 71970, Loss: 0.000000302\n",
      "Iteration 71980, Loss: 0.000000282\n",
      "Iteration 71990, Loss: 0.000000278\n",
      "Iteration 72000, Loss: 0.000000281\n",
      "Iteration 72010, Loss: 0.000000588\n",
      "Iteration 72020, Loss: 0.000001668\n",
      "Iteration 72030, Loss: 0.000000588\n",
      "Iteration 72040, Loss: 0.000000444\n",
      "Iteration 72050, Loss: 0.000000354\n",
      "Iteration 72060, Loss: 0.000000286\n",
      "Iteration 72070, Loss: 0.000000288\n",
      "Iteration 72080, Loss: 0.000000278\n",
      "Iteration 72090, Loss: 0.000000277\n",
      "Iteration 72100, Loss: 0.000000277\n",
      "Iteration 72110, Loss: 0.000000277\n",
      "Iteration 72120, Loss: 0.000000326\n",
      "Iteration 72130, Loss: 0.000001906\n",
      "Iteration 72140, Loss: 0.000000688\n",
      "Iteration 72150, Loss: 0.000000451\n",
      "Iteration 72160, Loss: 0.000000293\n",
      "Iteration 72170, Loss: 0.000000297\n",
      "Iteration 72180, Loss: 0.000000280\n",
      "Iteration 72190, Loss: 0.000000278\n",
      "Iteration 72200, Loss: 0.000000277\n",
      "Iteration 72210, Loss: 0.000000280\n",
      "Iteration 72220, Loss: 0.000000388\n",
      "Iteration 72230, Loss: 0.000002205\n",
      "Iteration 72240, Loss: 0.000000783\n",
      "Iteration 72250, Loss: 0.000000383\n",
      "Iteration 72260, Loss: 0.000000330\n",
      "Iteration 72270, Loss: 0.000000297\n",
      "Iteration 72280, Loss: 0.000000319\n",
      "Iteration 72290, Loss: 0.000000537\n",
      "Iteration 72300, Loss: 0.000000849\n",
      "Iteration 72310, Loss: 0.000000451\n",
      "Iteration 72320, Loss: 0.000000293\n",
      "Iteration 72330, Loss: 0.000000295\n",
      "Iteration 72340, Loss: 0.000000288\n",
      "Iteration 72350, Loss: 0.000000297\n",
      "Iteration 72360, Loss: 0.000000421\n",
      "Iteration 72370, Loss: 0.000001743\n",
      "Iteration 72380, Loss: 0.000000677\n",
      "Iteration 72390, Loss: 0.000000428\n",
      "Iteration 72400, Loss: 0.000000325\n",
      "Iteration 72410, Loss: 0.000000289\n",
      "Iteration 72420, Loss: 0.000000281\n",
      "Iteration 72430, Loss: 0.000000301\n",
      "Iteration 72440, Loss: 0.000000898\n",
      "Iteration 72450, Loss: 0.000000469\n",
      "Iteration 72460, Loss: 0.000000427\n",
      "Iteration 72470, Loss: 0.000000390\n",
      "Iteration 72480, Loss: 0.000000312\n",
      "Iteration 72490, Loss: 0.000000282\n",
      "Iteration 72500, Loss: 0.000000282\n",
      "Iteration 72510, Loss: 0.000000279\n",
      "Iteration 72520, Loss: 0.000000307\n",
      "Iteration 72530, Loss: 0.000000587\n",
      "Iteration 72540, Loss: 0.000000607\n",
      "Iteration 72550, Loss: 0.000001244\n",
      "Iteration 72560, Loss: 0.000000367\n",
      "Iteration 72570, Loss: 0.000000358\n",
      "Iteration 72580, Loss: 0.000000325\n",
      "Iteration 72590, Loss: 0.000000299\n",
      "Iteration 72600, Loss: 0.000000279\n",
      "Iteration 72610, Loss: 0.000000281\n",
      "Iteration 72620, Loss: 0.000000280\n",
      "Iteration 72630, Loss: 0.000000290\n",
      "Iteration 72640, Loss: 0.000000506\n",
      "Iteration 72650, Loss: 0.000001515\n",
      "Iteration 72660, Loss: 0.000000682\n",
      "Iteration 72670, Loss: 0.000000421\n",
      "Iteration 72680, Loss: 0.000000333\n",
      "Iteration 72690, Loss: 0.000000326\n",
      "Iteration 72700, Loss: 0.000000671\n",
      "Iteration 72710, Loss: 0.000000572\n",
      "Iteration 72720, Loss: 0.000000418\n",
      "Iteration 72730, Loss: 0.000000333\n",
      "Iteration 72740, Loss: 0.000000421\n",
      "Iteration 72750, Loss: 0.000000400\n",
      "Iteration 72760, Loss: 0.000000330\n",
      "Iteration 72770, Loss: 0.000000500\n",
      "Iteration 72780, Loss: 0.000001145\n",
      "Iteration 72790, Loss: 0.000000451\n",
      "Iteration 72800, Loss: 0.000000344\n",
      "Iteration 72810, Loss: 0.000000309\n",
      "Iteration 72820, Loss: 0.000000283\n",
      "Iteration 72830, Loss: 0.000000291\n",
      "Iteration 72840, Loss: 0.000000560\n",
      "Iteration 72850, Loss: 0.000001009\n",
      "Iteration 72860, Loss: 0.000000515\n",
      "Iteration 72870, Loss: 0.000000399\n",
      "Iteration 72880, Loss: 0.000000322\n",
      "Iteration 72890, Loss: 0.000000306\n",
      "Iteration 72900, Loss: 0.000000295\n",
      "Iteration 72910, Loss: 0.000000382\n",
      "Iteration 72920, Loss: 0.000001473\n",
      "Iteration 72930, Loss: 0.000000408\n",
      "Iteration 72940, Loss: 0.000000337\n",
      "Iteration 72950, Loss: 0.000000306\n",
      "Iteration 72960, Loss: 0.000000299\n",
      "Iteration 72970, Loss: 0.000000389\n",
      "Iteration 72980, Loss: 0.000000685\n",
      "Iteration 72990, Loss: 0.000000309\n",
      "Iteration 73000, Loss: 0.000000302\n",
      "Iteration 73010, Loss: 0.000000311\n",
      "Iteration 73020, Loss: 0.000000425\n",
      "Iteration 73030, Loss: 0.000001485\n",
      "Iteration 73040, Loss: 0.000000533\n",
      "Iteration 73050, Loss: 0.000000354\n",
      "Iteration 73060, Loss: 0.000000292\n",
      "Iteration 73070, Loss: 0.000000280\n",
      "Iteration 73080, Loss: 0.000000327\n",
      "Iteration 73090, Loss: 0.000001377\n",
      "Iteration 73100, Loss: 0.000000761\n",
      "Iteration 73110, Loss: 0.000000509\n",
      "Iteration 73120, Loss: 0.000000296\n",
      "Iteration 73130, Loss: 0.000000290\n",
      "Iteration 73140, Loss: 0.000000312\n",
      "Iteration 73150, Loss: 0.000000345\n",
      "Iteration 73160, Loss: 0.000000564\n",
      "Iteration 73170, Loss: 0.000001542\n",
      "Iteration 73180, Loss: 0.000000802\n",
      "Iteration 73190, Loss: 0.000000522\n",
      "Iteration 73200, Loss: 0.000000351\n",
      "Iteration 73210, Loss: 0.000000284\n",
      "Iteration 73220, Loss: 0.000000285\n",
      "Iteration 73230, Loss: 0.000000292\n",
      "Iteration 73240, Loss: 0.000000505\n",
      "Iteration 73250, Loss: 0.000000652\n",
      "Iteration 73260, Loss: 0.000000324\n",
      "Iteration 73270, Loss: 0.000000337\n",
      "Iteration 73280, Loss: 0.000000298\n",
      "Iteration 73290, Loss: 0.000000336\n",
      "Iteration 73300, Loss: 0.000001152\n",
      "Iteration 73310, Loss: 0.000000301\n",
      "Iteration 73320, Loss: 0.000000291\n",
      "Iteration 73330, Loss: 0.000000289\n",
      "Iteration 73340, Loss: 0.000000284\n",
      "Iteration 73350, Loss: 0.000000296\n",
      "Iteration 73360, Loss: 0.000000567\n",
      "Iteration 73370, Loss: 0.000000510\n",
      "Iteration 73380, Loss: 0.000000337\n",
      "Iteration 73390, Loss: 0.000000325\n",
      "Iteration 73400, Loss: 0.000000590\n",
      "Iteration 73410, Loss: 0.000000662\n",
      "Iteration 73420, Loss: 0.000000528\n",
      "Iteration 73430, Loss: 0.000000394\n",
      "Iteration 73440, Loss: 0.000000305\n",
      "Iteration 73450, Loss: 0.000000291\n",
      "Iteration 73460, Loss: 0.000000313\n",
      "Iteration 73470, Loss: 0.000000473\n",
      "Iteration 73480, Loss: 0.000001057\n",
      "Iteration 73490, Loss: 0.000000344\n",
      "Iteration 73500, Loss: 0.000000303\n",
      "Iteration 73510, Loss: 0.000000373\n",
      "Iteration 73520, Loss: 0.000000826\n",
      "Iteration 73530, Loss: 0.000000390\n",
      "Iteration 73540, Loss: 0.000000397\n",
      "Iteration 73550, Loss: 0.000000475\n",
      "Iteration 73560, Loss: 0.000000517\n",
      "Iteration 73570, Loss: 0.000000653\n",
      "Iteration 73580, Loss: 0.000000410\n",
      "Iteration 73590, Loss: 0.000000346\n",
      "Iteration 73600, Loss: 0.000000426\n",
      "Iteration 73610, Loss: 0.000000428\n",
      "Iteration 73620, Loss: 0.000000396\n",
      "Iteration 73630, Loss: 0.000000458\n",
      "Iteration 73640, Loss: 0.000000682\n",
      "Iteration 73650, Loss: 0.000000555\n",
      "Iteration 73660, Loss: 0.000001048\n",
      "Iteration 73670, Loss: 0.000000473\n",
      "Iteration 73680, Loss: 0.000000455\n",
      "Iteration 73690, Loss: 0.000000299\n",
      "Iteration 73700, Loss: 0.000000308\n",
      "Iteration 73710, Loss: 0.000000338\n",
      "Iteration 73720, Loss: 0.000000580\n",
      "Iteration 73730, Loss: 0.000000766\n",
      "Iteration 73740, Loss: 0.000000918\n",
      "Iteration 73750, Loss: 0.000000458\n",
      "Iteration 73760, Loss: 0.000000393\n",
      "Iteration 73770, Loss: 0.000000284\n",
      "Iteration 73780, Loss: 0.000000303\n",
      "Iteration 73790, Loss: 0.000000302\n",
      "Iteration 73800, Loss: 0.000000350\n",
      "Iteration 73810, Loss: 0.000000766\n",
      "Iteration 73820, Loss: 0.000000860\n",
      "Iteration 73830, Loss: 0.000000572\n",
      "Iteration 73840, Loss: 0.000000423\n",
      "Iteration 73850, Loss: 0.000000323\n",
      "Iteration 73860, Loss: 0.000000308\n",
      "Iteration 73870, Loss: 0.000000575\n",
      "Iteration 73880, Loss: 0.000000443\n",
      "Iteration 73890, Loss: 0.000000334\n",
      "Iteration 73900, Loss: 0.000000289\n",
      "Iteration 73910, Loss: 0.000000293\n",
      "Iteration 73920, Loss: 0.000000390\n",
      "Iteration 73930, Loss: 0.000001267\n",
      "Iteration 73940, Loss: 0.000000843\n",
      "Iteration 73950, Loss: 0.000000428\n",
      "Iteration 73960, Loss: 0.000000389\n",
      "Iteration 73970, Loss: 0.000000311\n",
      "Iteration 73980, Loss: 0.000000280\n",
      "Iteration 73990, Loss: 0.000000281\n",
      "Iteration 74000, Loss: 0.000000307\n",
      "Iteration 74010, Loss: 0.000000393\n",
      "Iteration 74020, Loss: 0.000000972\n",
      "Iteration 74030, Loss: 0.000001038\n",
      "Iteration 74040, Loss: 0.000000516\n",
      "Iteration 74050, Loss: 0.000000442\n",
      "Iteration 74060, Loss: 0.000000330\n",
      "Iteration 74070, Loss: 0.000000284\n",
      "Iteration 74080, Loss: 0.000000286\n",
      "Iteration 74090, Loss: 0.000000274\n",
      "Iteration 74100, Loss: 0.000000273\n",
      "Iteration 74110, Loss: 0.000000277\n",
      "Iteration 74120, Loss: 0.000000468\n",
      "Iteration 74130, Loss: 0.000002633\n",
      "Iteration 74140, Loss: 0.000000443\n",
      "Iteration 74150, Loss: 0.000000473\n",
      "Iteration 74160, Loss: 0.000000392\n",
      "Iteration 74170, Loss: 0.000000294\n",
      "Iteration 74180, Loss: 0.000000316\n",
      "Iteration 74190, Loss: 0.000000548\n",
      "Iteration 74200, Loss: 0.000000344\n",
      "Iteration 74210, Loss: 0.000000330\n",
      "Iteration 74220, Loss: 0.000000297\n",
      "Iteration 74230, Loss: 0.000000345\n",
      "Iteration 74240, Loss: 0.000000343\n",
      "Iteration 74250, Loss: 0.000000530\n",
      "Iteration 74260, Loss: 0.000000675\n",
      "Iteration 74270, Loss: 0.000000328\n",
      "Iteration 74280, Loss: 0.000000333\n",
      "Iteration 74290, Loss: 0.000000285\n",
      "Iteration 74300, Loss: 0.000000281\n",
      "Iteration 74310, Loss: 0.000000289\n",
      "Iteration 74320, Loss: 0.000000387\n",
      "Iteration 74330, Loss: 0.000001654\n",
      "Iteration 74340, Loss: 0.000000781\n",
      "Iteration 74350, Loss: 0.000000689\n",
      "Iteration 74360, Loss: 0.000000296\n",
      "Iteration 74370, Loss: 0.000000311\n",
      "Iteration 74380, Loss: 0.000000283\n",
      "Iteration 74390, Loss: 0.000000277\n",
      "Iteration 74400, Loss: 0.000000274\n",
      "Iteration 74410, Loss: 0.000000280\n",
      "Iteration 74420, Loss: 0.000000601\n",
      "Iteration 74430, Loss: 0.000000487\n",
      "Iteration 74440, Loss: 0.000000559\n",
      "Iteration 74450, Loss: 0.000000299\n",
      "Iteration 74460, Loss: 0.000000317\n",
      "Iteration 74470, Loss: 0.000000351\n",
      "Iteration 74480, Loss: 0.000000584\n",
      "Iteration 74490, Loss: 0.000000588\n",
      "Iteration 74500, Loss: 0.000000343\n",
      "Iteration 74510, Loss: 0.000000360\n",
      "Iteration 74520, Loss: 0.000000933\n",
      "Iteration 74530, Loss: 0.000000363\n",
      "Iteration 74540, Loss: 0.000000328\n",
      "Iteration 74550, Loss: 0.000000302\n",
      "Iteration 74560, Loss: 0.000000288\n",
      "Iteration 74570, Loss: 0.000000628\n",
      "Iteration 74580, Loss: 0.000001336\n",
      "Iteration 74590, Loss: 0.000000476\n",
      "Iteration 74600, Loss: 0.000000497\n",
      "Iteration 74610, Loss: 0.000000342\n",
      "Iteration 74620, Loss: 0.000000290\n",
      "Iteration 74630, Loss: 0.000000277\n",
      "Iteration 74640, Loss: 0.000000275\n",
      "Iteration 74650, Loss: 0.000000273\n",
      "Iteration 74660, Loss: 0.000000278\n",
      "Iteration 74670, Loss: 0.000000400\n",
      "Iteration 74680, Loss: 0.000000750\n",
      "Iteration 74690, Loss: 0.000000364\n",
      "Iteration 74700, Loss: 0.000000686\n",
      "Iteration 74710, Loss: 0.000000418\n",
      "Iteration 74720, Loss: 0.000000338\n",
      "Iteration 74730, Loss: 0.000000306\n",
      "Iteration 74740, Loss: 0.000000280\n",
      "Iteration 74750, Loss: 0.000000276\n",
      "Iteration 74760, Loss: 0.000000331\n",
      "Iteration 74770, Loss: 0.000001794\n",
      "Iteration 74780, Loss: 0.000000738\n",
      "Iteration 74790, Loss: 0.000000583\n",
      "Iteration 74800, Loss: 0.000000312\n",
      "Iteration 74810, Loss: 0.000000274\n",
      "Iteration 74820, Loss: 0.000000285\n",
      "Iteration 74830, Loss: 0.000000413\n",
      "Iteration 74840, Loss: 0.000000691\n",
      "Iteration 74850, Loss: 0.000000868\n",
      "Iteration 74860, Loss: 0.000000341\n",
      "Iteration 74870, Loss: 0.000000321\n",
      "Iteration 74880, Loss: 0.000000295\n",
      "Iteration 74890, Loss: 0.000000281\n",
      "Iteration 74900, Loss: 0.000000275\n",
      "Iteration 74910, Loss: 0.000000275\n",
      "Iteration 74920, Loss: 0.000000346\n",
      "Iteration 74930, Loss: 0.000002151\n",
      "Iteration 74940, Loss: 0.000001080\n",
      "Iteration 74950, Loss: 0.000000546\n",
      "Iteration 74960, Loss: 0.000000288\n",
      "Iteration 74970, Loss: 0.000000301\n",
      "Iteration 74980, Loss: 0.000000293\n",
      "Iteration 74990, Loss: 0.000000319\n",
      "Iteration 75000, Loss: 0.000000721\n",
      "Iteration 75010, Loss: 0.000000330\n",
      "Iteration 75020, Loss: 0.000000308\n",
      "Iteration 75030, Loss: 0.000000301\n",
      "Iteration 75040, Loss: 0.000000292\n",
      "Iteration 75050, Loss: 0.000000334\n",
      "Iteration 75060, Loss: 0.000001013\n",
      "Iteration 75070, Loss: 0.000000690\n",
      "Iteration 75080, Loss: 0.000000443\n",
      "Iteration 75090, Loss: 0.000000363\n",
      "Iteration 75100, Loss: 0.000000307\n",
      "Iteration 75110, Loss: 0.000000285\n",
      "Iteration 75120, Loss: 0.000000273\n",
      "Iteration 75130, Loss: 0.000000278\n",
      "Iteration 75140, Loss: 0.000000352\n",
      "Iteration 75150, Loss: 0.000001469\n",
      "Iteration 75160, Loss: 0.000000889\n",
      "Iteration 75170, Loss: 0.000000544\n",
      "Iteration 75180, Loss: 0.000000316\n",
      "Iteration 75190, Loss: 0.000000343\n",
      "Iteration 75200, Loss: 0.000000355\n",
      "Iteration 75210, Loss: 0.000000430\n",
      "Iteration 75220, Loss: 0.000000671\n",
      "Iteration 75230, Loss: 0.000000359\n",
      "Iteration 75240, Loss: 0.000000400\n",
      "Iteration 75250, Loss: 0.000000499\n",
      "Iteration 75260, Loss: 0.000000387\n",
      "Iteration 75270, Loss: 0.000000357\n",
      "Iteration 75280, Loss: 0.000000838\n",
      "Iteration 75290, Loss: 0.000000377\n",
      "Iteration 75300, Loss: 0.000000438\n",
      "Iteration 75310, Loss: 0.000000314\n",
      "Iteration 75320, Loss: 0.000000431\n",
      "Iteration 75330, Loss: 0.000000892\n",
      "Iteration 75340, Loss: 0.000000456\n",
      "Iteration 75350, Loss: 0.000000375\n",
      "Iteration 75360, Loss: 0.000000489\n",
      "Iteration 75370, Loss: 0.000001027\n",
      "Iteration 75380, Loss: 0.000000479\n",
      "Iteration 75390, Loss: 0.000000320\n",
      "Iteration 75400, Loss: 0.000000325\n",
      "Iteration 75410, Loss: 0.000000317\n",
      "Iteration 75420, Loss: 0.000000370\n",
      "Iteration 75430, Loss: 0.000000894\n",
      "Iteration 75440, Loss: 0.000000402\n",
      "Iteration 75450, Loss: 0.000000425\n",
      "Iteration 75460, Loss: 0.000000321\n",
      "Iteration 75470, Loss: 0.000000302\n",
      "Iteration 75480, Loss: 0.000000388\n",
      "Iteration 75490, Loss: 0.000000380\n",
      "Iteration 75500, Loss: 0.000001092\n",
      "Iteration 75510, Loss: 0.000001849\n",
      "Iteration 75520, Loss: 0.000000677\n",
      "Iteration 75530, Loss: 0.000000384\n",
      "Iteration 75540, Loss: 0.000000299\n",
      "Iteration 75550, Loss: 0.000000286\n",
      "Iteration 75560, Loss: 0.000000278\n",
      "Iteration 75570, Loss: 0.000000272\n",
      "Iteration 75580, Loss: 0.000000274\n",
      "Iteration 75590, Loss: 0.000000292\n",
      "Iteration 75600, Loss: 0.000000605\n",
      "Iteration 75610, Loss: 0.000000319\n",
      "Iteration 75620, Loss: 0.000000827\n",
      "Iteration 75630, Loss: 0.000000562\n",
      "Iteration 75640, Loss: 0.000000449\n",
      "Iteration 75650, Loss: 0.000000367\n",
      "Iteration 75660, Loss: 0.000000306\n",
      "Iteration 75670, Loss: 0.000000277\n",
      "Iteration 75680, Loss: 0.000000273\n",
      "Iteration 75690, Loss: 0.000000272\n",
      "Iteration 75700, Loss: 0.000000332\n",
      "Iteration 75710, Loss: 0.000001501\n",
      "Iteration 75720, Loss: 0.000000680\n",
      "Iteration 75730, Loss: 0.000000654\n",
      "Iteration 75740, Loss: 0.000000328\n",
      "Iteration 75750, Loss: 0.000000305\n",
      "Iteration 75760, Loss: 0.000000351\n",
      "Iteration 75770, Loss: 0.000000496\n",
      "Iteration 75780, Loss: 0.000000733\n",
      "Iteration 75790, Loss: 0.000000281\n",
      "Iteration 75800, Loss: 0.000000401\n",
      "Iteration 75810, Loss: 0.000000307\n",
      "Iteration 75820, Loss: 0.000000420\n",
      "Iteration 75830, Loss: 0.000000585\n",
      "Iteration 75840, Loss: 0.000000417\n",
      "Iteration 75850, Loss: 0.000001289\n",
      "Iteration 75860, Loss: 0.000000390\n",
      "Iteration 75870, Loss: 0.000000331\n",
      "Iteration 75880, Loss: 0.000000315\n",
      "Iteration 75890, Loss: 0.000000291\n",
      "Iteration 75900, Loss: 0.000000277\n",
      "Iteration 75910, Loss: 0.000000272\n",
      "Iteration 75920, Loss: 0.000000277\n",
      "Iteration 75930, Loss: 0.000000500\n",
      "Iteration 75940, Loss: 0.000001644\n",
      "Iteration 75950, Loss: 0.000000399\n",
      "Iteration 75960, Loss: 0.000000388\n",
      "Iteration 75970, Loss: 0.000000343\n",
      "Iteration 75980, Loss: 0.000000282\n",
      "Iteration 75990, Loss: 0.000000279\n",
      "Iteration 76000, Loss: 0.000000283\n",
      "Iteration 76010, Loss: 0.000000479\n",
      "Iteration 76020, Loss: 0.000001298\n",
      "Iteration 76030, Loss: 0.000000505\n",
      "Iteration 76040, Loss: 0.000000315\n",
      "Iteration 76050, Loss: 0.000000293\n",
      "Iteration 76060, Loss: 0.000000274\n",
      "Iteration 76070, Loss: 0.000000270\n",
      "Iteration 76080, Loss: 0.000000270\n",
      "Iteration 76090, Loss: 0.000000277\n",
      "Iteration 76100, Loss: 0.000000383\n",
      "Iteration 76110, Loss: 0.000002403\n",
      "Iteration 76120, Loss: 0.000001617\n",
      "Iteration 76130, Loss: 0.000000479\n",
      "Iteration 76140, Loss: 0.000000465\n",
      "Iteration 76150, Loss: 0.000000299\n",
      "Iteration 76160, Loss: 0.000000283\n",
      "Iteration 76170, Loss: 0.000000273\n",
      "Iteration 76180, Loss: 0.000000271\n",
      "Iteration 76190, Loss: 0.000000269\n",
      "Iteration 76200, Loss: 0.000000268\n",
      "Iteration 76210, Loss: 0.000000268\n",
      "Iteration 76220, Loss: 0.000000275\n",
      "Iteration 76230, Loss: 0.000000608\n",
      "Iteration 76240, Loss: 0.000000855\n",
      "Iteration 76250, Loss: 0.000000489\n",
      "Iteration 76260, Loss: 0.000000338\n",
      "Iteration 76270, Loss: 0.000000301\n",
      "Iteration 76280, Loss: 0.000000285\n",
      "Iteration 76290, Loss: 0.000000274\n",
      "Iteration 76300, Loss: 0.000000275\n",
      "Iteration 76310, Loss: 0.000000558\n",
      "Iteration 76320, Loss: 0.000001156\n",
      "Iteration 76330, Loss: 0.000000563\n",
      "Iteration 76340, Loss: 0.000000342\n",
      "Iteration 76350, Loss: 0.000000334\n",
      "Iteration 76360, Loss: 0.000000275\n",
      "Iteration 76370, Loss: 0.000000275\n",
      "Iteration 76380, Loss: 0.000000275\n",
      "Iteration 76390, Loss: 0.000000310\n",
      "Iteration 76400, Loss: 0.000001110\n",
      "Iteration 76410, Loss: 0.000000326\n",
      "Iteration 76420, Loss: 0.000000331\n",
      "Iteration 76430, Loss: 0.000000337\n",
      "Iteration 76440, Loss: 0.000000306\n",
      "Iteration 76450, Loss: 0.000000283\n",
      "Iteration 76460, Loss: 0.000000274\n",
      "Iteration 76470, Loss: 0.000000293\n",
      "Iteration 76480, Loss: 0.000000439\n",
      "Iteration 76490, Loss: 0.000000695\n",
      "Iteration 76500, Loss: 0.000001048\n",
      "Iteration 76510, Loss: 0.000000638\n",
      "Iteration 76520, Loss: 0.000000407\n",
      "Iteration 76530, Loss: 0.000000288\n",
      "Iteration 76540, Loss: 0.000000284\n",
      "Iteration 76550, Loss: 0.000000276\n",
      "Iteration 76560, Loss: 0.000000270\n",
      "Iteration 76570, Loss: 0.000000268\n",
      "Iteration 76580, Loss: 0.000000268\n",
      "Iteration 76590, Loss: 0.000000268\n",
      "Iteration 76600, Loss: 0.000000276\n",
      "Iteration 76610, Loss: 0.000000657\n",
      "Iteration 76620, Loss: 0.000000934\n",
      "Iteration 76630, Loss: 0.000000532\n",
      "Iteration 76640, Loss: 0.000000460\n",
      "Iteration 76650, Loss: 0.000000312\n",
      "Iteration 76660, Loss: 0.000000277\n",
      "Iteration 76670, Loss: 0.000000279\n",
      "Iteration 76680, Loss: 0.000000291\n",
      "Iteration 76690, Loss: 0.000000411\n",
      "Iteration 76700, Loss: 0.000001087\n",
      "Iteration 76710, Loss: 0.000000322\n",
      "Iteration 76720, Loss: 0.000000301\n",
      "Iteration 76730, Loss: 0.000000324\n",
      "Iteration 76740, Loss: 0.000000273\n",
      "Iteration 76750, Loss: 0.000000298\n",
      "Iteration 76760, Loss: 0.000000552\n",
      "Iteration 76770, Loss: 0.000001001\n",
      "Iteration 76780, Loss: 0.000001062\n",
      "Iteration 76790, Loss: 0.000000485\n",
      "Iteration 76800, Loss: 0.000000369\n",
      "Iteration 76810, Loss: 0.000000308\n",
      "Iteration 76820, Loss: 0.000000277\n",
      "Iteration 76830, Loss: 0.000000272\n",
      "Iteration 76840, Loss: 0.000000285\n",
      "Iteration 76850, Loss: 0.000000467\n",
      "Iteration 76860, Loss: 0.000001590\n",
      "Iteration 76870, Loss: 0.000000684\n",
      "Iteration 76880, Loss: 0.000000425\n",
      "Iteration 76890, Loss: 0.000000324\n",
      "Iteration 76900, Loss: 0.000000283\n",
      "Iteration 76910, Loss: 0.000000272\n",
      "Iteration 76920, Loss: 0.000000312\n",
      "Iteration 76930, Loss: 0.000000283\n",
      "Iteration 76940, Loss: 0.000000634\n",
      "Iteration 76950, Loss: 0.000000372\n",
      "Iteration 76960, Loss: 0.000000477\n",
      "Iteration 76970, Loss: 0.000000321\n",
      "Iteration 76980, Loss: 0.000001075\n",
      "Iteration 76990, Loss: 0.000000339\n",
      "Iteration 77000, Loss: 0.000000339\n",
      "Iteration 77010, Loss: 0.000000310\n",
      "Iteration 77020, Loss: 0.000000302\n",
      "Iteration 77030, Loss: 0.000000281\n",
      "Iteration 77040, Loss: 0.000000271\n",
      "Iteration 77050, Loss: 0.000000267\n",
      "Iteration 77060, Loss: 0.000000268\n",
      "Iteration 77070, Loss: 0.000000281\n",
      "Iteration 77080, Loss: 0.000000976\n",
      "Iteration 77090, Loss: 0.000000666\n",
      "Iteration 77100, Loss: 0.000000491\n",
      "Iteration 77110, Loss: 0.000000321\n",
      "Iteration 77120, Loss: 0.000000287\n",
      "Iteration 77130, Loss: 0.000000283\n",
      "Iteration 77140, Loss: 0.000000310\n",
      "Iteration 77150, Loss: 0.000000779\n",
      "Iteration 77160, Loss: 0.000000616\n",
      "Iteration 77170, Loss: 0.000000386\n",
      "Iteration 77180, Loss: 0.000000323\n",
      "Iteration 77190, Loss: 0.000000295\n",
      "Iteration 77200, Loss: 0.000000283\n",
      "Iteration 77210, Loss: 0.000000290\n",
      "Iteration 77220, Loss: 0.000000920\n",
      "Iteration 77230, Loss: 0.000000426\n",
      "Iteration 77240, Loss: 0.000000343\n",
      "Iteration 77250, Loss: 0.000000393\n",
      "Iteration 77260, Loss: 0.000000309\n",
      "Iteration 77270, Loss: 0.000000275\n",
      "Iteration 77280, Loss: 0.000000270\n",
      "Iteration 77290, Loss: 0.000000268\n",
      "Iteration 77300, Loss: 0.000000273\n",
      "Iteration 77310, Loss: 0.000000389\n",
      "Iteration 77320, Loss: 0.000001202\n",
      "Iteration 77330, Loss: 0.000000387\n",
      "Iteration 77340, Loss: 0.000000475\n",
      "Iteration 77350, Loss: 0.000000385\n",
      "Iteration 77360, Loss: 0.000000293\n",
      "Iteration 77370, Loss: 0.000000275\n",
      "Iteration 77380, Loss: 0.000000271\n",
      "Iteration 77390, Loss: 0.000000269\n",
      "Iteration 77400, Loss: 0.000000279\n",
      "Iteration 77410, Loss: 0.000000549\n",
      "Iteration 77420, Loss: 0.000001188\n",
      "Iteration 77430, Loss: 0.000000669\n",
      "Iteration 77440, Loss: 0.000000392\n",
      "Iteration 77450, Loss: 0.000000320\n",
      "Iteration 77460, Loss: 0.000000311\n",
      "Iteration 77470, Loss: 0.000000869\n",
      "Iteration 77480, Loss: 0.000000519\n",
      "Iteration 77490, Loss: 0.000000325\n",
      "Iteration 77500, Loss: 0.000000281\n",
      "Iteration 77510, Loss: 0.000000340\n",
      "Iteration 77520, Loss: 0.000001488\n",
      "Iteration 77530, Loss: 0.000000394\n",
      "Iteration 77540, Loss: 0.000000370\n",
      "Iteration 77550, Loss: 0.000000317\n",
      "Iteration 77560, Loss: 0.000000285\n",
      "Iteration 77570, Loss: 0.000000271\n",
      "Iteration 77580, Loss: 0.000000267\n",
      "Iteration 77590, Loss: 0.000000268\n",
      "Iteration 77600, Loss: 0.000000303\n",
      "Iteration 77610, Loss: 0.000001524\n",
      "Iteration 77620, Loss: 0.000000987\n",
      "Iteration 77630, Loss: 0.000000502\n",
      "Iteration 77640, Loss: 0.000000306\n",
      "Iteration 77650, Loss: 0.000000300\n",
      "Iteration 77660, Loss: 0.000000305\n",
      "Iteration 77670, Loss: 0.000000407\n",
      "Iteration 77680, Loss: 0.000000971\n",
      "Iteration 77690, Loss: 0.000000270\n",
      "Iteration 77700, Loss: 0.000000339\n",
      "Iteration 77710, Loss: 0.000000326\n",
      "Iteration 77720, Loss: 0.000000385\n",
      "Iteration 77730, Loss: 0.000000328\n",
      "Iteration 77740, Loss: 0.000000640\n",
      "Iteration 77750, Loss: 0.000000350\n",
      "Iteration 77760, Loss: 0.000000417\n",
      "Iteration 77770, Loss: 0.000001729\n",
      "Iteration 77780, Loss: 0.000000601\n",
      "Iteration 77790, Loss: 0.000000464\n",
      "Iteration 77800, Loss: 0.000000351\n",
      "Iteration 77810, Loss: 0.000000300\n",
      "Iteration 77820, Loss: 0.000000280\n",
      "Iteration 77830, Loss: 0.000000270\n",
      "Iteration 77840, Loss: 0.000000316\n",
      "Iteration 77850, Loss: 0.000000405\n",
      "Iteration 77860, Loss: 0.000000491\n",
      "Iteration 77870, Loss: 0.000000506\n",
      "Iteration 77880, Loss: 0.000000648\n",
      "Iteration 77890, Loss: 0.000000310\n",
      "Iteration 77900, Loss: 0.000000333\n",
      "Iteration 77910, Loss: 0.000000296\n",
      "Iteration 77920, Loss: 0.000000392\n",
      "Iteration 77930, Loss: 0.000002751\n",
      "Iteration 77940, Loss: 0.000001191\n",
      "Iteration 77950, Loss: 0.000000314\n",
      "Iteration 77960, Loss: 0.000000355\n",
      "Iteration 77970, Loss: 0.000000289\n",
      "Iteration 77980, Loss: 0.000000269\n",
      "Iteration 77990, Loss: 0.000000270\n",
      "Iteration 78000, Loss: 0.000000268\n",
      "Iteration 78010, Loss: 0.000000283\n",
      "Iteration 78020, Loss: 0.000000784\n",
      "Iteration 78030, Loss: 0.000000551\n",
      "Iteration 78040, Loss: 0.000000357\n",
      "Iteration 78050, Loss: 0.000000313\n",
      "Iteration 78060, Loss: 0.000000287\n",
      "Iteration 78070, Loss: 0.000000297\n",
      "Iteration 78080, Loss: 0.000000399\n",
      "Iteration 78090, Loss: 0.000000651\n",
      "Iteration 78100, Loss: 0.000000321\n",
      "Iteration 78110, Loss: 0.000000281\n",
      "Iteration 78120, Loss: 0.000000281\n",
      "Iteration 78130, Loss: 0.000000276\n",
      "Iteration 78140, Loss: 0.000000274\n",
      "Iteration 78150, Loss: 0.000000412\n",
      "Iteration 78160, Loss: 0.000002581\n",
      "Iteration 78170, Loss: 0.000000980\n",
      "Iteration 78180, Loss: 0.000000481\n",
      "Iteration 78190, Loss: 0.000000300\n",
      "Iteration 78200, Loss: 0.000000270\n",
      "Iteration 78210, Loss: 0.000000276\n",
      "Iteration 78220, Loss: 0.000000316\n",
      "Iteration 78230, Loss: 0.000000770\n",
      "Iteration 78240, Loss: 0.000000407\n",
      "Iteration 78250, Loss: 0.000000344\n",
      "Iteration 78260, Loss: 0.000000592\n",
      "Iteration 78270, Loss: 0.000000340\n",
      "Iteration 78280, Loss: 0.000000343\n",
      "Iteration 78290, Loss: 0.000000300\n",
      "Iteration 78300, Loss: 0.000000273\n",
      "Iteration 78310, Loss: 0.000000385\n",
      "Iteration 78320, Loss: 0.000001333\n",
      "Iteration 78330, Loss: 0.000000634\n",
      "Iteration 78340, Loss: 0.000000358\n",
      "Iteration 78350, Loss: 0.000000311\n",
      "Iteration 78360, Loss: 0.000000304\n",
      "Iteration 78370, Loss: 0.000000407\n",
      "Iteration 78380, Loss: 0.000000895\n",
      "Iteration 78390, Loss: 0.000000944\n",
      "Iteration 78400, Loss: 0.000000395\n",
      "Iteration 78410, Loss: 0.000000332\n",
      "Iteration 78420, Loss: 0.000000282\n",
      "Iteration 78430, Loss: 0.000000284\n",
      "Iteration 78440, Loss: 0.000000323\n",
      "Iteration 78450, Loss: 0.000000700\n",
      "Iteration 78460, Loss: 0.000000751\n",
      "Iteration 78470, Loss: 0.000000542\n",
      "Iteration 78480, Loss: 0.000000369\n",
      "Iteration 78490, Loss: 0.000000284\n",
      "Iteration 78500, Loss: 0.000000320\n",
      "Iteration 78510, Loss: 0.000000461\n",
      "Iteration 78520, Loss: 0.000000369\n",
      "Iteration 78530, Loss: 0.000000429\n",
      "Iteration 78540, Loss: 0.000002009\n",
      "Iteration 78550, Loss: 0.000000776\n",
      "Iteration 78560, Loss: 0.000000361\n",
      "Iteration 78570, Loss: 0.000000308\n",
      "Iteration 78580, Loss: 0.000000275\n",
      "Iteration 78590, Loss: 0.000000281\n",
      "Iteration 78600, Loss: 0.000000489\n",
      "Iteration 78610, Loss: 0.000001594\n",
      "Iteration 78620, Loss: 0.000000696\n",
      "Iteration 78630, Loss: 0.000000390\n",
      "Iteration 78640, Loss: 0.000000306\n",
      "Iteration 78650, Loss: 0.000000287\n",
      "Iteration 78660, Loss: 0.000000326\n",
      "Iteration 78670, Loss: 0.000000460\n",
      "Iteration 78680, Loss: 0.000000425\n",
      "Iteration 78690, Loss: 0.000000303\n",
      "Iteration 78700, Loss: 0.000000305\n",
      "Iteration 78710, Loss: 0.000000370\n",
      "Iteration 78720, Loss: 0.000000763\n",
      "Iteration 78730, Loss: 0.000000401\n",
      "Iteration 78740, Loss: 0.000000443\n",
      "Iteration 78750, Loss: 0.000000517\n",
      "Iteration 78760, Loss: 0.000000601\n",
      "Iteration 78770, Loss: 0.000000501\n",
      "Iteration 78780, Loss: 0.000000467\n",
      "Iteration 78790, Loss: 0.000000628\n",
      "Iteration 78800, Loss: 0.000000327\n",
      "Iteration 78810, Loss: 0.000000377\n",
      "Iteration 78820, Loss: 0.000000399\n",
      "Iteration 78830, Loss: 0.000000573\n",
      "Iteration 78840, Loss: 0.000000320\n",
      "Iteration 78850, Loss: 0.000000347\n",
      "Iteration 78860, Loss: 0.000000302\n",
      "Iteration 78870, Loss: 0.000001044\n",
      "Iteration 78880, Loss: 0.000000384\n",
      "Iteration 78890, Loss: 0.000000492\n",
      "Iteration 78900, Loss: 0.000000433\n",
      "Iteration 78910, Loss: 0.000000288\n",
      "Iteration 78920, Loss: 0.000000269\n",
      "Iteration 78930, Loss: 0.000000267\n",
      "Iteration 78940, Loss: 0.000000292\n",
      "Iteration 78950, Loss: 0.000000727\n",
      "Iteration 78960, Loss: 0.000000470\n",
      "Iteration 78970, Loss: 0.000000365\n",
      "Iteration 78980, Loss: 0.000000349\n",
      "Iteration 78990, Loss: 0.000001653\n",
      "Iteration 79000, Loss: 0.000000574\n",
      "Iteration 79010, Loss: 0.000000377\n",
      "Iteration 79020, Loss: 0.000000308\n",
      "Iteration 79030, Loss: 0.000000284\n",
      "Iteration 79040, Loss: 0.000000270\n",
      "Iteration 79050, Loss: 0.000000273\n",
      "Iteration 79060, Loss: 0.000000339\n",
      "Iteration 79070, Loss: 0.000001262\n",
      "Iteration 79080, Loss: 0.000000320\n",
      "Iteration 79090, Loss: 0.000000290\n",
      "Iteration 79100, Loss: 0.000000278\n",
      "Iteration 79110, Loss: 0.000000281\n",
      "Iteration 79120, Loss: 0.000000371\n",
      "Iteration 79130, Loss: 0.000000984\n",
      "Iteration 79140, Loss: 0.000000450\n",
      "Iteration 79150, Loss: 0.000000350\n",
      "Iteration 79160, Loss: 0.000000302\n",
      "Iteration 79170, Loss: 0.000000314\n",
      "Iteration 79180, Loss: 0.000000648\n",
      "Iteration 79190, Loss: 0.000000875\n",
      "Iteration 79200, Loss: 0.000000590\n",
      "Iteration 79210, Loss: 0.000000384\n",
      "Iteration 79220, Loss: 0.000000330\n",
      "Iteration 79230, Loss: 0.000000374\n",
      "Iteration 79240, Loss: 0.000000688\n",
      "Iteration 79250, Loss: 0.000000687\n",
      "Iteration 79260, Loss: 0.000000466\n",
      "Iteration 79270, Loss: 0.000000308\n",
      "Iteration 79280, Loss: 0.000000288\n",
      "Iteration 79290, Loss: 0.000000393\n",
      "Iteration 79300, Loss: 0.000000474\n",
      "Iteration 79310, Loss: 0.000000338\n",
      "Iteration 79320, Loss: 0.000000647\n",
      "Iteration 79330, Loss: 0.000000587\n",
      "Iteration 79340, Loss: 0.000000593\n",
      "Iteration 79350, Loss: 0.000000477\n",
      "Iteration 79360, Loss: 0.000000563\n",
      "Iteration 79370, Loss: 0.000000310\n",
      "Iteration 79380, Loss: 0.000000323\n",
      "Iteration 79390, Loss: 0.000000296\n",
      "Iteration 79400, Loss: 0.000000636\n",
      "Iteration 79410, Loss: 0.000001232\n",
      "Iteration 79420, Loss: 0.000000591\n",
      "Iteration 79430, Loss: 0.000000389\n",
      "Iteration 79440, Loss: 0.000000287\n",
      "Iteration 79450, Loss: 0.000000278\n",
      "Iteration 79460, Loss: 0.000000312\n",
      "Iteration 79470, Loss: 0.000001156\n",
      "Iteration 79480, Loss: 0.000000576\n",
      "Iteration 79490, Loss: 0.000000372\n",
      "Iteration 79500, Loss: 0.000000281\n",
      "Iteration 79510, Loss: 0.000000282\n",
      "Iteration 79520, Loss: 0.000000371\n",
      "Iteration 79530, Loss: 0.000001646\n",
      "Iteration 79540, Loss: 0.000000549\n",
      "Iteration 79550, Loss: 0.000000399\n",
      "Iteration 79560, Loss: 0.000000318\n",
      "Iteration 79570, Loss: 0.000000281\n",
      "Iteration 79580, Loss: 0.000000278\n",
      "Iteration 79590, Loss: 0.000000519\n",
      "Iteration 79600, Loss: 0.000000612\n",
      "Iteration 79610, Loss: 0.000000337\n",
      "Iteration 79620, Loss: 0.000000312\n",
      "Iteration 79630, Loss: 0.000000353\n",
      "Iteration 79640, Loss: 0.000000409\n",
      "Iteration 79650, Loss: 0.000000438\n",
      "Iteration 79660, Loss: 0.000000412\n",
      "Iteration 79670, Loss: 0.000000352\n",
      "Iteration 79680, Loss: 0.000000425\n",
      "Iteration 79690, Loss: 0.000000805\n",
      "Iteration 79700, Loss: 0.000000531\n",
      "Iteration 79710, Loss: 0.000000946\n",
      "Iteration 79720, Loss: 0.000000518\n",
      "Iteration 79730, Loss: 0.000000438\n",
      "Iteration 79740, Loss: 0.000000284\n",
      "Iteration 79750, Loss: 0.000000295\n",
      "Iteration 79760, Loss: 0.000000266\n",
      "Iteration 79770, Loss: 0.000000262\n",
      "Iteration 79780, Loss: 0.000000266\n",
      "Iteration 79790, Loss: 0.000000346\n",
      "Iteration 79800, Loss: 0.000001860\n",
      "Iteration 79810, Loss: 0.000001371\n",
      "Iteration 79820, Loss: 0.000000606\n",
      "Iteration 79830, Loss: 0.000000328\n",
      "Iteration 79840, Loss: 0.000000318\n",
      "Iteration 79850, Loss: 0.000000280\n",
      "Iteration 79860, Loss: 0.000000265\n",
      "Iteration 79870, Loss: 0.000000264\n",
      "Iteration 79880, Loss: 0.000000262\n",
      "Iteration 79890, Loss: 0.000000262\n",
      "Iteration 79900, Loss: 0.000000264\n",
      "Iteration 79910, Loss: 0.000000364\n",
      "Iteration 79920, Loss: 0.000002180\n",
      "Iteration 79930, Loss: 0.000001011\n",
      "Iteration 79940, Loss: 0.000000404\n",
      "Iteration 79950, Loss: 0.000000344\n",
      "Iteration 79960, Loss: 0.000000299\n",
      "Iteration 79970, Loss: 0.000000275\n",
      "Iteration 79980, Loss: 0.000000269\n",
      "Iteration 79990, Loss: 0.000000271\n",
      "Iteration 80000, Loss: 0.000000448\n",
      "Iteration 80010, Loss: 0.000000588\n",
      "Iteration 80020, Loss: 0.000000325\n",
      "Iteration 80030, Loss: 0.000000296\n",
      "Iteration 80040, Loss: 0.000000281\n",
      "Iteration 80050, Loss: 0.000000285\n",
      "Iteration 80060, Loss: 0.000000325\n",
      "Iteration 80070, Loss: 0.000000763\n",
      "Iteration 80080, Loss: 0.000000481\n",
      "Iteration 80090, Loss: 0.000000440\n",
      "Iteration 80100, Loss: 0.000000320\n",
      "Iteration 80110, Loss: 0.000000264\n",
      "Iteration 80120, Loss: 0.000000283\n",
      "Iteration 80130, Loss: 0.000000473\n",
      "Iteration 80140, Loss: 0.000000768\n",
      "Iteration 80150, Loss: 0.000000305\n",
      "Iteration 80160, Loss: 0.000000374\n",
      "Iteration 80170, Loss: 0.000000370\n",
      "Iteration 80180, Loss: 0.000001381\n",
      "Iteration 80190, Loss: 0.000000434\n",
      "Iteration 80200, Loss: 0.000000435\n",
      "Iteration 80210, Loss: 0.000000349\n",
      "Iteration 80220, Loss: 0.000000300\n",
      "Iteration 80230, Loss: 0.000000274\n",
      "Iteration 80240, Loss: 0.000000266\n",
      "Iteration 80250, Loss: 0.000000267\n",
      "Iteration 80260, Loss: 0.000000333\n",
      "Iteration 80270, Loss: 0.000001029\n",
      "Iteration 80280, Loss: 0.000000508\n",
      "Iteration 80290, Loss: 0.000000334\n",
      "Iteration 80300, Loss: 0.000000271\n",
      "Iteration 80310, Loss: 0.000000267\n",
      "Iteration 80320, Loss: 0.000000498\n",
      "Iteration 80330, Loss: 0.000002275\n",
      "Iteration 80340, Loss: 0.000000351\n",
      "Iteration 80350, Loss: 0.000000431\n",
      "Iteration 80360, Loss: 0.000000352\n",
      "Iteration 80370, Loss: 0.000000268\n",
      "Iteration 80380, Loss: 0.000000268\n",
      "Iteration 80390, Loss: 0.000000273\n",
      "Iteration 80400, Loss: 0.000000370\n",
      "Iteration 80410, Loss: 0.000000649\n",
      "Iteration 80420, Loss: 0.000000790\n",
      "Iteration 80430, Loss: 0.000000427\n",
      "Iteration 80440, Loss: 0.000000327\n",
      "Iteration 80450, Loss: 0.000000272\n",
      "Iteration 80460, Loss: 0.000000264\n",
      "Iteration 80470, Loss: 0.000000262\n",
      "Iteration 80480, Loss: 0.000000263\n",
      "Iteration 80490, Loss: 0.000000317\n",
      "Iteration 80500, Loss: 0.000001666\n",
      "Iteration 80510, Loss: 0.000000746\n",
      "Iteration 80520, Loss: 0.000000438\n",
      "Iteration 80530, Loss: 0.000000360\n",
      "Iteration 80540, Loss: 0.000000284\n",
      "Iteration 80550, Loss: 0.000000295\n",
      "Iteration 80560, Loss: 0.000000362\n",
      "Iteration 80570, Loss: 0.000001101\n",
      "Iteration 80580, Loss: 0.000000401\n",
      "Iteration 80590, Loss: 0.000000349\n",
      "Iteration 80600, Loss: 0.000000658\n",
      "Iteration 80610, Loss: 0.000000728\n",
      "Iteration 80620, Loss: 0.000000482\n",
      "Iteration 80630, Loss: 0.000000299\n",
      "Iteration 80640, Loss: 0.000000303\n",
      "Iteration 80650, Loss: 0.000000303\n",
      "Iteration 80660, Loss: 0.000000279\n",
      "Iteration 80670, Loss: 0.000000304\n",
      "Iteration 80680, Loss: 0.000000613\n",
      "Iteration 80690, Loss: 0.000001026\n",
      "Iteration 80700, Loss: 0.000000609\n",
      "Iteration 80710, Loss: 0.000000479\n",
      "Iteration 80720, Loss: 0.000000332\n",
      "Iteration 80730, Loss: 0.000000291\n",
      "Iteration 80740, Loss: 0.000000360\n",
      "Iteration 80750, Loss: 0.000001122\n",
      "Iteration 80760, Loss: 0.000000508\n",
      "Iteration 80770, Loss: 0.000000354\n",
      "Iteration 80780, Loss: 0.000000356\n",
      "Iteration 80790, Loss: 0.000000431\n",
      "Iteration 80800, Loss: 0.000001305\n",
      "Iteration 80810, Loss: 0.000000393\n",
      "Iteration 80820, Loss: 0.000000322\n",
      "Iteration 80830, Loss: 0.000000311\n",
      "Iteration 80840, Loss: 0.000000280\n",
      "Iteration 80850, Loss: 0.000000268\n",
      "Iteration 80860, Loss: 0.000000267\n",
      "Iteration 80870, Loss: 0.000000294\n",
      "Iteration 80880, Loss: 0.000000636\n",
      "Iteration 80890, Loss: 0.000001133\n",
      "Iteration 80900, Loss: 0.000000441\n",
      "Iteration 80910, Loss: 0.000000442\n",
      "Iteration 80920, Loss: 0.000000279\n",
      "Iteration 80930, Loss: 0.000000284\n",
      "Iteration 80940, Loss: 0.000000304\n",
      "Iteration 80950, Loss: 0.000000675\n",
      "Iteration 80960, Loss: 0.000000871\n",
      "Iteration 80970, Loss: 0.000000365\n",
      "Iteration 80980, Loss: 0.000000425\n",
      "Iteration 80990, Loss: 0.000000341\n",
      "Iteration 81000, Loss: 0.000000274\n",
      "Iteration 81010, Loss: 0.000000272\n",
      "Iteration 81020, Loss: 0.000000261\n",
      "Iteration 81030, Loss: 0.000000260\n",
      "Iteration 81040, Loss: 0.000000278\n",
      "Iteration 81050, Loss: 0.000000589\n",
      "Iteration 81060, Loss: 0.000002338\n",
      "Iteration 81070, Loss: 0.000000552\n",
      "Iteration 81080, Loss: 0.000000318\n",
      "Iteration 81090, Loss: 0.000000355\n",
      "Iteration 81100, Loss: 0.000000279\n",
      "Iteration 81110, Loss: 0.000000264\n",
      "Iteration 81120, Loss: 0.000000262\n",
      "Iteration 81130, Loss: 0.000000262\n",
      "Iteration 81140, Loss: 0.000000329\n",
      "Iteration 81150, Loss: 0.000001403\n",
      "Iteration 81160, Loss: 0.000000472\n",
      "Iteration 81170, Loss: 0.000000358\n",
      "Iteration 81180, Loss: 0.000000292\n",
      "Iteration 81190, Loss: 0.000000282\n",
      "Iteration 81200, Loss: 0.000000265\n",
      "Iteration 81210, Loss: 0.000000279\n",
      "Iteration 81220, Loss: 0.000000616\n",
      "Iteration 81230, Loss: 0.000000592\n",
      "Iteration 81240, Loss: 0.000000281\n",
      "Iteration 81250, Loss: 0.000000306\n",
      "Iteration 81260, Loss: 0.000000307\n",
      "Iteration 81270, Loss: 0.000000357\n",
      "Iteration 81280, Loss: 0.000001218\n",
      "Iteration 81290, Loss: 0.000000326\n",
      "Iteration 81300, Loss: 0.000000294\n",
      "Iteration 81310, Loss: 0.000000275\n",
      "Iteration 81320, Loss: 0.000000276\n",
      "Iteration 81330, Loss: 0.000000274\n",
      "Iteration 81340, Loss: 0.000000296\n",
      "Iteration 81350, Loss: 0.000001444\n",
      "Iteration 81360, Loss: 0.000000760\n",
      "Iteration 81370, Loss: 0.000000425\n",
      "Iteration 81380, Loss: 0.000000328\n",
      "Iteration 81390, Loss: 0.000000284\n",
      "Iteration 81400, Loss: 0.000000263\n",
      "Iteration 81410, Loss: 0.000000268\n",
      "Iteration 81420, Loss: 0.000000315\n",
      "Iteration 81430, Loss: 0.000001133\n",
      "Iteration 81440, Loss: 0.000000306\n",
      "Iteration 81450, Loss: 0.000000274\n",
      "Iteration 81460, Loss: 0.000000282\n",
      "Iteration 81470, Loss: 0.000000278\n",
      "Iteration 81480, Loss: 0.000000279\n",
      "Iteration 81490, Loss: 0.000000271\n",
      "Iteration 81500, Loss: 0.000000401\n",
      "Iteration 81510, Loss: 0.000000956\n",
      "Iteration 81520, Loss: 0.000000460\n",
      "Iteration 81530, Loss: 0.000000338\n",
      "Iteration 81540, Loss: 0.000000306\n",
      "Iteration 81550, Loss: 0.000000482\n",
      "Iteration 81560, Loss: 0.000001332\n",
      "Iteration 81570, Loss: 0.000000541\n",
      "Iteration 81580, Loss: 0.000000322\n",
      "Iteration 81590, Loss: 0.000000273\n",
      "Iteration 81600, Loss: 0.000000324\n",
      "Iteration 81610, Loss: 0.000000670\n",
      "Iteration 81620, Loss: 0.000000309\n",
      "Iteration 81630, Loss: 0.000000299\n",
      "Iteration 81640, Loss: 0.000000287\n",
      "Iteration 81650, Loss: 0.000000321\n",
      "Iteration 81660, Loss: 0.000000308\n",
      "Iteration 81670, Loss: 0.000000479\n",
      "Iteration 81680, Loss: 0.000002752\n",
      "Iteration 81690, Loss: 0.000000867\n",
      "Iteration 81700, Loss: 0.000000552\n",
      "Iteration 81710, Loss: 0.000000330\n",
      "Iteration 81720, Loss: 0.000000301\n",
      "Iteration 81730, Loss: 0.000000267\n",
      "Iteration 81740, Loss: 0.000000261\n",
      "Iteration 81750, Loss: 0.000000259\n",
      "Iteration 81760, Loss: 0.000000258\n",
      "Iteration 81770, Loss: 0.000000258\n",
      "Iteration 81780, Loss: 0.000000258\n",
      "Iteration 81790, Loss: 0.000000296\n",
      "Iteration 81800, Loss: 0.000000338\n",
      "Iteration 81810, Loss: 0.000000321\n",
      "Iteration 81820, Loss: 0.000002044\n",
      "Iteration 81830, Loss: 0.000001276\n",
      "Iteration 81840, Loss: 0.000000473\n",
      "Iteration 81850, Loss: 0.000000335\n",
      "Iteration 81860, Loss: 0.000000300\n",
      "Iteration 81870, Loss: 0.000000273\n",
      "Iteration 81880, Loss: 0.000000260\n",
      "Iteration 81890, Loss: 0.000000259\n",
      "Iteration 81900, Loss: 0.000000258\n",
      "Iteration 81910, Loss: 0.000000261\n",
      "Iteration 81920, Loss: 0.000000439\n",
      "Iteration 81930, Loss: 0.000000686\n",
      "Iteration 81940, Loss: 0.000000415\n",
      "Iteration 81950, Loss: 0.000000336\n",
      "Iteration 81960, Loss: 0.000000285\n",
      "Iteration 81970, Loss: 0.000000311\n",
      "Iteration 81980, Loss: 0.000000734\n",
      "Iteration 81990, Loss: 0.000000490\n",
      "Iteration 82000, Loss: 0.000000441\n",
      "Iteration 82010, Loss: 0.000000318\n",
      "Iteration 82020, Loss: 0.000000261\n",
      "Iteration 82030, Loss: 0.000000291\n",
      "Iteration 82040, Loss: 0.000000353\n",
      "Iteration 82050, Loss: 0.000000290\n",
      "Iteration 82060, Loss: 0.000000689\n",
      "Iteration 82070, Loss: 0.000000556\n",
      "Iteration 82080, Loss: 0.000001107\n",
      "Iteration 82090, Loss: 0.000000481\n",
      "Iteration 82100, Loss: 0.000000272\n",
      "Iteration 82110, Loss: 0.000000301\n",
      "Iteration 82120, Loss: 0.000000265\n",
      "Iteration 82130, Loss: 0.000000271\n",
      "Iteration 82140, Loss: 0.000000279\n",
      "Iteration 82150, Loss: 0.000000412\n",
      "Iteration 82160, Loss: 0.000001345\n",
      "Iteration 82170, Loss: 0.000000424\n",
      "Iteration 82180, Loss: 0.000000296\n",
      "Iteration 82190, Loss: 0.000000372\n",
      "Iteration 82200, Loss: 0.000000311\n",
      "Iteration 82210, Loss: 0.000000325\n",
      "Iteration 82220, Loss: 0.000000502\n",
      "Iteration 82230, Loss: 0.000000356\n",
      "Iteration 82240, Loss: 0.000000373\n",
      "Iteration 82250, Loss: 0.000000296\n",
      "Iteration 82260, Loss: 0.000000519\n",
      "Iteration 82270, Loss: 0.000001852\n",
      "Iteration 82280, Loss: 0.000000696\n",
      "Iteration 82290, Loss: 0.000000317\n",
      "Iteration 82300, Loss: 0.000000276\n",
      "Iteration 82310, Loss: 0.000000269\n",
      "Iteration 82320, Loss: 0.000000275\n",
      "Iteration 82330, Loss: 0.000000524\n",
      "Iteration 82340, Loss: 0.000000754\n",
      "Iteration 82350, Loss: 0.000000366\n",
      "Iteration 82360, Loss: 0.000000303\n",
      "Iteration 82370, Loss: 0.000000274\n",
      "Iteration 82380, Loss: 0.000000313\n",
      "Iteration 82390, Loss: 0.000000664\n",
      "Iteration 82400, Loss: 0.000000570\n",
      "Iteration 82410, Loss: 0.000000703\n",
      "Iteration 82420, Loss: 0.000000301\n",
      "Iteration 82430, Loss: 0.000000348\n",
      "Iteration 82440, Loss: 0.000000296\n",
      "Iteration 82450, Loss: 0.000000278\n",
      "Iteration 82460, Loss: 0.000000356\n",
      "Iteration 82470, Loss: 0.000001188\n",
      "Iteration 82480, Loss: 0.000000271\n",
      "Iteration 82490, Loss: 0.000000274\n",
      "Iteration 82500, Loss: 0.000000353\n",
      "Iteration 82510, Loss: 0.000000657\n",
      "Iteration 82520, Loss: 0.000000380\n",
      "Iteration 82530, Loss: 0.000000285\n",
      "Iteration 82540, Loss: 0.000000318\n",
      "Iteration 82550, Loss: 0.000000457\n",
      "Iteration 82560, Loss: 0.000000685\n",
      "Iteration 82570, Loss: 0.000000442\n",
      "Iteration 82580, Loss: 0.000000336\n",
      "Iteration 82590, Loss: 0.000000338\n",
      "Iteration 82600, Loss: 0.000000439\n",
      "Iteration 82610, Loss: 0.000001225\n",
      "Iteration 82620, Loss: 0.000000378\n",
      "Iteration 82630, Loss: 0.000000279\n",
      "Iteration 82640, Loss: 0.000000326\n",
      "Iteration 82650, Loss: 0.000000342\n",
      "Iteration 82660, Loss: 0.000000345\n",
      "Iteration 82670, Loss: 0.000000426\n",
      "Iteration 82680, Loss: 0.000001446\n",
      "Iteration 82690, Loss: 0.000000666\n",
      "Iteration 82700, Loss: 0.000000384\n",
      "Iteration 82710, Loss: 0.000000303\n",
      "Iteration 82720, Loss: 0.000000316\n",
      "Iteration 82730, Loss: 0.000000364\n",
      "Iteration 82740, Loss: 0.000000731\n",
      "Iteration 82750, Loss: 0.000000351\n",
      "Iteration 82760, Loss: 0.000000454\n",
      "Iteration 82770, Loss: 0.000000283\n",
      "Iteration 82780, Loss: 0.000000288\n",
      "Iteration 82790, Loss: 0.000000418\n",
      "Iteration 82800, Loss: 0.000001207\n",
      "Iteration 82810, Loss: 0.000000627\n",
      "Iteration 82820, Loss: 0.000000539\n",
      "Iteration 82830, Loss: 0.000000366\n",
      "Iteration 82840, Loss: 0.000000280\n",
      "Iteration 82850, Loss: 0.000000282\n",
      "Iteration 82860, Loss: 0.000000362\n",
      "Iteration 82870, Loss: 0.000000666\n",
      "Iteration 82880, Loss: 0.000000458\n",
      "Iteration 82890, Loss: 0.000000652\n",
      "Iteration 82900, Loss: 0.000000464\n",
      "Iteration 82910, Loss: 0.000000304\n",
      "Iteration 82920, Loss: 0.000000378\n",
      "Iteration 82930, Loss: 0.000000358\n",
      "Iteration 82940, Loss: 0.000000394\n",
      "Iteration 82950, Loss: 0.000000515\n",
      "Iteration 82960, Loss: 0.000000468\n",
      "Iteration 82970, Loss: 0.000000893\n",
      "Iteration 82980, Loss: 0.000000399\n",
      "Iteration 82990, Loss: 0.000000337\n",
      "Iteration 83000, Loss: 0.000000304\n",
      "Iteration 83010, Loss: 0.000000319\n",
      "Iteration 83020, Loss: 0.000000536\n",
      "Iteration 83030, Loss: 0.000000956\n",
      "Iteration 83040, Loss: 0.000000423\n",
      "Iteration 83050, Loss: 0.000000294\n",
      "Iteration 83060, Loss: 0.000000478\n",
      "Iteration 83070, Loss: 0.000000715\n",
      "Iteration 83080, Loss: 0.000000342\n",
      "Iteration 83090, Loss: 0.000000287\n",
      "Iteration 83100, Loss: 0.000000288\n",
      "Iteration 83110, Loss: 0.000000468\n",
      "Iteration 83120, Loss: 0.000001526\n",
      "Iteration 83130, Loss: 0.000000679\n",
      "Iteration 83140, Loss: 0.000000399\n",
      "Iteration 83150, Loss: 0.000000305\n",
      "Iteration 83160, Loss: 0.000000276\n",
      "Iteration 83170, Loss: 0.000000281\n",
      "Iteration 83180, Loss: 0.000000642\n",
      "Iteration 83190, Loss: 0.000000389\n",
      "Iteration 83200, Loss: 0.000000319\n",
      "Iteration 83210, Loss: 0.000000340\n",
      "Iteration 83220, Loss: 0.000000499\n",
      "Iteration 83230, Loss: 0.000001017\n",
      "Iteration 83240, Loss: 0.000000401\n",
      "Iteration 83250, Loss: 0.000000308\n",
      "Iteration 83260, Loss: 0.000000295\n",
      "Iteration 83270, Loss: 0.000000281\n",
      "Iteration 83280, Loss: 0.000000284\n",
      "Iteration 83290, Loss: 0.000000363\n",
      "Iteration 83300, Loss: 0.000001116\n",
      "Iteration 83310, Loss: 0.000000454\n",
      "Iteration 83320, Loss: 0.000000323\n",
      "Iteration 83330, Loss: 0.000000280\n",
      "Iteration 83340, Loss: 0.000000268\n",
      "Iteration 83350, Loss: 0.000000275\n",
      "Iteration 83360, Loss: 0.000000524\n",
      "Iteration 83370, Loss: 0.000001344\n",
      "Iteration 83380, Loss: 0.000000586\n",
      "Iteration 83390, Loss: 0.000000351\n",
      "Iteration 83400, Loss: 0.000000283\n",
      "Iteration 83410, Loss: 0.000000262\n",
      "Iteration 83420, Loss: 0.000000282\n",
      "Iteration 83430, Loss: 0.000000817\n",
      "Iteration 83440, Loss: 0.000000589\n",
      "Iteration 83450, Loss: 0.000000451\n",
      "Iteration 83460, Loss: 0.000000348\n",
      "Iteration 83470, Loss: 0.000000279\n",
      "Iteration 83480, Loss: 0.000000265\n",
      "Iteration 83490, Loss: 0.000000261\n",
      "Iteration 83500, Loss: 0.000000276\n",
      "Iteration 83510, Loss: 0.000000550\n",
      "Iteration 83520, Loss: 0.000001107\n",
      "Iteration 83530, Loss: 0.000000467\n",
      "Iteration 83540, Loss: 0.000000331\n",
      "Iteration 83550, Loss: 0.000000283\n",
      "Iteration 83560, Loss: 0.000000283\n",
      "Iteration 83570, Loss: 0.000000311\n",
      "Iteration 83580, Loss: 0.000000536\n",
      "Iteration 83590, Loss: 0.000000856\n",
      "Iteration 83600, Loss: 0.000000631\n",
      "Iteration 83610, Loss: 0.000000357\n",
      "Iteration 83620, Loss: 0.000000296\n",
      "Iteration 83630, Loss: 0.000000297\n",
      "Iteration 83640, Loss: 0.000000780\n",
      "Iteration 83650, Loss: 0.000000584\n",
      "Iteration 83660, Loss: 0.000000454\n",
      "Iteration 83670, Loss: 0.000000402\n",
      "Iteration 83680, Loss: 0.000000336\n",
      "Iteration 83690, Loss: 0.000000269\n",
      "Iteration 83700, Loss: 0.000000281\n",
      "Iteration 83710, Loss: 0.000000341\n",
      "Iteration 83720, Loss: 0.000000818\n",
      "Iteration 83730, Loss: 0.000000656\n",
      "Iteration 83740, Loss: 0.000000477\n",
      "Iteration 83750, Loss: 0.000000479\n",
      "Iteration 83760, Loss: 0.000000382\n",
      "Iteration 83770, Loss: 0.000000291\n",
      "Iteration 83780, Loss: 0.000000432\n",
      "Iteration 83790, Loss: 0.000001191\n",
      "Iteration 83800, Loss: 0.000000447\n",
      "Iteration 83810, Loss: 0.000000302\n",
      "Iteration 83820, Loss: 0.000000340\n",
      "Iteration 83830, Loss: 0.000000589\n",
      "Iteration 83840, Loss: 0.000000481\n",
      "Iteration 83850, Loss: 0.000000368\n",
      "Iteration 83860, Loss: 0.000000302\n",
      "Iteration 83870, Loss: 0.000000298\n",
      "Iteration 83880, Loss: 0.000000382\n",
      "Iteration 83890, Loss: 0.000000829\n",
      "Iteration 83900, Loss: 0.000000328\n",
      "Iteration 83910, Loss: 0.000000480\n",
      "Iteration 83920, Loss: 0.000000486\n",
      "Iteration 83930, Loss: 0.000000335\n",
      "Iteration 83940, Loss: 0.000000335\n",
      "Iteration 83950, Loss: 0.000000817\n",
      "Iteration 83960, Loss: 0.000000466\n",
      "Iteration 83970, Loss: 0.000000384\n",
      "Iteration 83980, Loss: 0.000000310\n",
      "Iteration 83990, Loss: 0.000000283\n",
      "Iteration 84000, Loss: 0.000000317\n",
      "Iteration 84010, Loss: 0.000001298\n",
      "Iteration 84020, Loss: 0.000000393\n",
      "Iteration 84030, Loss: 0.000000295\n",
      "Iteration 84040, Loss: 0.000000288\n",
      "Iteration 84050, Loss: 0.000000268\n",
      "Iteration 84060, Loss: 0.000000272\n",
      "Iteration 84070, Loss: 0.000000261\n",
      "Iteration 84080, Loss: 0.000000426\n",
      "Iteration 84090, Loss: 0.000000658\n",
      "Iteration 84100, Loss: 0.000000337\n",
      "Iteration 84110, Loss: 0.000000304\n",
      "Iteration 84120, Loss: 0.000000426\n",
      "Iteration 84130, Loss: 0.000000818\n",
      "Iteration 84140, Loss: 0.000000788\n",
      "Iteration 84150, Loss: 0.000000457\n",
      "Iteration 84160, Loss: 0.000000265\n",
      "Iteration 84170, Loss: 0.000000280\n",
      "Iteration 84180, Loss: 0.000000258\n",
      "Iteration 84190, Loss: 0.000000269\n",
      "Iteration 84200, Loss: 0.000000348\n",
      "Iteration 84210, Loss: 0.000001277\n",
      "Iteration 84220, Loss: 0.000000607\n",
      "Iteration 84230, Loss: 0.000000595\n",
      "Iteration 84240, Loss: 0.000000539\n",
      "Iteration 84250, Loss: 0.000000274\n",
      "Iteration 84260, Loss: 0.000000330\n",
      "Iteration 84270, Loss: 0.000000417\n",
      "Iteration 84280, Loss: 0.000000521\n",
      "Iteration 84290, Loss: 0.000000453\n",
      "Iteration 84300, Loss: 0.000000311\n",
      "Iteration 84310, Loss: 0.000000360\n",
      "Iteration 84320, Loss: 0.000000630\n",
      "Iteration 84330, Loss: 0.000000785\n",
      "Iteration 84340, Loss: 0.000000503\n",
      "Iteration 84350, Loss: 0.000000289\n",
      "Iteration 84360, Loss: 0.000000302\n",
      "Iteration 84370, Loss: 0.000000280\n",
      "Iteration 84380, Loss: 0.000000572\n",
      "Iteration 84390, Loss: 0.000000643\n",
      "Iteration 84400, Loss: 0.000000355\n",
      "Iteration 84410, Loss: 0.000000269\n",
      "Iteration 84420, Loss: 0.000000262\n",
      "Iteration 84430, Loss: 0.000000403\n",
      "Iteration 84440, Loss: 0.000002096\n",
      "Iteration 84450, Loss: 0.000000896\n",
      "Iteration 84460, Loss: 0.000000551\n",
      "Iteration 84470, Loss: 0.000000386\n",
      "Iteration 84480, Loss: 0.000000420\n",
      "Iteration 84490, Loss: 0.000000635\n",
      "Iteration 84500, Loss: 0.000000263\n",
      "Iteration 84510, Loss: 0.000000275\n",
      "Iteration 84520, Loss: 0.000000262\n",
      "Iteration 84530, Loss: 0.000000262\n",
      "Iteration 84540, Loss: 0.000000261\n",
      "Iteration 84550, Loss: 0.000000281\n",
      "Iteration 84560, Loss: 0.000000633\n",
      "Iteration 84570, Loss: 0.000000973\n",
      "Iteration 84580, Loss: 0.000000408\n",
      "Iteration 84590, Loss: 0.000000360\n",
      "Iteration 84600, Loss: 0.000000346\n",
      "Iteration 84610, Loss: 0.000000446\n",
      "Iteration 84620, Loss: 0.000000553\n",
      "Iteration 84630, Loss: 0.000000304\n",
      "Iteration 84640, Loss: 0.000000298\n",
      "Iteration 84650, Loss: 0.000000424\n",
      "Iteration 84660, Loss: 0.000000695\n",
      "Iteration 84670, Loss: 0.000000349\n",
      "Iteration 84680, Loss: 0.000000406\n",
      "Iteration 84690, Loss: 0.000000277\n",
      "Iteration 84700, Loss: 0.000000333\n",
      "Iteration 84710, Loss: 0.000001121\n",
      "Iteration 84720, Loss: 0.000000751\n",
      "Iteration 84730, Loss: 0.000000472\n",
      "Iteration 84740, Loss: 0.000000362\n",
      "Iteration 84750, Loss: 0.000000284\n",
      "Iteration 84760, Loss: 0.000000266\n",
      "Iteration 84770, Loss: 0.000000300\n",
      "Iteration 84780, Loss: 0.000000278\n",
      "Iteration 84790, Loss: 0.000000344\n",
      "Iteration 84800, Loss: 0.000001541\n",
      "Iteration 84810, Loss: 0.000000615\n",
      "Iteration 84820, Loss: 0.000000444\n",
      "Iteration 84830, Loss: 0.000000303\n",
      "Iteration 84840, Loss: 0.000000266\n",
      "Iteration 84850, Loss: 0.000000255\n",
      "Iteration 84860, Loss: 0.000000253\n",
      "Iteration 84870, Loss: 0.000000256\n",
      "Iteration 84880, Loss: 0.000000345\n",
      "Iteration 84890, Loss: 0.000001718\n",
      "Iteration 84900, Loss: 0.000000558\n",
      "Iteration 84910, Loss: 0.000000469\n",
      "Iteration 84920, Loss: 0.000000378\n",
      "Iteration 84930, Loss: 0.000000454\n",
      "Iteration 84940, Loss: 0.000000321\n",
      "Iteration 84950, Loss: 0.000000266\n",
      "Iteration 84960, Loss: 0.000000258\n",
      "Iteration 84970, Loss: 0.000000254\n",
      "Iteration 84980, Loss: 0.000000252\n",
      "Iteration 84990, Loss: 0.000000256\n",
      "Iteration 85000, Loss: 0.000000444\n",
      "Iteration 85010, Loss: 0.000001011\n",
      "Iteration 85020, Loss: 0.000000464\n",
      "Iteration 85030, Loss: 0.000000327\n",
      "Iteration 85040, Loss: 0.000000268\n",
      "Iteration 85050, Loss: 0.000000266\n",
      "Iteration 85060, Loss: 0.000000256\n",
      "Iteration 85070, Loss: 0.000000252\n",
      "Iteration 85080, Loss: 0.000000252\n",
      "Iteration 85090, Loss: 0.000000252\n",
      "Iteration 85100, Loss: 0.000000255\n",
      "Iteration 85110, Loss: 0.000000361\n",
      "Iteration 85120, Loss: 0.000002512\n",
      "Iteration 85130, Loss: 0.000000712\n",
      "Iteration 85140, Loss: 0.000000375\n",
      "Iteration 85150, Loss: 0.000000284\n",
      "Iteration 85160, Loss: 0.000000282\n",
      "Iteration 85170, Loss: 0.000000258\n",
      "Iteration 85180, Loss: 0.000000277\n",
      "Iteration 85190, Loss: 0.000000386\n",
      "Iteration 85200, Loss: 0.000000309\n",
      "Iteration 85210, Loss: 0.000000731\n",
      "Iteration 85220, Loss: 0.000001345\n",
      "Iteration 85230, Loss: 0.000000555\n",
      "Iteration 85240, Loss: 0.000000290\n",
      "Iteration 85250, Loss: 0.000000273\n",
      "Iteration 85260, Loss: 0.000000272\n",
      "Iteration 85270, Loss: 0.000000257\n",
      "Iteration 85280, Loss: 0.000000255\n",
      "Iteration 85290, Loss: 0.000000263\n",
      "Iteration 85300, Loss: 0.000000429\n",
      "Iteration 85310, Loss: 0.000001737\n",
      "Iteration 85320, Loss: 0.000000727\n",
      "Iteration 85330, Loss: 0.000000418\n",
      "Iteration 85340, Loss: 0.000000325\n",
      "Iteration 85350, Loss: 0.000000554\n",
      "Iteration 85360, Loss: 0.000000445\n",
      "Iteration 85370, Loss: 0.000000347\n",
      "Iteration 85380, Loss: 0.000000291\n",
      "Iteration 85390, Loss: 0.000000273\n",
      "Iteration 85400, Loss: 0.000000266\n",
      "Iteration 85410, Loss: 0.000000377\n",
      "Iteration 85420, Loss: 0.000000355\n",
      "Iteration 85430, Loss: 0.000000928\n",
      "Iteration 85440, Loss: 0.000000925\n",
      "Iteration 85450, Loss: 0.000000537\n",
      "Iteration 85460, Loss: 0.000000328\n",
      "Iteration 85470, Loss: 0.000000266\n",
      "Iteration 85480, Loss: 0.000000259\n",
      "Iteration 85490, Loss: 0.000000261\n",
      "Iteration 85500, Loss: 0.000000371\n",
      "Iteration 85510, Loss: 0.000001326\n",
      "Iteration 85520, Loss: 0.000000655\n",
      "Iteration 85530, Loss: 0.000000275\n",
      "Iteration 85540, Loss: 0.000000317\n",
      "Iteration 85550, Loss: 0.000000293\n",
      "Iteration 85560, Loss: 0.000000316\n",
      "Iteration 85570, Loss: 0.000000723\n",
      "Iteration 85580, Loss: 0.000000622\n",
      "Iteration 85590, Loss: 0.000000586\n",
      "Iteration 85600, Loss: 0.000000437\n",
      "Iteration 85610, Loss: 0.000000283\n",
      "Iteration 85620, Loss: 0.000000281\n",
      "Iteration 85630, Loss: 0.000000272\n",
      "Iteration 85640, Loss: 0.000000371\n",
      "Iteration 85650, Loss: 0.000000822\n",
      "Iteration 85660, Loss: 0.000000443\n",
      "Iteration 85670, Loss: 0.000000588\n",
      "Iteration 85680, Loss: 0.000000776\n",
      "Iteration 85690, Loss: 0.000000325\n",
      "Iteration 85700, Loss: 0.000000340\n",
      "Iteration 85710, Loss: 0.000000321\n",
      "Iteration 85720, Loss: 0.000000439\n",
      "Iteration 85730, Loss: 0.000000821\n",
      "Iteration 85740, Loss: 0.000000361\n",
      "Iteration 85750, Loss: 0.000000377\n",
      "Iteration 85760, Loss: 0.000000812\n",
      "Iteration 85770, Loss: 0.000000317\n",
      "Iteration 85780, Loss: 0.000000390\n",
      "Iteration 85790, Loss: 0.000000258\n",
      "Iteration 85800, Loss: 0.000000281\n",
      "Iteration 85810, Loss: 0.000000283\n",
      "Iteration 85820, Loss: 0.000000409\n",
      "Iteration 85830, Loss: 0.000001058\n",
      "Iteration 85840, Loss: 0.000000694\n",
      "Iteration 85850, Loss: 0.000000401\n",
      "Iteration 85860, Loss: 0.000000351\n",
      "Iteration 85870, Loss: 0.000000317\n",
      "Iteration 85880, Loss: 0.000000278\n",
      "Iteration 85890, Loss: 0.000000294\n",
      "Iteration 85900, Loss: 0.000000669\n",
      "Iteration 85910, Loss: 0.000001166\n",
      "Iteration 85920, Loss: 0.000000670\n",
      "Iteration 85930, Loss: 0.000000481\n",
      "Iteration 85940, Loss: 0.000000307\n",
      "Iteration 85950, Loss: 0.000000286\n",
      "Iteration 85960, Loss: 0.000000257\n",
      "Iteration 85970, Loss: 0.000000253\n",
      "Iteration 85980, Loss: 0.000000253\n",
      "Iteration 85990, Loss: 0.000000288\n",
      "Iteration 86000, Loss: 0.000000666\n",
      "Iteration 86010, Loss: 0.000000590\n",
      "Iteration 86020, Loss: 0.000000560\n",
      "Iteration 86030, Loss: 0.000000277\n",
      "Iteration 86040, Loss: 0.000000319\n",
      "Iteration 86050, Loss: 0.000000344\n",
      "Iteration 86060, Loss: 0.000000368\n",
      "Iteration 86070, Loss: 0.000000478\n",
      "Iteration 86080, Loss: 0.000000510\n",
      "Iteration 86090, Loss: 0.000000264\n",
      "Iteration 86100, Loss: 0.000000275\n",
      "Iteration 86110, Loss: 0.000000408\n",
      "Iteration 86120, Loss: 0.000001016\n",
      "Iteration 86130, Loss: 0.000000334\n",
      "Iteration 86140, Loss: 0.000000295\n",
      "Iteration 86150, Loss: 0.000000459\n",
      "Iteration 86160, Loss: 0.000000909\n",
      "Iteration 86170, Loss: 0.000000536\n",
      "Iteration 86180, Loss: 0.000000299\n",
      "Iteration 86190, Loss: 0.000000260\n",
      "Iteration 86200, Loss: 0.000000267\n",
      "Iteration 86210, Loss: 0.000000535\n",
      "Iteration 86220, Loss: 0.000001543\n",
      "Iteration 86230, Loss: 0.000000600\n",
      "Iteration 86240, Loss: 0.000000307\n",
      "Iteration 86250, Loss: 0.000000260\n",
      "Iteration 86260, Loss: 0.000000255\n",
      "Iteration 86270, Loss: 0.000000263\n",
      "Iteration 86280, Loss: 0.000000350\n",
      "Iteration 86290, Loss: 0.000000409\n",
      "Iteration 86300, Loss: 0.000001339\n",
      "Iteration 86310, Loss: 0.000000412\n",
      "Iteration 86320, Loss: 0.000000317\n",
      "Iteration 86330, Loss: 0.000000298\n",
      "Iteration 86340, Loss: 0.000000268\n",
      "Iteration 86350, Loss: 0.000000260\n",
      "Iteration 86360, Loss: 0.000000263\n",
      "Iteration 86370, Loss: 0.000000510\n",
      "Iteration 86380, Loss: 0.000001673\n",
      "Iteration 86390, Loss: 0.000000460\n",
      "Iteration 86400, Loss: 0.000000290\n",
      "Iteration 86410, Loss: 0.000000300\n",
      "Iteration 86420, Loss: 0.000000269\n",
      "Iteration 86430, Loss: 0.000000256\n",
      "Iteration 86440, Loss: 0.000000268\n",
      "Iteration 86450, Loss: 0.000000636\n",
      "Iteration 86460, Loss: 0.000001128\n",
      "Iteration 86470, Loss: 0.000000442\n",
      "Iteration 86480, Loss: 0.000000359\n",
      "Iteration 86490, Loss: 0.000000295\n",
      "Iteration 86500, Loss: 0.000000259\n",
      "Iteration 86510, Loss: 0.000000251\n",
      "Iteration 86520, Loss: 0.000000250\n",
      "Iteration 86530, Loss: 0.000000249\n",
      "Iteration 86540, Loss: 0.000000251\n",
      "Iteration 86550, Loss: 0.000000371\n",
      "Iteration 86560, Loss: 0.000002168\n",
      "Iteration 86570, Loss: 0.000000631\n",
      "Iteration 86580, Loss: 0.000000528\n",
      "Iteration 86590, Loss: 0.000000304\n",
      "Iteration 86600, Loss: 0.000000271\n",
      "Iteration 86610, Loss: 0.000000251\n",
      "Iteration 86620, Loss: 0.000000273\n",
      "Iteration 86630, Loss: 0.000000870\n",
      "Iteration 86640, Loss: 0.000000360\n",
      "Iteration 86650, Loss: 0.000000400\n",
      "Iteration 86660, Loss: 0.000000320\n",
      "Iteration 86670, Loss: 0.000000263\n",
      "Iteration 86680, Loss: 0.000000259\n",
      "Iteration 86690, Loss: 0.000000276\n",
      "Iteration 86700, Loss: 0.000000581\n",
      "Iteration 86710, Loss: 0.000001652\n",
      "Iteration 86720, Loss: 0.000000436\n",
      "Iteration 86730, Loss: 0.000000319\n",
      "Iteration 86740, Loss: 0.000000295\n",
      "Iteration 86750, Loss: 0.000000266\n",
      "Iteration 86760, Loss: 0.000000254\n",
      "Iteration 86770, Loss: 0.000000250\n",
      "Iteration 86780, Loss: 0.000000249\n",
      "Iteration 86790, Loss: 0.000000248\n",
      "Iteration 86800, Loss: 0.000000248\n",
      "Iteration 86810, Loss: 0.000000253\n",
      "Iteration 86820, Loss: 0.000000667\n",
      "Iteration 86830, Loss: 0.000000819\n",
      "Iteration 86840, Loss: 0.000000500\n",
      "Iteration 86850, Loss: 0.000000394\n",
      "Iteration 86860, Loss: 0.000000302\n",
      "Iteration 86870, Loss: 0.000000267\n",
      "Iteration 86880, Loss: 0.000000307\n",
      "Iteration 86890, Loss: 0.000000843\n",
      "Iteration 86900, Loss: 0.000000427\n",
      "Iteration 86910, Loss: 0.000000415\n",
      "Iteration 86920, Loss: 0.000000397\n",
      "Iteration 86930, Loss: 0.000000287\n",
      "Iteration 86940, Loss: 0.000000258\n",
      "Iteration 86950, Loss: 0.000000321\n",
      "Iteration 86960, Loss: 0.000000942\n",
      "Iteration 86970, Loss: 0.000000336\n",
      "Iteration 86980, Loss: 0.000000283\n",
      "Iteration 86990, Loss: 0.000000261\n",
      "Iteration 87000, Loss: 0.000000256\n",
      "Iteration 87010, Loss: 0.000000621\n",
      "Iteration 87020, Loss: 0.000001234\n",
      "Iteration 87030, Loss: 0.000000406\n",
      "Iteration 87040, Loss: 0.000000840\n",
      "Iteration 87050, Loss: 0.000000416\n",
      "Iteration 87060, Loss: 0.000000293\n",
      "Iteration 87070, Loss: 0.000000266\n",
      "Iteration 87080, Loss: 0.000000254\n",
      "Iteration 87090, Loss: 0.000000251\n",
      "Iteration 87100, Loss: 0.000000248\n",
      "Iteration 87110, Loss: 0.000000248\n",
      "Iteration 87120, Loss: 0.000000248\n",
      "Iteration 87130, Loss: 0.000000271\n",
      "Iteration 87140, Loss: 0.000001288\n",
      "Iteration 87150, Loss: 0.000000944\n",
      "Iteration 87160, Loss: 0.000000400\n",
      "Iteration 87170, Loss: 0.000000303\n",
      "Iteration 87180, Loss: 0.000000267\n",
      "Iteration 87190, Loss: 0.000000256\n",
      "Iteration 87200, Loss: 0.000000253\n",
      "Iteration 87210, Loss: 0.000000289\n",
      "Iteration 87220, Loss: 0.000000375\n",
      "Iteration 87230, Loss: 0.000000519\n",
      "Iteration 87240, Loss: 0.000000624\n",
      "Iteration 87250, Loss: 0.000000420\n",
      "Iteration 87260, Loss: 0.000000318\n",
      "Iteration 87270, Loss: 0.000000312\n",
      "Iteration 87280, Loss: 0.000000284\n",
      "Iteration 87290, Loss: 0.000000313\n",
      "Iteration 87300, Loss: 0.000000823\n",
      "Iteration 87310, Loss: 0.000000442\n",
      "Iteration 87320, Loss: 0.000000406\n",
      "Iteration 87330, Loss: 0.000000338\n",
      "Iteration 87340, Loss: 0.000000377\n",
      "Iteration 87350, Loss: 0.000000709\n",
      "Iteration 87360, Loss: 0.000000365\n",
      "Iteration 87370, Loss: 0.000000277\n",
      "Iteration 87380, Loss: 0.000000272\n",
      "Iteration 87390, Loss: 0.000000381\n",
      "Iteration 87400, Loss: 0.000000854\n",
      "Iteration 87410, Loss: 0.000000726\n",
      "Iteration 87420, Loss: 0.000001253\n",
      "Iteration 87430, Loss: 0.000000505\n",
      "Iteration 87440, Loss: 0.000000328\n",
      "Iteration 87450, Loss: 0.000000276\n",
      "Iteration 87460, Loss: 0.000000260\n",
      "Iteration 87470, Loss: 0.000000250\n",
      "Iteration 87480, Loss: 0.000000251\n",
      "Iteration 87490, Loss: 0.000000277\n",
      "Iteration 87500, Loss: 0.000000349\n",
      "Iteration 87510, Loss: 0.000001605\n",
      "Iteration 87520, Loss: 0.000000833\n",
      "Iteration 87530, Loss: 0.000000524\n",
      "Iteration 87540, Loss: 0.000000285\n",
      "Iteration 87550, Loss: 0.000000289\n",
      "Iteration 87560, Loss: 0.000000249\n",
      "Iteration 87570, Loss: 0.000000251\n",
      "Iteration 87580, Loss: 0.000000249\n",
      "Iteration 87590, Loss: 0.000000264\n",
      "Iteration 87600, Loss: 0.000000647\n",
      "Iteration 87610, Loss: 0.000002259\n",
      "Iteration 87620, Loss: 0.000000517\n",
      "Iteration 87630, Loss: 0.000000438\n",
      "Iteration 87640, Loss: 0.000000292\n",
      "Iteration 87650, Loss: 0.000000267\n",
      "Iteration 87660, Loss: 0.000000250\n",
      "Iteration 87670, Loss: 0.000000249\n",
      "Iteration 87680, Loss: 0.000000247\n",
      "Iteration 87690, Loss: 0.000000246\n",
      "Iteration 87700, Loss: 0.000000246\n",
      "Iteration 87710, Loss: 0.000000247\n",
      "Iteration 87720, Loss: 0.000000304\n",
      "Iteration 87730, Loss: 0.000002050\n",
      "Iteration 87740, Loss: 0.000000756\n",
      "Iteration 87750, Loss: 0.000000278\n",
      "Iteration 87760, Loss: 0.000000322\n",
      "Iteration 87770, Loss: 0.000000258\n",
      "Iteration 87780, Loss: 0.000000254\n",
      "Iteration 87790, Loss: 0.000000256\n",
      "Iteration 87800, Loss: 0.000000359\n",
      "Iteration 87810, Loss: 0.000001000\n",
      "Iteration 87820, Loss: 0.000000654\n",
      "Iteration 87830, Loss: 0.000000273\n",
      "Iteration 87840, Loss: 0.000000313\n",
      "Iteration 87850, Loss: 0.000000317\n",
      "Iteration 87860, Loss: 0.000000388\n",
      "Iteration 87870, Loss: 0.000000691\n",
      "Iteration 87880, Loss: 0.000000338\n",
      "Iteration 87890, Loss: 0.000000329\n",
      "Iteration 87900, Loss: 0.000000287\n",
      "Iteration 87910, Loss: 0.000000303\n",
      "Iteration 87920, Loss: 0.000000429\n",
      "Iteration 87930, Loss: 0.000001261\n",
      "Iteration 87940, Loss: 0.000000665\n",
      "Iteration 87950, Loss: 0.000000346\n",
      "Iteration 87960, Loss: 0.000000304\n",
      "Iteration 87970, Loss: 0.000000278\n",
      "Iteration 87980, Loss: 0.000000269\n",
      "Iteration 87990, Loss: 0.000000263\n",
      "Iteration 88000, Loss: 0.000000311\n",
      "Iteration 88010, Loss: 0.000000523\n",
      "Iteration 88020, Loss: 0.000001022\n",
      "Iteration 88030, Loss: 0.000000676\n",
      "Iteration 88040, Loss: 0.000000374\n",
      "Iteration 88050, Loss: 0.000000284\n",
      "Iteration 88060, Loss: 0.000000273\n",
      "Iteration 88070, Loss: 0.000000251\n",
      "Iteration 88080, Loss: 0.000000248\n",
      "Iteration 88090, Loss: 0.000000258\n",
      "Iteration 88100, Loss: 0.000000549\n",
      "Iteration 88110, Loss: 0.000001898\n",
      "Iteration 88120, Loss: 0.000000350\n",
      "Iteration 88130, Loss: 0.000000483\n",
      "Iteration 88140, Loss: 0.000000259\n",
      "Iteration 88150, Loss: 0.000000276\n",
      "Iteration 88160, Loss: 0.000000249\n",
      "Iteration 88170, Loss: 0.000000248\n",
      "Iteration 88180, Loss: 0.000000248\n",
      "Iteration 88190, Loss: 0.000000299\n",
      "Iteration 88200, Loss: 0.000000755\n",
      "Iteration 88210, Loss: 0.000001092\n",
      "Iteration 88220, Loss: 0.000000556\n",
      "Iteration 88230, Loss: 0.000000366\n",
      "Iteration 88240, Loss: 0.000000297\n",
      "Iteration 88250, Loss: 0.000000267\n",
      "Iteration 88260, Loss: 0.000000252\n",
      "Iteration 88270, Loss: 0.000000247\n",
      "Iteration 88280, Loss: 0.000000247\n",
      "Iteration 88290, Loss: 0.000000256\n",
      "Iteration 88300, Loss: 0.000000715\n",
      "Iteration 88310, Loss: 0.000000505\n",
      "Iteration 88320, Loss: 0.000000572\n",
      "Iteration 88330, Loss: 0.000000251\n",
      "Iteration 88340, Loss: 0.000000312\n",
      "Iteration 88350, Loss: 0.000000393\n",
      "Iteration 88360, Loss: 0.000000834\n",
      "Iteration 88370, Loss: 0.000000259\n",
      "Iteration 88380, Loss: 0.000000360\n",
      "Iteration 88390, Loss: 0.000000248\n",
      "Iteration 88400, Loss: 0.000000285\n",
      "Iteration 88410, Loss: 0.000000357\n",
      "Iteration 88420, Loss: 0.000001307\n",
      "Iteration 88430, Loss: 0.000000582\n",
      "Iteration 88440, Loss: 0.000000439\n",
      "Iteration 88450, Loss: 0.000000706\n",
      "Iteration 88460, Loss: 0.000000539\n",
      "Iteration 88470, Loss: 0.000000355\n",
      "Iteration 88480, Loss: 0.000000275\n",
      "Iteration 88490, Loss: 0.000000265\n",
      "Iteration 88500, Loss: 0.000000299\n",
      "Iteration 88510, Loss: 0.000000474\n",
      "Iteration 88520, Loss: 0.000000909\n",
      "Iteration 88530, Loss: 0.000000301\n",
      "Iteration 88540, Loss: 0.000000371\n",
      "Iteration 88550, Loss: 0.000000469\n",
      "Iteration 88560, Loss: 0.000000293\n",
      "Iteration 88570, Loss: 0.000000275\n",
      "Iteration 88580, Loss: 0.000000305\n",
      "Iteration 88590, Loss: 0.000000571\n",
      "Iteration 88600, Loss: 0.000001283\n",
      "Iteration 88610, Loss: 0.000000595\n",
      "Iteration 88620, Loss: 0.000000369\n",
      "Iteration 88630, Loss: 0.000000302\n",
      "Iteration 88640, Loss: 0.000000270\n",
      "Iteration 88650, Loss: 0.000000361\n",
      "Iteration 88660, Loss: 0.000000766\n",
      "Iteration 88670, Loss: 0.000000637\n",
      "Iteration 88680, Loss: 0.000000523\n",
      "Iteration 88690, Loss: 0.000000329\n",
      "Iteration 88700, Loss: 0.000000334\n",
      "Iteration 88710, Loss: 0.000000276\n",
      "Iteration 88720, Loss: 0.000000263\n",
      "Iteration 88730, Loss: 0.000000356\n",
      "Iteration 88740, Loss: 0.000001416\n",
      "Iteration 88750, Loss: 0.000000436\n",
      "Iteration 88760, Loss: 0.000000319\n",
      "Iteration 88770, Loss: 0.000000300\n",
      "Iteration 88780, Loss: 0.000000555\n",
      "Iteration 88790, Loss: 0.000000361\n",
      "Iteration 88800, Loss: 0.000000357\n",
      "Iteration 88810, Loss: 0.000000274\n",
      "Iteration 88820, Loss: 0.000000253\n",
      "Iteration 88830, Loss: 0.000000271\n",
      "Iteration 88840, Loss: 0.000000388\n",
      "Iteration 88850, Loss: 0.000000829\n",
      "Iteration 88860, Loss: 0.000001176\n",
      "Iteration 88870, Loss: 0.000000390\n",
      "Iteration 88880, Loss: 0.000000401\n",
      "Iteration 88890, Loss: 0.000000269\n",
      "Iteration 88900, Loss: 0.000000264\n",
      "Iteration 88910, Loss: 0.000000263\n",
      "Iteration 88920, Loss: 0.000000338\n",
      "Iteration 88930, Loss: 0.000001169\n",
      "Iteration 88940, Loss: 0.000000277\n",
      "Iteration 88950, Loss: 0.000000263\n",
      "Iteration 88960, Loss: 0.000000275\n",
      "Iteration 88970, Loss: 0.000000270\n",
      "Iteration 88980, Loss: 0.000000248\n",
      "Iteration 88990, Loss: 0.000000261\n",
      "Iteration 89000, Loss: 0.000000335\n",
      "Iteration 89010, Loss: 0.000000500\n",
      "Iteration 89020, Loss: 0.000000707\n",
      "Iteration 89030, Loss: 0.000000545\n",
      "Iteration 89040, Loss: 0.000001619\n",
      "Iteration 89050, Loss: 0.000000490\n",
      "Iteration 89060, Loss: 0.000000320\n",
      "Iteration 89070, Loss: 0.000000267\n",
      "Iteration 89080, Loss: 0.000000253\n",
      "Iteration 89090, Loss: 0.000000252\n",
      "Iteration 89100, Loss: 0.000000253\n",
      "Iteration 89110, Loss: 0.000000280\n",
      "Iteration 89120, Loss: 0.000001070\n",
      "Iteration 89130, Loss: 0.000000419\n",
      "Iteration 89140, Loss: 0.000000339\n",
      "Iteration 89150, Loss: 0.000000275\n",
      "Iteration 89160, Loss: 0.000000321\n",
      "Iteration 89170, Loss: 0.000001147\n",
      "Iteration 89180, Loss: 0.000000259\n",
      "Iteration 89190, Loss: 0.000000256\n",
      "Iteration 89200, Loss: 0.000000264\n",
      "Iteration 89210, Loss: 0.000000268\n",
      "Iteration 89220, Loss: 0.000000254\n",
      "Iteration 89230, Loss: 0.000000248\n",
      "Iteration 89240, Loss: 0.000000310\n",
      "Iteration 89250, Loss: 0.000001345\n",
      "Iteration 89260, Loss: 0.000000613\n",
      "Iteration 89270, Loss: 0.000000473\n",
      "Iteration 89280, Loss: 0.000000490\n",
      "Iteration 89290, Loss: 0.000000349\n",
      "Iteration 89300, Loss: 0.000000255\n",
      "Iteration 89310, Loss: 0.000000247\n",
      "Iteration 89320, Loss: 0.000000272\n",
      "Iteration 89330, Loss: 0.000001300\n",
      "Iteration 89340, Loss: 0.000000337\n",
      "Iteration 89350, Loss: 0.000000481\n",
      "Iteration 89360, Loss: 0.000000487\n",
      "Iteration 89370, Loss: 0.000000336\n",
      "Iteration 89380, Loss: 0.000000260\n",
      "Iteration 89390, Loss: 0.000000247\n",
      "Iteration 89400, Loss: 0.000000276\n",
      "Iteration 89410, Loss: 0.000000520\n",
      "Iteration 89420, Loss: 0.000000659\n",
      "Iteration 89430, Loss: 0.000000330\n",
      "Iteration 89440, Loss: 0.000000285\n",
      "Iteration 89450, Loss: 0.000000254\n",
      "Iteration 89460, Loss: 0.000000250\n",
      "Iteration 89470, Loss: 0.000000255\n",
      "Iteration 89480, Loss: 0.000000356\n",
      "Iteration 89490, Loss: 0.000001243\n",
      "Iteration 89500, Loss: 0.000000659\n",
      "Iteration 89510, Loss: 0.000000340\n",
      "Iteration 89520, Loss: 0.000000290\n",
      "Iteration 89530, Loss: 0.000000264\n",
      "Iteration 89540, Loss: 0.000000311\n",
      "Iteration 89550, Loss: 0.000000758\n",
      "Iteration 89560, Loss: 0.000000888\n",
      "Iteration 89570, Loss: 0.000000338\n",
      "Iteration 89580, Loss: 0.000000380\n",
      "Iteration 89590, Loss: 0.000000276\n",
      "Iteration 89600, Loss: 0.000000265\n",
      "Iteration 89610, Loss: 0.000000277\n",
      "Iteration 89620, Loss: 0.000000447\n",
      "Iteration 89630, Loss: 0.000001187\n",
      "Iteration 89640, Loss: 0.000000449\n",
      "Iteration 89650, Loss: 0.000000309\n",
      "Iteration 89660, Loss: 0.000000358\n",
      "Iteration 89670, Loss: 0.000000449\n",
      "Iteration 89680, Loss: 0.000000339\n",
      "Iteration 89690, Loss: 0.000000411\n",
      "Iteration 89700, Loss: 0.000000323\n",
      "Iteration 89710, Loss: 0.000000304\n",
      "Iteration 89720, Loss: 0.000000632\n",
      "Iteration 89730, Loss: 0.000001084\n",
      "Iteration 89740, Loss: 0.000000474\n",
      "Iteration 89750, Loss: 0.000000279\n",
      "Iteration 89760, Loss: 0.000000254\n",
      "Iteration 89770, Loss: 0.000000257\n",
      "Iteration 89780, Loss: 0.000000311\n",
      "Iteration 89790, Loss: 0.000001062\n",
      "Iteration 89800, Loss: 0.000000392\n",
      "Iteration 89810, Loss: 0.000000339\n",
      "Iteration 89820, Loss: 0.000000271\n",
      "Iteration 89830, Loss: 0.000000258\n",
      "Iteration 89840, Loss: 0.000000272\n",
      "Iteration 89850, Loss: 0.000001352\n",
      "Iteration 89860, Loss: 0.000000866\n",
      "Iteration 89870, Loss: 0.000000306\n",
      "Iteration 89880, Loss: 0.000000341\n",
      "Iteration 89890, Loss: 0.000000363\n",
      "Iteration 89900, Loss: 0.000000500\n",
      "Iteration 89910, Loss: 0.000000351\n",
      "Iteration 89920, Loss: 0.000000245\n",
      "Iteration 89930, Loss: 0.000000287\n",
      "Iteration 89940, Loss: 0.000000577\n",
      "Iteration 89950, Loss: 0.000000861\n",
      "Iteration 89960, Loss: 0.000000500\n",
      "Iteration 89970, Loss: 0.000000719\n",
      "Iteration 89980, Loss: 0.000000316\n",
      "Iteration 89990, Loss: 0.000000296\n",
      "Iteration 90000, Loss: 0.000000281\n",
      "Iteration 90010, Loss: 0.000000257\n",
      "Iteration 90020, Loss: 0.000000270\n",
      "Iteration 90030, Loss: 0.000000781\n",
      "Iteration 90040, Loss: 0.000000595\n",
      "Iteration 90050, Loss: 0.000000295\n",
      "Iteration 90060, Loss: 0.000000255\n",
      "Iteration 90070, Loss: 0.000000255\n",
      "Iteration 90080, Loss: 0.000000262\n",
      "Iteration 90090, Loss: 0.000000315\n",
      "Iteration 90100, Loss: 0.000000934\n",
      "Iteration 90110, Loss: 0.000000426\n",
      "Iteration 90120, Loss: 0.000000404\n",
      "Iteration 90130, Loss: 0.000000284\n",
      "Iteration 90140, Loss: 0.000000261\n",
      "Iteration 90150, Loss: 0.000000253\n",
      "Iteration 90160, Loss: 0.000000273\n",
      "Iteration 90170, Loss: 0.000000577\n",
      "Iteration 90180, Loss: 0.000001074\n",
      "Iteration 90190, Loss: 0.000000566\n",
      "Iteration 90200, Loss: 0.000000346\n",
      "Iteration 90210, Loss: 0.000000270\n",
      "Iteration 90220, Loss: 0.000000247\n",
      "Iteration 90230, Loss: 0.000000286\n",
      "Iteration 90240, Loss: 0.000001391\n",
      "Iteration 90250, Loss: 0.000000823\n",
      "Iteration 90260, Loss: 0.000000445\n",
      "Iteration 90270, Loss: 0.000000308\n",
      "Iteration 90280, Loss: 0.000000274\n",
      "Iteration 90290, Loss: 0.000000249\n",
      "Iteration 90300, Loss: 0.000000250\n",
      "Iteration 90310, Loss: 0.000000270\n",
      "Iteration 90320, Loss: 0.000000701\n",
      "Iteration 90330, Loss: 0.000000824\n",
      "Iteration 90340, Loss: 0.000000399\n",
      "Iteration 90350, Loss: 0.000000271\n",
      "Iteration 90360, Loss: 0.000000252\n",
      "Iteration 90370, Loss: 0.000000250\n",
      "Iteration 90380, Loss: 0.000000251\n",
      "Iteration 90390, Loss: 0.000000312\n",
      "Iteration 90400, Loss: 0.000001674\n",
      "Iteration 90410, Loss: 0.000000688\n",
      "Iteration 90420, Loss: 0.000000299\n",
      "Iteration 90430, Loss: 0.000000276\n",
      "Iteration 90440, Loss: 0.000000266\n",
      "Iteration 90450, Loss: 0.000000258\n",
      "Iteration 90460, Loss: 0.000000314\n",
      "Iteration 90470, Loss: 0.000001261\n",
      "Iteration 90480, Loss: 0.000000399\n",
      "Iteration 90490, Loss: 0.000000324\n",
      "Iteration 90500, Loss: 0.000000300\n",
      "Iteration 90510, Loss: 0.000000272\n",
      "Iteration 90520, Loss: 0.000000252\n",
      "Iteration 90530, Loss: 0.000000244\n",
      "Iteration 90540, Loss: 0.000000247\n",
      "Iteration 90550, Loss: 0.000000336\n",
      "Iteration 90560, Loss: 0.000001103\n",
      "Iteration 90570, Loss: 0.000000339\n",
      "Iteration 90580, Loss: 0.000000662\n",
      "Iteration 90590, Loss: 0.000001106\n",
      "Iteration 90600, Loss: 0.000000775\n",
      "Iteration 90610, Loss: 0.000000487\n",
      "Iteration 90620, Loss: 0.000000314\n",
      "Iteration 90630, Loss: 0.000000254\n",
      "Iteration 90640, Loss: 0.000000248\n",
      "Iteration 90650, Loss: 0.000000247\n",
      "Iteration 90660, Loss: 0.000000246\n",
      "Iteration 90670, Loss: 0.000000274\n",
      "Iteration 90680, Loss: 0.000000896\n",
      "Iteration 90690, Loss: 0.000000408\n",
      "Iteration 90700, Loss: 0.000000406\n",
      "Iteration 90710, Loss: 0.000000364\n",
      "Iteration 90720, Loss: 0.000000545\n",
      "Iteration 90730, Loss: 0.000000643\n",
      "Iteration 90740, Loss: 0.000000286\n",
      "Iteration 90750, Loss: 0.000000267\n",
      "Iteration 90760, Loss: 0.000000308\n",
      "Iteration 90770, Loss: 0.000000629\n",
      "Iteration 90780, Loss: 0.000000539\n",
      "Iteration 90790, Loss: 0.000000412\n",
      "Iteration 90800, Loss: 0.000000298\n",
      "Iteration 90810, Loss: 0.000000415\n",
      "Iteration 90820, Loss: 0.000000588\n",
      "Iteration 90830, Loss: 0.000000287\n",
      "Iteration 90840, Loss: 0.000000316\n",
      "Iteration 90850, Loss: 0.000000442\n",
      "Iteration 90860, Loss: 0.000000814\n",
      "Iteration 90870, Loss: 0.000000409\n",
      "Iteration 90880, Loss: 0.000000343\n",
      "Iteration 90890, Loss: 0.000000287\n",
      "Iteration 90900, Loss: 0.000000311\n",
      "Iteration 90910, Loss: 0.000000623\n",
      "Iteration 90920, Loss: 0.000000804\n",
      "Iteration 90930, Loss: 0.000000543\n",
      "Iteration 90940, Loss: 0.000000418\n",
      "Iteration 90950, Loss: 0.000000294\n",
      "Iteration 90960, Loss: 0.000000266\n",
      "Iteration 90970, Loss: 0.000000276\n",
      "Iteration 90980, Loss: 0.000000439\n",
      "Iteration 90990, Loss: 0.000000843\n",
      "Iteration 91000, Loss: 0.000001144\n",
      "Iteration 91010, Loss: 0.000000358\n",
      "Iteration 91020, Loss: 0.000000304\n",
      "Iteration 91030, Loss: 0.000000284\n",
      "Iteration 91040, Loss: 0.000000251\n",
      "Iteration 91050, Loss: 0.000000250\n",
      "Iteration 91060, Loss: 0.000000350\n",
      "Iteration 91070, Loss: 0.000000569\n",
      "Iteration 91080, Loss: 0.000000762\n",
      "Iteration 91090, Loss: 0.000000377\n",
      "Iteration 91100, Loss: 0.000000275\n",
      "Iteration 91110, Loss: 0.000000321\n",
      "Iteration 91120, Loss: 0.000000441\n",
      "Iteration 91130, Loss: 0.000000468\n",
      "Iteration 91140, Loss: 0.000000274\n",
      "Iteration 91150, Loss: 0.000000290\n",
      "Iteration 91160, Loss: 0.000000736\n",
      "Iteration 91170, Loss: 0.000000417\n",
      "Iteration 91180, Loss: 0.000000692\n",
      "Iteration 91190, Loss: 0.000000335\n",
      "Iteration 91200, Loss: 0.000000320\n",
      "Iteration 91210, Loss: 0.000000342\n",
      "Iteration 91220, Loss: 0.000000301\n",
      "Iteration 91230, Loss: 0.000000277\n",
      "Iteration 91240, Loss: 0.000000728\n",
      "Iteration 91250, Loss: 0.000000706\n",
      "Iteration 91260, Loss: 0.000000453\n",
      "Iteration 91270, Loss: 0.000000401\n",
      "Iteration 91280, Loss: 0.000000499\n",
      "Iteration 91290, Loss: 0.000000348\n",
      "Iteration 91300, Loss: 0.000000275\n",
      "Iteration 91310, Loss: 0.000000253\n",
      "Iteration 91320, Loss: 0.000000268\n",
      "Iteration 91330, Loss: 0.000000578\n",
      "Iteration 91340, Loss: 0.000000930\n",
      "Iteration 91350, Loss: 0.000000901\n",
      "Iteration 91360, Loss: 0.000000354\n",
      "Iteration 91370, Loss: 0.000000280\n",
      "Iteration 91380, Loss: 0.000000255\n",
      "Iteration 91390, Loss: 0.000000270\n",
      "Iteration 91400, Loss: 0.000000307\n",
      "Iteration 91410, Loss: 0.000000535\n",
      "Iteration 91420, Loss: 0.000000435\n",
      "Iteration 91430, Loss: 0.000000536\n",
      "Iteration 91440, Loss: 0.000000714\n",
      "Iteration 91450, Loss: 0.000000327\n",
      "Iteration 91460, Loss: 0.000000285\n",
      "Iteration 91470, Loss: 0.000000334\n",
      "Iteration 91480, Loss: 0.000000441\n",
      "Iteration 91490, Loss: 0.000000618\n",
      "Iteration 91500, Loss: 0.000000309\n",
      "Iteration 91510, Loss: 0.000000567\n",
      "Iteration 91520, Loss: 0.000000420\n",
      "Iteration 91530, Loss: 0.000000308\n",
      "Iteration 91540, Loss: 0.000000318\n",
      "Iteration 91550, Loss: 0.000001157\n",
      "Iteration 91560, Loss: 0.000000400\n",
      "Iteration 91570, Loss: 0.000000372\n",
      "Iteration 91580, Loss: 0.000000306\n",
      "Iteration 91590, Loss: 0.000000274\n",
      "Iteration 91600, Loss: 0.000000263\n",
      "Iteration 91610, Loss: 0.000000260\n",
      "Iteration 91620, Loss: 0.000000307\n",
      "Iteration 91630, Loss: 0.000000598\n",
      "Iteration 91640, Loss: 0.000000307\n",
      "Iteration 91650, Loss: 0.000000988\n",
      "Iteration 91660, Loss: 0.000000376\n",
      "Iteration 91670, Loss: 0.000000344\n",
      "Iteration 91680, Loss: 0.000000288\n",
      "Iteration 91690, Loss: 0.000000253\n",
      "Iteration 91700, Loss: 0.000000250\n",
      "Iteration 91710, Loss: 0.000000324\n",
      "Iteration 91720, Loss: 0.000000415\n",
      "Iteration 91730, Loss: 0.000000623\n",
      "Iteration 91740, Loss: 0.000000890\n",
      "Iteration 91750, Loss: 0.000000511\n",
      "Iteration 91760, Loss: 0.000000293\n",
      "Iteration 91770, Loss: 0.000000267\n",
      "Iteration 91780, Loss: 0.000000258\n",
      "Iteration 91790, Loss: 0.000000310\n",
      "Iteration 91800, Loss: 0.000000897\n",
      "Iteration 91810, Loss: 0.000000575\n",
      "Iteration 91820, Loss: 0.000000413\n",
      "Iteration 91830, Loss: 0.000000441\n",
      "Iteration 91840, Loss: 0.000000460\n",
      "Iteration 91850, Loss: 0.000000388\n",
      "Iteration 91860, Loss: 0.000000270\n",
      "Iteration 91870, Loss: 0.000000307\n",
      "Iteration 91880, Loss: 0.000000453\n",
      "Iteration 91890, Loss: 0.000000996\n",
      "Iteration 91900, Loss: 0.000000828\n",
      "Iteration 91910, Loss: 0.000000437\n",
      "Iteration 91920, Loss: 0.000000316\n",
      "Iteration 91930, Loss: 0.000000284\n",
      "Iteration 91940, Loss: 0.000000251\n",
      "Iteration 91950, Loss: 0.000000248\n",
      "Iteration 91960, Loss: 0.000000256\n",
      "Iteration 91970, Loss: 0.000000415\n",
      "Iteration 91980, Loss: 0.000001348\n",
      "Iteration 91990, Loss: 0.000000540\n",
      "Iteration 92000, Loss: 0.000000353\n",
      "Iteration 92010, Loss: 0.000000306\n",
      "Iteration 92020, Loss: 0.000000348\n",
      "Iteration 92030, Loss: 0.000000973\n",
      "Iteration 92040, Loss: 0.000000468\n",
      "Iteration 92050, Loss: 0.000000311\n",
      "Iteration 92060, Loss: 0.000000262\n",
      "Iteration 92070, Loss: 0.000000255\n",
      "Iteration 92080, Loss: 0.000000287\n",
      "Iteration 92090, Loss: 0.000001222\n",
      "Iteration 92100, Loss: 0.000000289\n",
      "Iteration 92110, Loss: 0.000000300\n",
      "Iteration 92120, Loss: 0.000000289\n",
      "Iteration 92130, Loss: 0.000000265\n",
      "Iteration 92140, Loss: 0.000000257\n",
      "Iteration 92150, Loss: 0.000000330\n",
      "Iteration 92160, Loss: 0.000000984\n",
      "Iteration 92170, Loss: 0.000000479\n",
      "Iteration 92180, Loss: 0.000000329\n",
      "Iteration 92190, Loss: 0.000000270\n",
      "Iteration 92200, Loss: 0.000000251\n",
      "Iteration 92210, Loss: 0.000000256\n",
      "Iteration 92220, Loss: 0.000000710\n",
      "Iteration 92230, Loss: 0.000000335\n",
      "Iteration 92240, Loss: 0.000000475\n",
      "Iteration 92250, Loss: 0.000002256\n",
      "Iteration 92260, Loss: 0.000000832\n",
      "Iteration 92270, Loss: 0.000000709\n",
      "Iteration 92280, Loss: 0.000000543\n",
      "Iteration 92290, Loss: 0.000000309\n",
      "Iteration 92300, Loss: 0.000000249\n",
      "Iteration 92310, Loss: 0.000000242\n",
      "Iteration 92320, Loss: 0.000000241\n",
      "Iteration 92330, Loss: 0.000000238\n",
      "Iteration 92340, Loss: 0.000000238\n",
      "Iteration 92350, Loss: 0.000000238\n",
      "Iteration 92360, Loss: 0.000000254\n",
      "Iteration 92370, Loss: 0.000000487\n",
      "Iteration 92380, Loss: 0.000000836\n",
      "Iteration 92390, Loss: 0.000000556\n",
      "Iteration 92400, Loss: 0.000000302\n",
      "Iteration 92410, Loss: 0.000000331\n",
      "Iteration 92420, Loss: 0.000000779\n",
      "Iteration 92430, Loss: 0.000000475\n",
      "Iteration 92440, Loss: 0.000000444\n",
      "Iteration 92450, Loss: 0.000000295\n",
      "Iteration 92460, Loss: 0.000000248\n",
      "Iteration 92470, Loss: 0.000000317\n",
      "Iteration 92480, Loss: 0.000000686\n",
      "Iteration 92490, Loss: 0.000000428\n",
      "Iteration 92500, Loss: 0.000000485\n",
      "Iteration 92510, Loss: 0.000000287\n",
      "Iteration 92520, Loss: 0.000000258\n",
      "Iteration 92530, Loss: 0.000000280\n",
      "Iteration 92540, Loss: 0.000000722\n",
      "Iteration 92550, Loss: 0.000000703\n",
      "Iteration 92560, Loss: 0.000000466\n",
      "Iteration 92570, Loss: 0.000000373\n",
      "Iteration 92580, Loss: 0.000000362\n",
      "Iteration 92590, Loss: 0.000000450\n",
      "Iteration 92600, Loss: 0.000000273\n",
      "Iteration 92610, Loss: 0.000000289\n",
      "Iteration 92620, Loss: 0.000000307\n",
      "Iteration 92630, Loss: 0.000001010\n",
      "Iteration 92640, Loss: 0.000000473\n",
      "Iteration 92650, Loss: 0.000000363\n",
      "Iteration 92660, Loss: 0.000000309\n",
      "Iteration 92670, Loss: 0.000000612\n",
      "Iteration 92680, Loss: 0.000000926\n",
      "Iteration 92690, Loss: 0.000000535\n",
      "Iteration 92700, Loss: 0.000000348\n",
      "Iteration 92710, Loss: 0.000000275\n",
      "Iteration 92720, Loss: 0.000000322\n",
      "Iteration 92730, Loss: 0.000000273\n",
      "Iteration 92740, Loss: 0.000000302\n",
      "Iteration 92750, Loss: 0.000000728\n",
      "Iteration 92760, Loss: 0.000000398\n",
      "Iteration 92770, Loss: 0.000000467\n",
      "Iteration 92780, Loss: 0.000000582\n",
      "Iteration 92790, Loss: 0.000000297\n",
      "Iteration 92800, Loss: 0.000000376\n",
      "Iteration 92810, Loss: 0.000000413\n",
      "Iteration 92820, Loss: 0.000000440\n",
      "Iteration 92830, Loss: 0.000000844\n",
      "Iteration 92840, Loss: 0.000000635\n",
      "Iteration 92850, Loss: 0.000000282\n",
      "Iteration 92860, Loss: 0.000000280\n",
      "Iteration 92870, Loss: 0.000000264\n",
      "Iteration 92880, Loss: 0.000000254\n",
      "Iteration 92890, Loss: 0.000000332\n",
      "Iteration 92900, Loss: 0.000001241\n",
      "Iteration 92910, Loss: 0.000000303\n",
      "Iteration 92920, Loss: 0.000000296\n",
      "Iteration 92930, Loss: 0.000000265\n",
      "Iteration 92940, Loss: 0.000000270\n",
      "Iteration 92950, Loss: 0.000000261\n",
      "Iteration 92960, Loss: 0.000000341\n",
      "Iteration 92970, Loss: 0.000001108\n",
      "Iteration 92980, Loss: 0.000000821\n",
      "Iteration 92990, Loss: 0.000000320\n",
      "Iteration 93000, Loss: 0.000000299\n",
      "Iteration 93010, Loss: 0.000000346\n",
      "Iteration 93020, Loss: 0.000000601\n",
      "Iteration 93030, Loss: 0.000000509\n",
      "Iteration 93040, Loss: 0.000000362\n",
      "Iteration 93050, Loss: 0.000000335\n",
      "Iteration 93060, Loss: 0.000000247\n",
      "Iteration 93070, Loss: 0.000000248\n",
      "Iteration 93080, Loss: 0.000000306\n",
      "Iteration 93090, Loss: 0.000001450\n",
      "Iteration 93100, Loss: 0.000000689\n",
      "Iteration 93110, Loss: 0.000000416\n",
      "Iteration 93120, Loss: 0.000000347\n",
      "Iteration 93130, Loss: 0.000000276\n",
      "Iteration 93140, Loss: 0.000000251\n",
      "Iteration 93150, Loss: 0.000000245\n",
      "Iteration 93160, Loss: 0.000000294\n",
      "Iteration 93170, Loss: 0.000001099\n",
      "Iteration 93180, Loss: 0.000000687\n",
      "Iteration 93190, Loss: 0.000000327\n",
      "Iteration 93200, Loss: 0.000000268\n",
      "Iteration 93210, Loss: 0.000000245\n",
      "Iteration 93220, Loss: 0.000000246\n",
      "Iteration 93230, Loss: 0.000000327\n",
      "Iteration 93240, Loss: 0.000002281\n",
      "Iteration 93250, Loss: 0.000001123\n",
      "Iteration 93260, Loss: 0.000000410\n",
      "Iteration 93270, Loss: 0.000000261\n",
      "Iteration 93280, Loss: 0.000000275\n",
      "Iteration 93290, Loss: 0.000000247\n",
      "Iteration 93300, Loss: 0.000000239\n",
      "Iteration 93310, Loss: 0.000000244\n",
      "Iteration 93320, Loss: 0.000000411\n",
      "Iteration 93330, Loss: 0.000001540\n",
      "Iteration 93340, Loss: 0.000000593\n",
      "Iteration 93350, Loss: 0.000000342\n",
      "Iteration 93360, Loss: 0.000000277\n",
      "Iteration 93370, Loss: 0.000000248\n",
      "Iteration 93380, Loss: 0.000000240\n",
      "Iteration 93390, Loss: 0.000000238\n",
      "Iteration 93400, Loss: 0.000000237\n",
      "Iteration 93410, Loss: 0.000000242\n",
      "Iteration 93420, Loss: 0.000000418\n",
      "Iteration 93430, Loss: 0.000001340\n",
      "Iteration 93440, Loss: 0.000000730\n",
      "Iteration 93450, Loss: 0.000000441\n",
      "Iteration 93460, Loss: 0.000000351\n",
      "Iteration 93470, Loss: 0.000000262\n",
      "Iteration 93480, Loss: 0.000000244\n",
      "Iteration 93490, Loss: 0.000000242\n",
      "Iteration 93500, Loss: 0.000000237\n",
      "Iteration 93510, Loss: 0.000000237\n",
      "Iteration 93520, Loss: 0.000000240\n",
      "Iteration 93530, Loss: 0.000000375\n",
      "Iteration 93540, Loss: 0.000001803\n",
      "Iteration 93550, Loss: 0.000000530\n",
      "Iteration 93560, Loss: 0.000000294\n",
      "Iteration 93570, Loss: 0.000000298\n",
      "Iteration 93580, Loss: 0.000000257\n",
      "Iteration 93590, Loss: 0.000000251\n",
      "Iteration 93600, Loss: 0.000000316\n",
      "Iteration 93610, Loss: 0.000001278\n",
      "Iteration 93620, Loss: 0.000000318\n",
      "Iteration 93630, Loss: 0.000000264\n",
      "Iteration 93640, Loss: 0.000000244\n",
      "Iteration 93650, Loss: 0.000000238\n",
      "Iteration 93660, Loss: 0.000000243\n",
      "Iteration 93670, Loss: 0.000000266\n",
      "Iteration 93680, Loss: 0.000000688\n",
      "Iteration 93690, Loss: 0.000000282\n",
      "Iteration 93700, Loss: 0.000000287\n",
      "Iteration 93710, Loss: 0.000000305\n",
      "Iteration 93720, Loss: 0.000000858\n",
      "Iteration 93730, Loss: 0.000000425\n",
      "Iteration 93740, Loss: 0.000000310\n",
      "Iteration 93750, Loss: 0.000000266\n",
      "Iteration 93760, Loss: 0.000000255\n",
      "Iteration 93770, Loss: 0.000000249\n",
      "Iteration 93780, Loss: 0.000000241\n",
      "Iteration 93790, Loss: 0.000000303\n",
      "Iteration 93800, Loss: 0.000001825\n",
      "Iteration 93810, Loss: 0.000000632\n",
      "Iteration 93820, Loss: 0.000000265\n",
      "Iteration 93830, Loss: 0.000000340\n",
      "Iteration 93840, Loss: 0.000000619\n",
      "Iteration 93850, Loss: 0.000000548\n",
      "Iteration 93860, Loss: 0.000000417\n",
      "Iteration 93870, Loss: 0.000000253\n",
      "Iteration 93880, Loss: 0.000000256\n",
      "Iteration 93890, Loss: 0.000000244\n",
      "Iteration 93900, Loss: 0.000000342\n",
      "Iteration 93910, Loss: 0.000000758\n",
      "Iteration 93920, Loss: 0.000001358\n",
      "Iteration 93930, Loss: 0.000000449\n",
      "Iteration 93940, Loss: 0.000000310\n",
      "Iteration 93950, Loss: 0.000000326\n",
      "Iteration 93960, Loss: 0.000000263\n",
      "Iteration 93970, Loss: 0.000000241\n",
      "Iteration 93980, Loss: 0.000000245\n",
      "Iteration 93990, Loss: 0.000000285\n",
      "Iteration 94000, Loss: 0.000000697\n",
      "Iteration 94010, Loss: 0.000000732\n",
      "Iteration 94020, Loss: 0.000000520\n",
      "Iteration 94030, Loss: 0.000000339\n",
      "Iteration 94040, Loss: 0.000000315\n",
      "Iteration 94050, Loss: 0.000000242\n",
      "Iteration 94060, Loss: 0.000000267\n",
      "Iteration 94070, Loss: 0.000000680\n",
      "Iteration 94080, Loss: 0.000000334\n",
      "Iteration 94090, Loss: 0.000000697\n",
      "Iteration 94100, Loss: 0.000000713\n",
      "Iteration 94110, Loss: 0.000000482\n",
      "Iteration 94120, Loss: 0.000000328\n",
      "Iteration 94130, Loss: 0.000000252\n",
      "Iteration 94140, Loss: 0.000000241\n",
      "Iteration 94150, Loss: 0.000000239\n",
      "Iteration 94160, Loss: 0.000000243\n",
      "Iteration 94170, Loss: 0.000000281\n",
      "Iteration 94180, Loss: 0.000000833\n",
      "Iteration 94190, Loss: 0.000000567\n",
      "Iteration 94200, Loss: 0.000000394\n",
      "Iteration 94210, Loss: 0.000000367\n",
      "Iteration 94220, Loss: 0.000000293\n",
      "Iteration 94230, Loss: 0.000000240\n",
      "Iteration 94240, Loss: 0.000000241\n",
      "Iteration 94250, Loss: 0.000000269\n",
      "Iteration 94260, Loss: 0.000001294\n",
      "Iteration 94270, Loss: 0.000000720\n",
      "Iteration 94280, Loss: 0.000000542\n",
      "Iteration 94290, Loss: 0.000000252\n",
      "Iteration 94300, Loss: 0.000000279\n",
      "Iteration 94310, Loss: 0.000000265\n",
      "Iteration 94320, Loss: 0.000000510\n",
      "Iteration 94330, Loss: 0.000000845\n",
      "Iteration 94340, Loss: 0.000000399\n",
      "Iteration 94350, Loss: 0.000000251\n",
      "Iteration 94360, Loss: 0.000000265\n",
      "Iteration 94370, Loss: 0.000000238\n",
      "Iteration 94380, Loss: 0.000000254\n",
      "Iteration 94390, Loss: 0.000000311\n",
      "Iteration 94400, Loss: 0.000000592\n",
      "Iteration 94410, Loss: 0.000001383\n",
      "Iteration 94420, Loss: 0.000000669\n",
      "Iteration 94430, Loss: 0.000000373\n",
      "Iteration 94440, Loss: 0.000000265\n",
      "Iteration 94450, Loss: 0.000000249\n",
      "Iteration 94460, Loss: 0.000000243\n",
      "Iteration 94470, Loss: 0.000000295\n",
      "Iteration 94480, Loss: 0.000001158\n",
      "Iteration 94490, Loss: 0.000000473\n",
      "Iteration 94500, Loss: 0.000000344\n",
      "Iteration 94510, Loss: 0.000000250\n",
      "Iteration 94520, Loss: 0.000000249\n",
      "Iteration 94530, Loss: 0.000000252\n",
      "Iteration 94540, Loss: 0.000000326\n",
      "Iteration 94550, Loss: 0.000001089\n",
      "Iteration 94560, Loss: 0.000000364\n",
      "Iteration 94570, Loss: 0.000000323\n",
      "Iteration 94580, Loss: 0.000000274\n",
      "Iteration 94590, Loss: 0.000000256\n",
      "Iteration 94600, Loss: 0.000000247\n",
      "Iteration 94610, Loss: 0.000000236\n",
      "Iteration 94620, Loss: 0.000000358\n",
      "Iteration 94630, Loss: 0.000001349\n",
      "Iteration 94640, Loss: 0.000000411\n",
      "Iteration 94650, Loss: 0.000000446\n",
      "Iteration 94660, Loss: 0.000000316\n",
      "Iteration 94670, Loss: 0.000000286\n",
      "Iteration 94680, Loss: 0.000000423\n",
      "Iteration 94690, Loss: 0.000000984\n",
      "Iteration 94700, Loss: 0.000000324\n",
      "Iteration 94710, Loss: 0.000000297\n",
      "Iteration 94720, Loss: 0.000000361\n",
      "Iteration 94730, Loss: 0.000000417\n",
      "Iteration 94740, Loss: 0.000000302\n",
      "Iteration 94750, Loss: 0.000000299\n",
      "Iteration 94760, Loss: 0.000000341\n",
      "Iteration 94770, Loss: 0.000000733\n",
      "Iteration 94780, Loss: 0.000000415\n",
      "Iteration 94790, Loss: 0.000000356\n",
      "Iteration 94800, Loss: 0.000000391\n",
      "Iteration 94810, Loss: 0.000000684\n",
      "Iteration 94820, Loss: 0.000000336\n",
      "Iteration 94830, Loss: 0.000000301\n",
      "Iteration 94840, Loss: 0.000000334\n",
      "Iteration 94850, Loss: 0.000001036\n",
      "Iteration 94860, Loss: 0.000000326\n",
      "Iteration 94870, Loss: 0.000000296\n",
      "Iteration 94880, Loss: 0.000000292\n",
      "Iteration 94890, Loss: 0.000000270\n",
      "Iteration 94900, Loss: 0.000000247\n",
      "Iteration 94910, Loss: 0.000000303\n",
      "Iteration 94920, Loss: 0.000000282\n",
      "Iteration 94930, Loss: 0.000000558\n",
      "Iteration 94940, Loss: 0.000000884\n",
      "Iteration 94950, Loss: 0.000000605\n",
      "Iteration 94960, Loss: 0.000000662\n",
      "Iteration 94970, Loss: 0.000000252\n",
      "Iteration 94980, Loss: 0.000000323\n",
      "Iteration 94990, Loss: 0.000000274\n",
      "Iteration 95000, Loss: 0.000000265\n",
      "Iteration 95010, Loss: 0.000000376\n",
      "Iteration 95020, Loss: 0.000000784\n",
      "Iteration 95030, Loss: 0.000000769\n",
      "Iteration 95040, Loss: 0.000000325\n",
      "Iteration 95050, Loss: 0.000000288\n",
      "Iteration 95060, Loss: 0.000000257\n",
      "Iteration 95070, Loss: 0.000000269\n",
      "Iteration 95080, Loss: 0.000000357\n",
      "Iteration 95090, Loss: 0.000001183\n",
      "Iteration 95100, Loss: 0.000000277\n",
      "Iteration 95110, Loss: 0.000000317\n",
      "Iteration 95120, Loss: 0.000000401\n",
      "Iteration 95130, Loss: 0.000000363\n",
      "Iteration 95140, Loss: 0.000000382\n",
      "Iteration 95150, Loss: 0.000000461\n",
      "Iteration 95160, Loss: 0.000000483\n",
      "Iteration 95170, Loss: 0.000000348\n",
      "Iteration 95180, Loss: 0.000000278\n",
      "Iteration 95190, Loss: 0.000000329\n",
      "Iteration 95200, Loss: 0.000001063\n",
      "Iteration 95210, Loss: 0.000000362\n",
      "Iteration 95220, Loss: 0.000000329\n",
      "Iteration 95230, Loss: 0.000000277\n",
      "Iteration 95240, Loss: 0.000000263\n",
      "Iteration 95250, Loss: 0.000000433\n",
      "Iteration 95260, Loss: 0.000000892\n",
      "Iteration 95270, Loss: 0.000000435\n",
      "Iteration 95280, Loss: 0.000000333\n",
      "Iteration 95290, Loss: 0.000000331\n",
      "Iteration 95300, Loss: 0.000000370\n",
      "Iteration 95310, Loss: 0.000000528\n",
      "Iteration 95320, Loss: 0.000001085\n",
      "Iteration 95330, Loss: 0.000000318\n",
      "Iteration 95340, Loss: 0.000000290\n",
      "Iteration 95350, Loss: 0.000000301\n",
      "Iteration 95360, Loss: 0.000000314\n",
      "Iteration 95370, Loss: 0.000000283\n",
      "Iteration 95380, Loss: 0.000000263\n",
      "Iteration 95390, Loss: 0.000000669\n",
      "Iteration 95400, Loss: 0.000000469\n",
      "Iteration 95410, Loss: 0.000000879\n",
      "Iteration 95420, Loss: 0.000000363\n",
      "Iteration 95430, Loss: 0.000000359\n",
      "Iteration 95440, Loss: 0.000000262\n",
      "Iteration 95450, Loss: 0.000000257\n",
      "Iteration 95460, Loss: 0.000000373\n",
      "Iteration 95470, Loss: 0.000000675\n",
      "Iteration 95480, Loss: 0.000000299\n",
      "Iteration 95490, Loss: 0.000000612\n",
      "Iteration 95500, Loss: 0.000000716\n",
      "Iteration 95510, Loss: 0.000000268\n",
      "Iteration 95520, Loss: 0.000000300\n",
      "Iteration 95530, Loss: 0.000000269\n",
      "Iteration 95540, Loss: 0.000000273\n",
      "Iteration 95550, Loss: 0.000000479\n",
      "Iteration 95560, Loss: 0.000000874\n",
      "Iteration 95570, Loss: 0.000000656\n",
      "Iteration 95580, Loss: 0.000000354\n",
      "Iteration 95590, Loss: 0.000000313\n",
      "Iteration 95600, Loss: 0.000000256\n",
      "Iteration 95610, Loss: 0.000000241\n",
      "Iteration 95620, Loss: 0.000000283\n",
      "Iteration 95630, Loss: 0.000000918\n",
      "Iteration 95640, Loss: 0.000000373\n",
      "Iteration 95650, Loss: 0.000000322\n",
      "Iteration 95660, Loss: 0.000000297\n",
      "Iteration 95670, Loss: 0.000000268\n",
      "Iteration 95680, Loss: 0.000000279\n",
      "Iteration 95690, Loss: 0.000000626\n",
      "Iteration 95700, Loss: 0.000000610\n",
      "Iteration 95710, Loss: 0.000000733\n",
      "Iteration 95720, Loss: 0.000000385\n",
      "Iteration 95730, Loss: 0.000000313\n",
      "Iteration 95740, Loss: 0.000000253\n",
      "Iteration 95750, Loss: 0.000000267\n",
      "Iteration 95760, Loss: 0.000000771\n",
      "Iteration 95770, Loss: 0.000000537\n",
      "Iteration 95780, Loss: 0.000000397\n",
      "Iteration 95790, Loss: 0.000000331\n",
      "Iteration 95800, Loss: 0.000000277\n",
      "Iteration 95810, Loss: 0.000000241\n",
      "Iteration 95820, Loss: 0.000000241\n",
      "Iteration 95830, Loss: 0.000000442\n",
      "Iteration 95840, Loss: 0.000000766\n",
      "Iteration 95850, Loss: 0.000000331\n",
      "Iteration 95860, Loss: 0.000000319\n",
      "Iteration 95870, Loss: 0.000000505\n",
      "Iteration 95880, Loss: 0.000000487\n",
      "Iteration 95890, Loss: 0.000000573\n",
      "Iteration 95900, Loss: 0.000000328\n",
      "Iteration 95910, Loss: 0.000000242\n",
      "Iteration 95920, Loss: 0.000000261\n",
      "Iteration 95930, Loss: 0.000000618\n",
      "Iteration 95940, Loss: 0.000000961\n",
      "Iteration 95950, Loss: 0.000000579\n",
      "Iteration 95960, Loss: 0.000000395\n",
      "Iteration 95970, Loss: 0.000000271\n",
      "Iteration 95980, Loss: 0.000000238\n",
      "Iteration 95990, Loss: 0.000000243\n",
      "Iteration 96000, Loss: 0.000000274\n",
      "Iteration 96010, Loss: 0.000001165\n",
      "Iteration 96020, Loss: 0.000000632\n",
      "Iteration 96030, Loss: 0.000000256\n",
      "Iteration 96040, Loss: 0.000000287\n",
      "Iteration 96050, Loss: 0.000000637\n",
      "Iteration 96060, Loss: 0.000000786\n",
      "Iteration 96070, Loss: 0.000000453\n",
      "Iteration 96080, Loss: 0.000000285\n",
      "Iteration 96090, Loss: 0.000000309\n",
      "Iteration 96100, Loss: 0.000000243\n",
      "Iteration 96110, Loss: 0.000000292\n",
      "Iteration 96120, Loss: 0.000000850\n",
      "Iteration 96130, Loss: 0.000000312\n",
      "Iteration 96140, Loss: 0.000000243\n",
      "Iteration 96150, Loss: 0.000000257\n",
      "Iteration 96160, Loss: 0.000000296\n",
      "Iteration 96170, Loss: 0.000000672\n",
      "Iteration 96180, Loss: 0.000000540\n",
      "Iteration 96190, Loss: 0.000000468\n",
      "Iteration 96200, Loss: 0.000000283\n",
      "Iteration 96210, Loss: 0.000000252\n",
      "Iteration 96220, Loss: 0.000000238\n",
      "Iteration 96230, Loss: 0.000000383\n",
      "Iteration 96240, Loss: 0.000001520\n",
      "Iteration 96250, Loss: 0.000000419\n",
      "Iteration 96260, Loss: 0.000000328\n",
      "Iteration 96270, Loss: 0.000000285\n",
      "Iteration 96280, Loss: 0.000000246\n",
      "Iteration 96290, Loss: 0.000000263\n",
      "Iteration 96300, Loss: 0.000000659\n",
      "Iteration 96310, Loss: 0.000000648\n",
      "Iteration 96320, Loss: 0.000000329\n",
      "Iteration 96330, Loss: 0.000000256\n",
      "Iteration 96340, Loss: 0.000000244\n",
      "Iteration 96350, Loss: 0.000000251\n",
      "Iteration 96360, Loss: 0.000000295\n",
      "Iteration 96370, Loss: 0.000000914\n",
      "Iteration 96380, Loss: 0.000000492\n",
      "Iteration 96390, Loss: 0.000000431\n",
      "Iteration 96400, Loss: 0.000000294\n",
      "Iteration 96410, Loss: 0.000000238\n",
      "Iteration 96420, Loss: 0.000000250\n",
      "Iteration 96430, Loss: 0.000000347\n",
      "Iteration 96440, Loss: 0.000001230\n",
      "Iteration 96450, Loss: 0.000000481\n",
      "Iteration 96460, Loss: 0.000000396\n",
      "Iteration 96470, Loss: 0.000000256\n",
      "Iteration 96480, Loss: 0.000000249\n",
      "Iteration 96490, Loss: 0.000000247\n",
      "Iteration 96500, Loss: 0.000000269\n",
      "Iteration 96510, Loss: 0.000000647\n",
      "Iteration 96520, Loss: 0.000000597\n",
      "Iteration 96530, Loss: 0.000000436\n",
      "Iteration 96540, Loss: 0.000000344\n",
      "Iteration 96550, Loss: 0.000000293\n",
      "Iteration 96560, Loss: 0.000000430\n",
      "Iteration 96570, Loss: 0.000000818\n",
      "Iteration 96580, Loss: 0.000000268\n",
      "Iteration 96590, Loss: 0.000000371\n",
      "Iteration 96600, Loss: 0.000000251\n",
      "Iteration 96610, Loss: 0.000000310\n",
      "Iteration 96620, Loss: 0.000000608\n",
      "Iteration 96630, Loss: 0.000000326\n",
      "Iteration 96640, Loss: 0.000000528\n",
      "Iteration 96650, Loss: 0.000000665\n",
      "Iteration 96660, Loss: 0.000000258\n",
      "Iteration 96670, Loss: 0.000000313\n",
      "Iteration 96680, Loss: 0.000000411\n",
      "Iteration 96690, Loss: 0.000000363\n",
      "Iteration 96700, Loss: 0.000001131\n",
      "Iteration 96710, Loss: 0.000000536\n",
      "Iteration 96720, Loss: 0.000000604\n",
      "Iteration 96730, Loss: 0.000000598\n",
      "Iteration 96740, Loss: 0.000000257\n",
      "Iteration 96750, Loss: 0.000000323\n",
      "Iteration 96760, Loss: 0.000000249\n",
      "Iteration 96770, Loss: 0.000000246\n",
      "Iteration 96780, Loss: 0.000000403\n",
      "Iteration 96790, Loss: 0.000000993\n",
      "Iteration 96800, Loss: 0.000000805\n",
      "Iteration 96810, Loss: 0.000000439\n",
      "Iteration 96820, Loss: 0.000000296\n",
      "Iteration 96830, Loss: 0.000000246\n",
      "Iteration 96840, Loss: 0.000000245\n",
      "Iteration 96850, Loss: 0.000000236\n",
      "Iteration 96860, Loss: 0.000000404\n",
      "Iteration 96870, Loss: 0.000000353\n",
      "Iteration 96880, Loss: 0.000000558\n",
      "Iteration 96890, Loss: 0.000001413\n",
      "Iteration 96900, Loss: 0.000000546\n",
      "Iteration 96910, Loss: 0.000000291\n",
      "Iteration 96920, Loss: 0.000000251\n",
      "Iteration 96930, Loss: 0.000000241\n",
      "Iteration 96940, Loss: 0.000000232\n",
      "Iteration 96950, Loss: 0.000000233\n",
      "Iteration 96960, Loss: 0.000000280\n",
      "Iteration 96970, Loss: 0.000001561\n",
      "Iteration 96980, Loss: 0.000000506\n",
      "Iteration 96990, Loss: 0.000000444\n",
      "Iteration 97000, Loss: 0.000000295\n",
      "Iteration 97010, Loss: 0.000000242\n",
      "Iteration 97020, Loss: 0.000000232\n",
      "Iteration 97030, Loss: 0.000000236\n",
      "Iteration 97040, Loss: 0.000000429\n",
      "Iteration 97050, Loss: 0.000000373\n",
      "Iteration 97060, Loss: 0.000000286\n",
      "Iteration 97070, Loss: 0.000000408\n",
      "Iteration 97080, Loss: 0.000000897\n",
      "Iteration 97090, Loss: 0.000000248\n",
      "Iteration 97100, Loss: 0.000000354\n",
      "Iteration 97110, Loss: 0.000000256\n",
      "Iteration 97120, Loss: 0.000000314\n",
      "Iteration 97130, Loss: 0.000000799\n",
      "Iteration 97140, Loss: 0.000000348\n",
      "Iteration 97150, Loss: 0.000000295\n",
      "Iteration 97160, Loss: 0.000000398\n",
      "Iteration 97170, Loss: 0.000002078\n",
      "Iteration 97180, Loss: 0.000000964\n",
      "Iteration 97190, Loss: 0.000000580\n",
      "Iteration 97200, Loss: 0.000000366\n",
      "Iteration 97210, Loss: 0.000000270\n",
      "Iteration 97220, Loss: 0.000000239\n",
      "Iteration 97230, Loss: 0.000000233\n",
      "Iteration 97240, Loss: 0.000000233\n",
      "Iteration 97250, Loss: 0.000000370\n",
      "Iteration 97260, Loss: 0.000001241\n",
      "Iteration 97270, Loss: 0.000000370\n",
      "Iteration 97280, Loss: 0.000000295\n",
      "Iteration 97290, Loss: 0.000000268\n",
      "Iteration 97300, Loss: 0.000000233\n",
      "Iteration 97310, Loss: 0.000000240\n",
      "Iteration 97320, Loss: 0.000000448\n",
      "Iteration 97330, Loss: 0.000001432\n",
      "Iteration 97340, Loss: 0.000000654\n",
      "Iteration 97350, Loss: 0.000000340\n",
      "Iteration 97360, Loss: 0.000000253\n",
      "Iteration 97370, Loss: 0.000000239\n",
      "Iteration 97380, Loss: 0.000000237\n",
      "Iteration 97390, Loss: 0.000000283\n",
      "Iteration 97400, Loss: 0.000000954\n",
      "Iteration 97410, Loss: 0.000000410\n",
      "Iteration 97420, Loss: 0.000000320\n",
      "Iteration 97430, Loss: 0.000000271\n",
      "Iteration 97440, Loss: 0.000000254\n",
      "Iteration 97450, Loss: 0.000000323\n",
      "Iteration 97460, Loss: 0.000001273\n",
      "Iteration 97470, Loss: 0.000000302\n",
      "Iteration 97480, Loss: 0.000000299\n",
      "Iteration 97490, Loss: 0.000000271\n",
      "Iteration 97500, Loss: 0.000000252\n",
      "Iteration 97510, Loss: 0.000000251\n",
      "Iteration 97520, Loss: 0.000000268\n",
      "Iteration 97530, Loss: 0.000000339\n",
      "Iteration 97540, Loss: 0.000001233\n",
      "Iteration 97550, Loss: 0.000000449\n",
      "Iteration 97560, Loss: 0.000000357\n",
      "Iteration 97570, Loss: 0.000000265\n",
      "Iteration 97580, Loss: 0.000000250\n",
      "Iteration 97590, Loss: 0.000000236\n",
      "Iteration 97600, Loss: 0.000000236\n",
      "Iteration 97610, Loss: 0.000000461\n",
      "Iteration 97620, Loss: 0.000001471\n",
      "Iteration 97630, Loss: 0.000000468\n",
      "Iteration 97640, Loss: 0.000000281\n",
      "Iteration 97650, Loss: 0.000000290\n",
      "Iteration 97660, Loss: 0.000000242\n",
      "Iteration 97670, Loss: 0.000000255\n",
      "Iteration 97680, Loss: 0.000000663\n",
      "Iteration 97690, Loss: 0.000000483\n",
      "Iteration 97700, Loss: 0.000000300\n",
      "Iteration 97710, Loss: 0.000000240\n",
      "Iteration 97720, Loss: 0.000000243\n",
      "Iteration 97730, Loss: 0.000000252\n",
      "Iteration 97740, Loss: 0.000000347\n",
      "Iteration 97750, Loss: 0.000001082\n",
      "Iteration 97760, Loss: 0.000000437\n",
      "Iteration 97770, Loss: 0.000000552\n",
      "Iteration 97780, Loss: 0.000000333\n",
      "Iteration 97790, Loss: 0.000000279\n",
      "Iteration 97800, Loss: 0.000000258\n",
      "Iteration 97810, Loss: 0.000000231\n",
      "Iteration 97820, Loss: 0.000000233\n",
      "Iteration 97830, Loss: 0.000000273\n",
      "Iteration 97840, Loss: 0.000000549\n",
      "Iteration 97850, Loss: 0.000001514\n",
      "Iteration 97860, Loss: 0.000000532\n",
      "Iteration 97870, Loss: 0.000000333\n",
      "Iteration 97880, Loss: 0.000000268\n",
      "Iteration 97890, Loss: 0.000000248\n",
      "Iteration 97900, Loss: 0.000000273\n",
      "Iteration 97910, Loss: 0.000000553\n",
      "Iteration 97920, Loss: 0.000001173\n",
      "Iteration 97930, Loss: 0.000000534\n",
      "Iteration 97940, Loss: 0.000000307\n",
      "Iteration 97950, Loss: 0.000000258\n",
      "Iteration 97960, Loss: 0.000000243\n",
      "Iteration 97970, Loss: 0.000000232\n",
      "Iteration 97980, Loss: 0.000000232\n",
      "Iteration 97990, Loss: 0.000000279\n",
      "Iteration 98000, Loss: 0.000001189\n",
      "Iteration 98010, Loss: 0.000001032\n",
      "Iteration 98020, Loss: 0.000000481\n",
      "Iteration 98030, Loss: 0.000000463\n",
      "Iteration 98040, Loss: 0.000000310\n",
      "Iteration 98050, Loss: 0.000000689\n",
      "Iteration 98060, Loss: 0.000000314\n",
      "Iteration 98070, Loss: 0.000000407\n",
      "Iteration 98080, Loss: 0.000000335\n",
      "Iteration 98090, Loss: 0.000000399\n",
      "Iteration 98100, Loss: 0.000000269\n",
      "Iteration 98110, Loss: 0.000000239\n",
      "Iteration 98120, Loss: 0.000000273\n",
      "Iteration 98130, Loss: 0.000000563\n",
      "Iteration 98140, Loss: 0.000000801\n",
      "Iteration 98150, Loss: 0.000000513\n",
      "Iteration 98160, Loss: 0.000000595\n",
      "Iteration 98170, Loss: 0.000000378\n",
      "Iteration 98180, Loss: 0.000000304\n",
      "Iteration 98190, Loss: 0.000000257\n",
      "Iteration 98200, Loss: 0.000000240\n",
      "Iteration 98210, Loss: 0.000000231\n",
      "Iteration 98220, Loss: 0.000000254\n",
      "Iteration 98230, Loss: 0.000000759\n",
      "Iteration 98240, Loss: 0.000001357\n",
      "Iteration 98250, Loss: 0.000000641\n",
      "Iteration 98260, Loss: 0.000000343\n",
      "Iteration 98270, Loss: 0.000000255\n",
      "Iteration 98280, Loss: 0.000000245\n",
      "Iteration 98290, Loss: 0.000000233\n",
      "Iteration 98300, Loss: 0.000000238\n",
      "Iteration 98310, Loss: 0.000000422\n",
      "Iteration 98320, Loss: 0.000000673\n",
      "Iteration 98330, Loss: 0.000000475\n",
      "Iteration 98340, Loss: 0.000000536\n",
      "Iteration 98350, Loss: 0.000000261\n",
      "Iteration 98360, Loss: 0.000000289\n",
      "Iteration 98370, Loss: 0.000000394\n",
      "Iteration 98380, Loss: 0.000000465\n",
      "Iteration 98390, Loss: 0.000000609\n",
      "Iteration 98400, Loss: 0.000000263\n",
      "Iteration 98410, Loss: 0.000000272\n",
      "Iteration 98420, Loss: 0.000000336\n",
      "Iteration 98430, Loss: 0.000000543\n",
      "Iteration 98440, Loss: 0.000000564\n",
      "Iteration 98450, Loss: 0.000000271\n",
      "Iteration 98460, Loss: 0.000000314\n",
      "Iteration 98470, Loss: 0.000000278\n",
      "Iteration 98480, Loss: 0.000000645\n",
      "Iteration 98490, Loss: 0.000000590\n",
      "Iteration 98500, Loss: 0.000000613\n",
      "Iteration 98510, Loss: 0.000000355\n",
      "Iteration 98520, Loss: 0.000000274\n",
      "Iteration 98530, Loss: 0.000000250\n",
      "Iteration 98540, Loss: 0.000000242\n",
      "Iteration 98550, Loss: 0.000000292\n",
      "Iteration 98560, Loss: 0.000001095\n",
      "Iteration 98570, Loss: 0.000000436\n",
      "Iteration 98580, Loss: 0.000000305\n",
      "Iteration 98590, Loss: 0.000000332\n",
      "Iteration 98600, Loss: 0.000000278\n",
      "Iteration 98610, Loss: 0.000000252\n",
      "Iteration 98620, Loss: 0.000000235\n",
      "Iteration 98630, Loss: 0.000000251\n",
      "Iteration 98640, Loss: 0.000000760\n",
      "Iteration 98650, Loss: 0.000000478\n",
      "Iteration 98660, Loss: 0.000000437\n",
      "Iteration 98670, Loss: 0.000000254\n",
      "Iteration 98680, Loss: 0.000000240\n",
      "Iteration 98690, Loss: 0.000000232\n",
      "Iteration 98700, Loss: 0.000000237\n",
      "Iteration 98710, Loss: 0.000000570\n",
      "Iteration 98720, Loss: 0.000000810\n",
      "Iteration 98730, Loss: 0.000000401\n",
      "Iteration 98740, Loss: 0.000000330\n",
      "Iteration 98750, Loss: 0.000000273\n",
      "Iteration 98760, Loss: 0.000000292\n",
      "Iteration 98770, Loss: 0.000000251\n",
      "Iteration 98780, Loss: 0.000000342\n",
      "Iteration 98790, Loss: 0.000002263\n",
      "Iteration 98800, Loss: 0.000000989\n",
      "Iteration 98810, Loss: 0.000000575\n",
      "Iteration 98820, Loss: 0.000000432\n",
      "Iteration 98830, Loss: 0.000000259\n",
      "Iteration 98840, Loss: 0.000000236\n",
      "Iteration 98850, Loss: 0.000000235\n",
      "Iteration 98860, Loss: 0.000000256\n",
      "Iteration 98870, Loss: 0.000000393\n",
      "Iteration 98880, Loss: 0.000000533\n",
      "Iteration 98890, Loss: 0.000000309\n",
      "Iteration 98900, Loss: 0.000000264\n",
      "Iteration 98910, Loss: 0.000000238\n",
      "Iteration 98920, Loss: 0.000000234\n",
      "Iteration 98930, Loss: 0.000000258\n",
      "Iteration 98940, Loss: 0.000000756\n",
      "Iteration 98950, Loss: 0.000001072\n",
      "Iteration 98960, Loss: 0.000000381\n",
      "Iteration 98970, Loss: 0.000000351\n",
      "Iteration 98980, Loss: 0.000000265\n",
      "Iteration 98990, Loss: 0.000000231\n",
      "Iteration 99000, Loss: 0.000000252\n",
      "Iteration 99010, Loss: 0.000000348\n",
      "Iteration 99020, Loss: 0.000000283\n",
      "Iteration 99030, Loss: 0.000000798\n",
      "Iteration 99040, Loss: 0.000000850\n",
      "Iteration 99050, Loss: 0.000000462\n",
      "Iteration 99060, Loss: 0.000000329\n",
      "Iteration 99070, Loss: 0.000000257\n",
      "Iteration 99080, Loss: 0.000000236\n",
      "Iteration 99090, Loss: 0.000000226\n",
      "Iteration 99100, Loss: 0.000000227\n",
      "Iteration 99110, Loss: 0.000000233\n",
      "Iteration 99120, Loss: 0.000000363\n",
      "Iteration 99130, Loss: 0.000001605\n",
      "Iteration 99140, Loss: 0.000000618\n",
      "Iteration 99150, Loss: 0.000000322\n",
      "Iteration 99160, Loss: 0.000000289\n",
      "Iteration 99170, Loss: 0.000000241\n",
      "Iteration 99180, Loss: 0.000000230\n",
      "Iteration 99190, Loss: 0.000000232\n",
      "Iteration 99200, Loss: 0.000000285\n",
      "Iteration 99210, Loss: 0.000001110\n",
      "Iteration 99220, Loss: 0.000000415\n",
      "Iteration 99230, Loss: 0.000000305\n",
      "Iteration 99240, Loss: 0.000000269\n",
      "Iteration 99250, Loss: 0.000000256\n",
      "Iteration 99260, Loss: 0.000000233\n",
      "Iteration 99270, Loss: 0.000000226\n",
      "Iteration 99280, Loss: 0.000000238\n",
      "Iteration 99290, Loss: 0.000000846\n",
      "Iteration 99300, Loss: 0.000000589\n",
      "Iteration 99310, Loss: 0.000000577\n",
      "Iteration 99320, Loss: 0.000000304\n",
      "Iteration 99330, Loss: 0.000000259\n",
      "Iteration 99340, Loss: 0.000000233\n",
      "Iteration 99350, Loss: 0.000000229\n",
      "Iteration 99360, Loss: 0.000000232\n",
      "Iteration 99370, Loss: 0.000000320\n",
      "Iteration 99380, Loss: 0.000001296\n",
      "Iteration 99390, Loss: 0.000000459\n",
      "Iteration 99400, Loss: 0.000000293\n",
      "Iteration 99410, Loss: 0.000000264\n",
      "Iteration 99420, Loss: 0.000000249\n",
      "Iteration 99430, Loss: 0.000000253\n",
      "Iteration 99440, Loss: 0.000000676\n",
      "Iteration 99450, Loss: 0.000000595\n",
      "Iteration 99460, Loss: 0.000000313\n",
      "Iteration 99470, Loss: 0.000000241\n",
      "Iteration 99480, Loss: 0.000000241\n",
      "Iteration 99490, Loss: 0.000000238\n",
      "Iteration 99500, Loss: 0.000000254\n",
      "Iteration 99510, Loss: 0.000000460\n",
      "Iteration 99520, Loss: 0.000001479\n",
      "Iteration 99530, Loss: 0.000000648\n",
      "Iteration 99540, Loss: 0.000000369\n",
      "Iteration 99550, Loss: 0.000000271\n",
      "Iteration 99560, Loss: 0.000000236\n",
      "Iteration 99570, Loss: 0.000000227\n",
      "Iteration 99580, Loss: 0.000000288\n",
      "Iteration 99590, Loss: 0.000000427\n",
      "Iteration 99600, Loss: 0.000000500\n",
      "Iteration 99610, Loss: 0.000000931\n",
      "Iteration 99620, Loss: 0.000000373\n",
      "Iteration 99630, Loss: 0.000000281\n",
      "Iteration 99640, Loss: 0.000000264\n",
      "Iteration 99650, Loss: 0.000000256\n",
      "Iteration 99660, Loss: 0.000000323\n",
      "Iteration 99670, Loss: 0.000000761\n",
      "Iteration 99680, Loss: 0.000000558\n",
      "Iteration 99690, Loss: 0.000000356\n",
      "Iteration 99700, Loss: 0.000000279\n",
      "Iteration 99710, Loss: 0.000000240\n",
      "Iteration 99720, Loss: 0.000000254\n",
      "Iteration 99730, Loss: 0.000000301\n",
      "Iteration 99740, Loss: 0.000000817\n",
      "Iteration 99750, Loss: 0.000000349\n",
      "Iteration 99760, Loss: 0.000000392\n",
      "Iteration 99770, Loss: 0.000000392\n",
      "Iteration 99780, Loss: 0.000000663\n",
      "Iteration 99790, Loss: 0.000000308\n",
      "Iteration 99800, Loss: 0.000000272\n",
      "Iteration 99810, Loss: 0.000000319\n",
      "Iteration 99820, Loss: 0.000000303\n",
      "Iteration 99830, Loss: 0.000000751\n",
      "Iteration 99840, Loss: 0.000000539\n",
      "Iteration 99850, Loss: 0.000000419\n",
      "Iteration 99860, Loss: 0.000000345\n",
      "Iteration 99870, Loss: 0.000000379\n",
      "Iteration 99880, Loss: 0.000000412\n",
      "Iteration 99890, Loss: 0.000000337\n",
      "Iteration 99900, Loss: 0.000000429\n",
      "Iteration 99910, Loss: 0.000000375\n",
      "Iteration 99920, Loss: 0.000000547\n",
      "Iteration 99930, Loss: 0.000000527\n",
      "Iteration 99940, Loss: 0.000000580\n",
      "Iteration 99950, Loss: 0.000000275\n",
      "Iteration 99960, Loss: 0.000000307\n",
      "Iteration 99970, Loss: 0.000000462\n",
      "Iteration 99980, Loss: 0.000000464\n",
      "Iteration 99990, Loss: 0.000000487\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = Pinns()\n",
    "net.network.load_state_dict(torch.load(r'C:/Users/hossein/Result/Backward-facing step/Ra=800/1-PINNs/model'))\n",
    "net.train(num_epochs=100000)\n",
    "net.plot()\n",
    "net.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0c434-4813-4250-b786-f583df64cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
