{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb545fd-2b2c-42f1-9da2-80fa0359bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b5d0ce-d058-456b-9816-d3585a87fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7e5bb6-7a30-413f-88e9-6a7ca793ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.9))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tanh(self.alpha * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37e6b34-02a7-4983-8e76-607c00e8cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierFeatures(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=10.0):\n",
    "        super(FourierFeatures, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.B = nn.Parameter(scale * torch.randn(in_features, out_features), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_proj = 2 * np.pi * x @ self.B\n",
    "        fourier = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "        return torch.cat([x, fourier], dim=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb44b01-2097-4d86-8982-8c7b888ed60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gate1(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.atanh = Atanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.atanh(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d57ecf-d4bd-4ad3-b417-cea90f252bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gate2(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.atanh = Atanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.atanh(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5574a4e3-2fb6-4553-b301-454e59892b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_input=2, fourier_features=64, layers=[128, 128, 128, 128], num_output=4, scale=10.0):\n",
    "        super().__init__()\n",
    "        self.fourier = FourierFeatures(num_input, fourier_features, scale)\n",
    "        input_size = num_input + 2*fourier_features\n",
    "        self.input_layer = nn.Linear(input_size, layers[0])\n",
    "        self.z_layers = nn.ModuleList()\n",
    "        self.gate1 = Gate1(input_size, layers[0])\n",
    "        self.gate2 = Gate2(input_size, layers[0])\n",
    "        for i in range(len(layers)-1):\n",
    "            self.z_layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "        self.output_layer = nn.Linear(layers[-1], num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fourier(x)\n",
    "        U = self.gate1(x)\n",
    "        V = self.gate2(x)\n",
    "        h = torch.tanh(self.input_layer(x))\n",
    "        for z_layer in self.z_layers:\n",
    "            Z = torch.tanh(z_layer(h))\n",
    "            h = (1 - Z) * U + Z * V\n",
    "        return self.output_layer(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ccef41f-53de-4fd5-a793-7a654aa9a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pinns:\n",
    "    def __init__(self):\n",
    "        # Transfer to GPU if available\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.network = Network().to(self.device)\n",
    "        initialize_weights(self.network)\n",
    "        \n",
    "        # Physical parameters (dimensionless)\n",
    "        self.Ra = torch.tensor(1e7, device=self.device)  # Rayleigh number\n",
    "        self.Pr = torch.tensor(0.7096, device=self.device)  # Prandtl number\n",
    "\n",
    "        # Domain definition (dimensionless)\n",
    "        dx = 0.01\n",
    "        dy = 0.01\n",
    "        self.x = torch.arange(-0.25, 0.25 + dx, dx)\n",
    "        self.y = torch.arange(-0.5, 0.5 + dy, dy)\n",
    "        self.X = torch.stack(torch.meshgrid(self.x, self.y, indexing='ij')).reshape(2, -1).T\n",
    "\n",
    "        # Boundary_condition_input\n",
    "        dx_b=0.0005\n",
    "        dy_b=0.001\n",
    "        self.x_b = torch.arange(-0.25,0.25+dx_b,dx_b)\n",
    "        self.y_b = torch.arange(-0.5,0.5+dy_b,dy_b)\n",
    "        self.rw = torch.stack(torch.meshgrid(self.x_b[-1],self.y_b)).reshape(2,-1).T\n",
    "        self.lw = torch.stack(torch.meshgrid(self.x_b[0],self.y_b)).reshape(2,-1).T\n",
    "        self.uw = torch.stack(torch.meshgrid(self.x_b,self.y_b[-1])).reshape(2,-1).T\n",
    "        self.dw = torch.stack(torch.meshgrid(self.x_b,self.y_b[0])).reshape(2,-1).T\n",
    "        self.X_train = torch.cat([self.rw, self.lw, self.uw,  self.dw])\n",
    "        self.uw.requires_grad = True\n",
    "        self.dw.requires_grad = True\n",
    "\n",
    "        # Boundary_condition_output\n",
    "        self.uv_rw = torch.stack(torch.meshgrid(self.x_b[500],torch.zeros_like(self.y_b))).reshape(2,-1).T\n",
    "        self.uv_lw = torch.stack(torch.meshgrid(self.x_b[500],torch.zeros_like(self.y_b))).reshape(2,-1).T\n",
    "        self.uv_uw = torch.stack(torch.meshgrid(self.x_b[500],torch.zeros_like(self.y_b))).reshape(2,-1).T\n",
    "        self.uv_dw = torch.stack(torch.meshgrid(self.x_b[500],torch.zeros_like(self.y_b))).reshape(2,-1).T\n",
    "        self.uv_train = torch.cat([self.uv_rw, self.uv_lw, self.uv_uw,  self.uv_dw])\n",
    "        self.T_rw = torch.zeros_like(self.y_b)+1\n",
    "        self.T_lw = torch.zeros_like(self.y_b)\n",
    "        self.dT_uw = torch.zeros_like(self.y_b)\n",
    "        self.dT_dw = torch.zeros_like(self.y_b)\n",
    "        \n",
    "        # Transfer tensor to GPU\n",
    "        self.uv_train = self.uv_train.to(self.device)\n",
    "        self.X_train = self.X_train.to(self.device)\n",
    "        self.T_rw = self.T_rw.to(self.device)\n",
    "        self.T_lw = self.T_lw.to(self.device)\n",
    "        self.dT_uw = self.dT_uw.to(self.device)\n",
    "        self.dT_dw = self.dT_dw.to(self.device)\n",
    "        self.lw = self.lw.to(self.device)\n",
    "        self.rw = self.rw.to(self.device)\n",
    "        self.uw = self.uw.to(self.device)\n",
    "        self.dw = self.dw.to(self.device)\n",
    "        self.X = self.X.to(self.device)\n",
    "\n",
    "        # Error criterion\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        # Optimizer settings\n",
    "        self.adam = torch.optim.Adam(self.network.parameters(), lr=1e-4)\n",
    "        #, lr=1e-4\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.adam, step_size=10000, gamma=0.9)\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.network.parameters(),\n",
    "            lr=1.0,\n",
    "            max_iter=1000,\n",
    "            max_eval=1000,\n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-7,\n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "        # For tracking loss\n",
    "        self.loss_history = []\n",
    "\n",
    "    def apply_hard_boundary_conditions(self, predictions):\n",
    "        u_pred = predictions[:, 0].reshape(len(self.x), len(self.y))\n",
    "        v_pred = predictions[:, 1].reshape(len(self.x), len(self.y))\n",
    "        p_pred = predictions[:, 2].reshape(len(self.x), len(self.y))\n",
    "        theta_pred = predictions[:, 3].reshape(len(self.x), len(self.y))\n",
    "\n",
    "        # Apply boundary conditions\n",
    "        # Left wall (x=-0.2): u=0, v=0, theta=0 (cold wall)\n",
    "        u_pred[0, :] = 0.0\n",
    "        v_pred[0, :] = 0.0\n",
    "        theta_pred[0, :] = 0.0\n",
    "\n",
    "        # Right wall (x=0.2): u=0, v=0, theta=1 (hot wall)\n",
    "        u_pred[-1, :] = 0.0\n",
    "        v_pred[-1, :] = 0.0\n",
    "        theta_pred[-1, :] = 1.0\n",
    "\n",
    "        # Bottom wall (y=-0.4): u=0, v=0, adiabatic (dtheta/dy=0)\n",
    "        u_pred[:, 0] = 0.0\n",
    "        v_pred[:, 0] = 0.0\n",
    "        theta_pred[:, 0] = theta_pred[:, 1]\n",
    "\n",
    "        # Top wall (y=0.4): u=0, v=0, adiabatic (dtheta/dy=0)\n",
    "        u_pred[:, -1] = 0.0\n",
    "        v_pred[:, -1] = 0.0\n",
    "        theta_pred[:, -1] = theta_pred[:, -2]\n",
    "\n",
    "        return u_pred, v_pred, p_pred, theta_pred\n",
    "        \n",
    "    def gradient_b(self, input, inputs):\n",
    "        output = torch.autograd.grad(\n",
    "            input,\n",
    "            inputs,\n",
    "            grad_outputs=torch.ones_like(input),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        return output    \n",
    "\n",
    "    def loss_f(self):\n",
    "        # Reset gradients\n",
    "        self.adam.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        #output of NN for boundary\n",
    "        self.uv_P_b = self.network(self.X_train)\n",
    "        self.u_P_b = self.uv_P_b[:,0]\n",
    "        self.v_P_b = self.uv_P_b[:,1]\n",
    "        self.theta_P_l =  self.network(self.lw)[:,3]\n",
    "        self.theta_P_r =  self.network(self.rw)[:,3]\n",
    "        self.theta_P_u =  self.network(self.uw)[:,3]\n",
    "        self.theta_P_d =  self.network(self.dw)[:,3]\n",
    "        self.dtheta_P_b_u_dy = self.gradient_b(self.theta_P_u,self.uw)[:,1]\n",
    "        self.dtheta_P_b_d_dy = self.gradient_b(self.theta_P_d,self.dw)[:,1]\n",
    "\n",
    "        #loss data definition\n",
    "        self.loss_data =(self.criterion(self.u_P_b,self.uv_train[:,0])+self.criterion(self.v_P_b,self.uv_train[:,1])+\n",
    "                        self.criterion(self.theta_P_l,self.T_lw)+self.criterion(self.theta_P_r,self.T_rw)+\n",
    "                        self.criterion(self.dtheta_P_b_u_dy,self.dT_uw)+self.criterion(self.dtheta_P_b_d_dy,self.dT_dw)\n",
    "                        )\n",
    "\n",
    "        # Network prediction\n",
    "        self.uvpt_pred = self.network(self.X)\n",
    "\n",
    "        # Apply hard boundary conditions\n",
    "        self.u_pred, self.v_pred, self.p_pred, self.theta_pred = self.apply_hard_boundary_conditions(self.uvpt_pred)\n",
    "\n",
    "        dx = self.x[1] - self.x[0]\n",
    "        dy = self.y[1] - self.y[0]\n",
    "\n",
    "        # Finite difference operators\n",
    "        def central_diff_x(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[1:-1, :] = (arr[2:, :] - arr[:-2, :]) / (2 * dx)\n",
    "            return res\n",
    "\n",
    "        def central_diff_y(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[:, 1:-1] = (arr[:, 2:] - arr[:, :-2]) / (2 * dy)\n",
    "            return res\n",
    "\n",
    "        def second_diff_x(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[1:-1, :] = (arr[2:, :] - 2 * arr[1:-1, :] + arr[:-2, :]) / (dx ** 2)\n",
    "            return res\n",
    "\n",
    "        def second_diff_y(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[:, 1:-1] = (arr[:, 2:] - 2 * arr[:, 1:-1] + arr[:, :-2]) / (dy ** 2)\n",
    "            return res\n",
    "\n",
    "        # Compute derivatives\n",
    "        du_dx = central_diff_x(self.u_pred)\n",
    "        du_dy = central_diff_y(self.u_pred)\n",
    "        du_dxx = second_diff_x(self.u_pred)\n",
    "        du_dyy = second_diff_y(self.u_pred)\n",
    "\n",
    "        dv_dx = central_diff_x(self.v_pred)\n",
    "        dv_dy = central_diff_y(self.v_pred)\n",
    "        dv_dxx = second_diff_x(self.v_pred)\n",
    "        dv_dyy = second_diff_y(self.v_pred)\n",
    "\n",
    "        dp_dx = central_diff_x(self.p_pred)\n",
    "        dp_dy = central_diff_y(self.p_pred)\n",
    "\n",
    "        dtheta_dx = central_diff_x(self.theta_pred)\n",
    "        dtheta_dy = central_diff_y(self.theta_pred)\n",
    "        dtheta_dxx = second_diff_x(self.theta_pred)\n",
    "        dtheta_dyy = second_diff_y(self.theta_pred)\n",
    "\n",
    "        # Extract interior points (exclude boundaries)\n",
    "        slice_in = slice(1, -1)\n",
    "        u_int = self.u_pred[slice_in, slice_in]\n",
    "        v_int = self.v_pred[slice_in, slice_in]\n",
    "        theta_int = self.theta_pred[slice_in, slice_in]\n",
    "\n",
    "        du_dx_int = du_dx[slice_in, slice_in]\n",
    "        du_dy_int = du_dy[slice_in, slice_in]\n",
    "        du_dxx_int = du_dxx[slice_in, slice_in]\n",
    "        du_dyy_int = du_dyy[slice_in, slice_in]\n",
    "\n",
    "        dv_dx_int = dv_dx[slice_in, slice_in]\n",
    "        dv_dy_int = dv_dy[slice_in, slice_in]\n",
    "        dv_dxx_int = dv_dxx[slice_in, slice_in]\n",
    "        dv_dyy_int = dv_dyy[slice_in, slice_in]\n",
    "\n",
    "        dp_dx_int = dp_dx[slice_in, slice_in]\n",
    "        dp_dy_int = dp_dy[slice_in, slice_in]\n",
    "\n",
    "        dtheta_dx_int = dtheta_dx[slice_in, slice_in]\n",
    "        dtheta_dy_int = dtheta_dy[slice_in, slice_in]\n",
    "        dtheta_dxx_int = dtheta_dxx[slice_in, slice_in]\n",
    "        dtheta_dyy_int = dtheta_dyy[slice_in, slice_in]\n",
    "\n",
    "        # Dimensionless governing equations for natural convection\n",
    "        # Continuity equation:\n",
    "        continuity_eq = du_dx_int + dv_dy_int\n",
    "\n",
    "        # X-momentum equation:\n",
    "        u_momentum_eq = (u_int * du_dx_int + v_int * du_dy_int + dp_dx_int -\n",
    "                        torch.sqrt(self.Pr / self.Ra) * (du_dxx_int + du_dyy_int))\n",
    "\n",
    "        # Y-momentum equation:\n",
    "        v_momentum_eq = (u_int * dv_dx_int + v_int * dv_dy_int + dp_dy_int -\n",
    "                        torch.sqrt(self.Pr / self.Ra) * (dv_dxx_int + dv_dyy_int) - theta_int)\n",
    "\n",
    "        # Energy equation:\n",
    "        energy_eq = (u_int * dtheta_dx_int + v_int * dtheta_dy_int -\n",
    "                    torch.sqrt(1.0 / (self.Ra * self.Pr)) * (dtheta_dxx_int + dtheta_dyy_int))\n",
    "\n",
    "        # Compute total loss\n",
    "        self.loss = (self.criterion(continuity_eq.reshape(-1), torch.zeros_like(continuity_eq).reshape(-1)) +\n",
    "                    self.criterion(u_momentum_eq.reshape(-1), torch.zeros_like(u_momentum_eq).reshape(-1)) +\n",
    "                    self.criterion(v_momentum_eq.reshape(-1), torch.zeros_like(v_momentum_eq).reshape(-1)) +\n",
    "                    self.criterion(energy_eq.reshape(-1), torch.zeros_like(energy_eq).reshape(-1))+\n",
    "                    self.loss_data)\n",
    "\n",
    "        self.loss.backward()\n",
    "        return self.loss\n",
    "\n",
    "    def train(self, num_epochs=1):\n",
    "        self.network.train()\n",
    "        for i in range(num_epochs):\n",
    "            loss = self.loss_f()\n",
    "            self.loss_history.append(loss.item())\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Iteration {i}, Loss: {self.loss.item():.11f}\")\n",
    "            if i % 100 == 0:\n",
    "                torch.save(self.network.state_dict(), r'C:/Users/hossein/Result/Natural Convection/Ra=10^7/4-FF-FD-PINNs-gated-avtivated-initialized-hybrid/model')\n",
    "            self.adam.step(self.loss_f)\n",
    "        self.optimizer.step(self.loss_f)\n",
    "        torch.save(self.network.state_dict(), r'C:/Users/hossein/Result/Natural Convection/Ra=10^7/4-FF-FD-PINNs-gated-avtivated-initialized-hybrid/model')\n",
    "\n",
    "    def plot(self):\n",
    "        self.network.eval()\n",
    "        with torch.no_grad():\n",
    "            self.u = self.u_pred.cpu().numpy().T\n",
    "            self.v = self.v_pred.cpu().numpy().T\n",
    "            self.p = self.p_pred.cpu().numpy().T\n",
    "            self.theta = self.theta_pred.cpu().numpy().T\n",
    "\n",
    "        save_dir = \"C:/Users/hossein/Result/Natural Convection/Ra=10^7/4-FF-FD-PINNs-gated-avtivated-initialized-hybrid\"\n",
    "        plt.rcParams.update({\n",
    "            \"font.family\": \"Times New Roman\",\n",
    "            \"font.style\": \"italic\"\n",
    "        })\n",
    "\n",
    "        # Temperature field\n",
    "        plt.figure(figsize=(4, 5))\n",
    "        contour1 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                               self.theta, levels=50, cmap=\"jet\")\n",
    "        plt.colorbar(contour1, aspect=60)\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.title(\"Temperature Field (Î¸)\", fontsize=14)\n",
    "        plt.savefig(os.path.join(save_dir, \"Temperature.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # U velocity\n",
    "        plt.figure(figsize=(4, 5))\n",
    "        contour2 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                               self.u, levels=50, cmap=\"jet\")\n",
    "        plt.colorbar(contour2, aspect=60)\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.title(\"u-velocity\", fontsize=14)\n",
    "        plt.savefig(os.path.join(save_dir, \"u-velocity.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        # V velocity\n",
    "        plt.figure(figsize=(4, 5))\n",
    "        contour3 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                               self.v, levels=50, cmap=\"jet\")\n",
    "        plt.colorbar(contour3, aspect=60)\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.title(\"v-velocity\", fontsize=14)\n",
    "        plt.savefig(os.path.join(save_dir, \"v-velocity.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Streamlines\n",
    "        fig, ax = plt.subplots(figsize=(4, 6))\n",
    "        ax.streamplot(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                      self.u, self.v, color='red', cmap='autumn', linewidth=0.5, density=2, arrowsize=0.6)\n",
    "        ax.set_xlabel(\"x\", fontsize=14)\n",
    "        ax.set_ylabel(\"y\", fontsize=14)\n",
    "        ax.set_title(\"Streamlines\", fontsize=14)\n",
    "        ax.set_xlim(-0.2, 0.2)\n",
    "        ax.set_ylim(-0.4, 0.4)\n",
    "        fig.savefig(os.path.join(save_dir, \"Streamlines.png\"), dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.semilogy(self.loss_history)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss (Log Scale)')\n",
    "        plt.title('Training Loss History')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        df = pd.DataFrame({\"loss\": self.loss_history})\n",
    "        df.to_csv(\"C:/Users/hossein/Result/Natural Convection/Ra=10^7/4-FF-FD-PINNs-gated-avtivated-initialized-hybrid/loss_history1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53082ac5-3b80-4374-8554-187e6cf2b95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.00000285720\n",
      "Iteration 10, Loss: 0.00006701233\n",
      "Iteration 20, Loss: 0.00002320826\n",
      "Iteration 30, Loss: 0.00000867706\n",
      "Iteration 40, Loss: 0.00000510417\n",
      "Iteration 50, Loss: 0.00000370111\n",
      "Iteration 60, Loss: 0.00000311050\n",
      "Iteration 70, Loss: 0.00000292746\n",
      "Iteration 80, Loss: 0.00000285571\n",
      "Iteration 90, Loss: 0.00000282602\n",
      "Iteration 100, Loss: 0.00000281480\n",
      "Iteration 110, Loss: 0.00000280856\n",
      "Iteration 120, Loss: 0.00000280463\n",
      "Iteration 130, Loss: 0.00000280150\n",
      "Iteration 140, Loss: 0.00000279865\n",
      "Iteration 150, Loss: 0.00000279590\n",
      "Iteration 160, Loss: 0.00000279317\n",
      "Iteration 170, Loss: 0.00000279045\n",
      "Iteration 180, Loss: 0.00000278771\n",
      "Iteration 190, Loss: 0.00000278494\n",
      "Iteration 200, Loss: 0.00000278214\n",
      "Iteration 210, Loss: 0.00000277972\n",
      "Iteration 220, Loss: 0.00000362926\n",
      "Iteration 230, Loss: 0.00000283072\n",
      "Iteration 240, Loss: 0.00000278674\n",
      "Iteration 250, Loss: 0.00000276945\n",
      "Iteration 260, Loss: 0.00000278428\n",
      "Iteration 270, Loss: 0.00000276215\n",
      "Iteration 280, Loss: 0.00000275959\n",
      "Iteration 290, Loss: 0.00000275765\n",
      "Iteration 300, Loss: 0.00000275543\n",
      "Iteration 310, Loss: 0.00000325974\n",
      "Iteration 320, Loss: 0.00000393986\n",
      "Iteration 330, Loss: 0.00000301374\n",
      "Iteration 340, Loss: 0.00000276563\n",
      "Iteration 350, Loss: 0.00000275226\n",
      "Iteration 360, Loss: 0.00000275875\n",
      "Iteration 370, Loss: 0.00000273747\n",
      "Iteration 380, Loss: 0.00000272950\n",
      "Iteration 390, Loss: 0.00000272764\n",
      "Iteration 400, Loss: 0.00000272339\n",
      "Iteration 410, Loss: 0.00000279203\n",
      "Iteration 420, Loss: 0.00000655754\n",
      "Iteration 430, Loss: 0.00000318569\n",
      "Iteration 440, Loss: 0.00000273071\n",
      "Iteration 450, Loss: 0.00000277899\n",
      "Iteration 460, Loss: 0.00000276182\n",
      "Iteration 470, Loss: 0.00000271101\n",
      "Iteration 480, Loss: 0.00000285006\n",
      "Iteration 490, Loss: 0.00000274508\n",
      "Iteration 500, Loss: 0.00000271295\n",
      "Iteration 510, Loss: 0.00000269579\n",
      "Iteration 520, Loss: 0.00000278575\n",
      "Iteration 530, Loss: 0.00000575743\n",
      "Iteration 540, Loss: 0.00000437439\n",
      "Iteration 550, Loss: 0.00000282740\n",
      "Iteration 560, Loss: 0.00000285465\n",
      "Iteration 570, Loss: 0.00000270067\n",
      "Iteration 580, Loss: 0.00000267943\n",
      "Iteration 590, Loss: 0.00000266490\n",
      "Iteration 600, Loss: 0.00000266078\n",
      "Iteration 610, Loss: 0.00000279577\n",
      "Iteration 620, Loss: 0.00000626426\n",
      "Iteration 630, Loss: 0.00000331558\n",
      "Iteration 640, Loss: 0.00000294202\n",
      "Iteration 650, Loss: 0.00000276185\n",
      "Iteration 660, Loss: 0.00000268433\n",
      "Iteration 670, Loss: 0.00000464397\n",
      "Iteration 680, Loss: 0.00000423639\n",
      "Iteration 690, Loss: 0.00000314067\n",
      "Iteration 700, Loss: 0.00000278048\n",
      "Iteration 710, Loss: 0.00000270550\n",
      "Iteration 720, Loss: 0.00000263507\n",
      "Iteration 730, Loss: 0.00000282486\n",
      "Iteration 740, Loss: 0.00000363781\n",
      "Iteration 750, Loss: 0.00000294986\n",
      "Iteration 760, Loss: 0.00000272224\n",
      "Iteration 770, Loss: 0.00000266879\n",
      "Iteration 780, Loss: 0.00000385287\n",
      "Iteration 790, Loss: 0.00000330687\n",
      "Iteration 800, Loss: 0.00000376100\n",
      "Iteration 810, Loss: 0.00000276177\n",
      "Iteration 820, Loss: 0.00000270935\n",
      "Iteration 830, Loss: 0.00000261880\n",
      "Iteration 840, Loss: 0.00000258625\n",
      "Iteration 850, Loss: 0.00000262632\n",
      "Iteration 860, Loss: 0.00000357387\n",
      "Iteration 870, Loss: 0.00000530190\n",
      "Iteration 880, Loss: 0.00000462431\n",
      "Iteration 890, Loss: 0.00000285413\n",
      "Iteration 900, Loss: 0.00000299044\n",
      "Iteration 910, Loss: 0.00000263313\n",
      "Iteration 920, Loss: 0.00000257981\n",
      "Iteration 930, Loss: 0.00000258952\n",
      "Iteration 940, Loss: 0.00000438739\n",
      "Iteration 950, Loss: 0.00000436501\n",
      "Iteration 960, Loss: 0.00000402028\n",
      "Iteration 970, Loss: 0.00000292243\n",
      "Iteration 980, Loss: 0.00000272965\n",
      "Iteration 990, Loss: 0.00000257390\n",
      "Iteration 1000, Loss: 0.00000256417\n",
      "Iteration 1010, Loss: 0.00000253554\n",
      "Iteration 1020, Loss: 0.00000267608\n",
      "Iteration 1030, Loss: 0.00000276785\n",
      "Iteration 1040, Loss: 0.00000356702\n",
      "Iteration 1050, Loss: 0.00000352033\n",
      "Iteration 1060, Loss: 0.00000277022\n",
      "Iteration 1070, Loss: 0.00000265879\n",
      "Iteration 1080, Loss: 0.00000261242\n",
      "Iteration 1090, Loss: 0.00000259040\n",
      "Iteration 1100, Loss: 0.00000297510\n",
      "Iteration 1110, Loss: 0.00000370392\n",
      "Iteration 1120, Loss: 0.00000678036\n",
      "Iteration 1130, Loss: 0.00000282636\n",
      "Iteration 1140, Loss: 0.00000314369\n",
      "Iteration 1150, Loss: 0.00000258709\n",
      "Iteration 1160, Loss: 0.00000255933\n",
      "Iteration 1170, Loss: 0.00000250020\n",
      "Iteration 1180, Loss: 0.00000248945\n",
      "Iteration 1190, Loss: 0.00000267172\n",
      "Iteration 1200, Loss: 0.00000749859\n",
      "Iteration 1210, Loss: 0.00000313723\n",
      "Iteration 1220, Loss: 0.00000294013\n",
      "Iteration 1230, Loss: 0.00000262227\n",
      "Iteration 1240, Loss: 0.00000263162\n",
      "Iteration 1250, Loss: 0.00000286542\n",
      "Iteration 1260, Loss: 0.00000641511\n",
      "Iteration 1270, Loss: 0.00000332670\n",
      "Iteration 1280, Loss: 0.00000317196\n",
      "Iteration 1290, Loss: 0.00000284267\n",
      "Iteration 1300, Loss: 0.00000260200\n",
      "Iteration 1310, Loss: 0.00000254871\n",
      "Iteration 1320, Loss: 0.00000354265\n",
      "Iteration 1330, Loss: 0.00000336505\n",
      "Iteration 1340, Loss: 0.00000296749\n",
      "Iteration 1350, Loss: 0.00000257184\n",
      "Iteration 1360, Loss: 0.00000263060\n",
      "Iteration 1370, Loss: 0.00000347283\n",
      "Iteration 1380, Loss: 0.00000631587\n",
      "Iteration 1390, Loss: 0.00000318224\n",
      "Iteration 1400, Loss: 0.00000266958\n",
      "Iteration 1410, Loss: 0.00000255562\n",
      "Iteration 1420, Loss: 0.00000248688\n",
      "Iteration 1430, Loss: 0.00000244464\n",
      "Iteration 1440, Loss: 0.00000250698\n",
      "Iteration 1450, Loss: 0.00000478744\n",
      "Iteration 1460, Loss: 0.00000332133\n",
      "Iteration 1470, Loss: 0.00000348263\n",
      "Iteration 1480, Loss: 0.00000759557\n",
      "Iteration 1490, Loss: 0.00000379248\n",
      "Iteration 1500, Loss: 0.00000296541\n",
      "Iteration 1510, Loss: 0.00000257924\n",
      "Iteration 1520, Loss: 0.00000242724\n",
      "Iteration 1530, Loss: 0.00000242644\n",
      "Iteration 1540, Loss: 0.00000316179\n",
      "Iteration 1550, Loss: 0.00000459422\n",
      "Iteration 1560, Loss: 0.00000253858\n",
      "Iteration 1570, Loss: 0.00000272242\n",
      "Iteration 1580, Loss: 0.00000250131\n",
      "Iteration 1590, Loss: 0.00000252381\n",
      "Iteration 1600, Loss: 0.00000731730\n",
      "Iteration 1610, Loss: 0.00000498117\n",
      "Iteration 1620, Loss: 0.00000286776\n",
      "Iteration 1630, Loss: 0.00000275795\n",
      "Iteration 1640, Loss: 0.00000243991\n",
      "Iteration 1650, Loss: 0.00000240183\n",
      "Iteration 1660, Loss: 0.00000236901\n",
      "Iteration 1670, Loss: 0.00000236787\n",
      "Iteration 1680, Loss: 0.00000252032\n",
      "Iteration 1690, Loss: 0.00000598612\n"
     ]
    }
   ],
   "source": [
    "net = Pinns()\n",
    "net.network.load_state_dict(torch.load(r'C:/Users/hossein/Result/Natural Convection/Ra=10^7/4-FF-FD-PINNs-gated-avtivated-initialized-hybrid/model'))\n",
    "net.train(num_epochs=10000)\n",
    "net.plot()\n",
    "net.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ee454-50f3-4910-8928-e8ce61cb0b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
