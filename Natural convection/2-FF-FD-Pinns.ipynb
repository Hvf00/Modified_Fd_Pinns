{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb545fd-2b2c-42f1-9da2-80fa0359bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45a975e-9c02-4a36-8994-045dd9346b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierFeatures(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=10.0):\n",
    "        super(FourierFeatures, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.B = nn.Parameter(scale * torch.randn(in_features, out_features), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_proj = 2 * np.pi * x @ self.B\n",
    "        fourier = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "        return torch.cat([x, fourier], dim=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d271da-f557-4c47-a4e1-734644a63e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_input=2, fourier_features=64, layers=[128, 128, 128, 128], num_output=4, scale=10.0):\n",
    "        super(Network, self).__init__()\n",
    "        self.fourier = FourierFeatures(num_input, fourier_features, scale)\n",
    "        input_size = num_input + 2*fourier_features\n",
    "        self.input_layer = nn.Linear(input_size, layers[0])\n",
    "        self.hidden_layer = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.hidden_layer.append(nn.Linear(layers[i], layers[i+1]))\n",
    "        self.output_layer = nn.Linear(layers[-1], num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fourier(x)\n",
    "        out = torch.tanh(self.input_layer(x))\n",
    "        for layer in self.hidden_layer:\n",
    "            out = torch.tanh(layer(out))\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ccef41f-53de-4fd5-a793-7a654aa9a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pinns:\n",
    "    def __init__(self):\n",
    "        # Transfer to GPU if available\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.network = Network().to(self.device)\n",
    "\n",
    "        # Physical parameters (dimensionless)\n",
    "        self.Ra = torch.tensor(1e7, device=self.device)  # Rayleigh number\n",
    "        self.Pr = torch.tensor(0.7096, device=self.device)  # Prandtl number\n",
    "\n",
    "        # Domain definition (dimensionless)\n",
    "        dx = 0.01\n",
    "        dy = 0.01\n",
    "        self.x = torch.arange(-0.25, 0.25 + dx, dx)\n",
    "        self.y = torch.arange(-0.5, 0.5 + dy, dy)\n",
    "        self.X = torch.stack(torch.meshgrid(self.x, self.y, indexing='ij')).reshape(2, -1).T\n",
    "\n",
    "        # Transfer tensor to GPU\n",
    "        self.X = self.X.to(self.device)\n",
    "\n",
    "        # Error criterion\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        # Optimizer settings\n",
    "        self.adam = torch.optim.Adam(self.network.parameters(), lr=1e-5)\n",
    "        #, lr=1e-4\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.adam, step_size=10000, gamma=0.9)\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.network.parameters(),\n",
    "            lr=1.0,\n",
    "            max_iter=1000,\n",
    "            max_eval=1000,\n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-7,\n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "        # For tracking loss\n",
    "        self.loss_history = []\n",
    "\n",
    "    def apply_hard_boundary_conditions(self, predictions):\n",
    "        u_pred = predictions[:, 0].reshape(len(self.x), len(self.y))\n",
    "        v_pred = predictions[:, 1].reshape(len(self.x), len(self.y))\n",
    "        p_pred = predictions[:, 2].reshape(len(self.x), len(self.y))\n",
    "        theta_pred = predictions[:, 3].reshape(len(self.x), len(self.y))\n",
    "\n",
    "        # Apply boundary conditions\n",
    "        # Left wall (x=-0.2): u=0, v=0, theta=0 (cold wall)\n",
    "        u_pred[0, :] = 0.0\n",
    "        v_pred[0, :] = 0.0\n",
    "        theta_pred[0, :] = 0.0\n",
    "\n",
    "        # Right wall (x=0.2): u=0, v=0, theta=1 (hot wall)\n",
    "        u_pred[-1, :] = 0.0\n",
    "        v_pred[-1, :] = 0.0\n",
    "        theta_pred[-1, :] = 1.0\n",
    "\n",
    "        # Bottom wall (y=-0.4): u=0, v=0, adiabatic (dtheta/dy=0)\n",
    "        u_pred[:, 0] = 0.0\n",
    "        v_pred[:, 0] = 0.0\n",
    "        theta_pred[:, 0] = theta_pred[:, 1]\n",
    "\n",
    "        # Top wall (y=0.4): u=0, v=0, adiabatic (dtheta/dy=0)\n",
    "        u_pred[:, -1] = 0.0\n",
    "        v_pred[:, -1] = 0.0\n",
    "        theta_pred[:, -1] = theta_pred[:, -2]\n",
    "\n",
    "        return u_pred, v_pred, p_pred, theta_pred\n",
    "\n",
    "    def loss_f(self):\n",
    "        # Reset gradients\n",
    "        self.adam.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Network prediction\n",
    "        self.uvpt_pred = self.network(self.X)\n",
    "\n",
    "        # Apply hard boundary conditions\n",
    "        self.u_pred, self.v_pred, self.p_pred, self.theta_pred = self.apply_hard_boundary_conditions(self.uvpt_pred)\n",
    "\n",
    "        dx = self.x[1] - self.x[0]\n",
    "        dy = self.y[1] - self.y[0]\n",
    "\n",
    "        # Finite difference operators\n",
    "        def central_diff_x(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[1:-1, :] = (arr[2:, :] - arr[:-2, :]) / (2 * dx)\n",
    "            return res\n",
    "\n",
    "        def central_diff_y(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[:, 1:-1] = (arr[:, 2:] - arr[:, :-2]) / (2 * dy)\n",
    "            return res\n",
    "\n",
    "        def second_diff_x(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[1:-1, :] = (arr[2:, :] - 2 * arr[1:-1, :] + arr[:-2, :]) / (dx ** 2)\n",
    "            return res\n",
    "\n",
    "        def second_diff_y(arr):\n",
    "            res = torch.zeros_like(arr)\n",
    "            res[:, 1:-1] = (arr[:, 2:] - 2 * arr[:, 1:-1] + arr[:, :-2]) / (dy ** 2)\n",
    "            return res\n",
    "\n",
    "        # Compute derivatives\n",
    "        du_dx = central_diff_x(self.u_pred)\n",
    "        du_dy = central_diff_y(self.u_pred)\n",
    "        du_dxx = second_diff_x(self.u_pred)\n",
    "        du_dyy = second_diff_y(self.u_pred)\n",
    "\n",
    "        dv_dx = central_diff_x(self.v_pred)\n",
    "        dv_dy = central_diff_y(self.v_pred)\n",
    "        dv_dxx = second_diff_x(self.v_pred)\n",
    "        dv_dyy = second_diff_y(self.v_pred)\n",
    "\n",
    "        dp_dx = central_diff_x(self.p_pred)\n",
    "        dp_dy = central_diff_y(self.p_pred)\n",
    "\n",
    "        dtheta_dx = central_diff_x(self.theta_pred)\n",
    "        dtheta_dy = central_diff_y(self.theta_pred)\n",
    "        dtheta_dxx = second_diff_x(self.theta_pred)\n",
    "        dtheta_dyy = second_diff_y(self.theta_pred)\n",
    "\n",
    "        # Extract interior points (exclude boundaries)\n",
    "        slice_in = slice(1, -1)\n",
    "        u_int = self.u_pred[slice_in, slice_in]\n",
    "        v_int = self.v_pred[slice_in, slice_in]\n",
    "        theta_int = self.theta_pred[slice_in, slice_in]\n",
    "\n",
    "        du_dx_int = du_dx[slice_in, slice_in]\n",
    "        du_dy_int = du_dy[slice_in, slice_in]\n",
    "        du_dxx_int = du_dxx[slice_in, slice_in]\n",
    "        du_dyy_int = du_dyy[slice_in, slice_in]\n",
    "\n",
    "        dv_dx_int = dv_dx[slice_in, slice_in]\n",
    "        dv_dy_int = dv_dy[slice_in, slice_in]\n",
    "        dv_dxx_int = dv_dxx[slice_in, slice_in]\n",
    "        dv_dyy_int = dv_dyy[slice_in, slice_in]\n",
    "\n",
    "        dp_dx_int = dp_dx[slice_in, slice_in]\n",
    "        dp_dy_int = dp_dy[slice_in, slice_in]\n",
    "\n",
    "        dtheta_dx_int = dtheta_dx[slice_in, slice_in]\n",
    "        dtheta_dy_int = dtheta_dy[slice_in, slice_in]\n",
    "        dtheta_dxx_int = dtheta_dxx[slice_in, slice_in]\n",
    "        dtheta_dyy_int = dtheta_dyy[slice_in, slice_in]\n",
    "\n",
    "        # Dimensionless governing equations for natural convection\n",
    "        # Continuity equation:\n",
    "        continuity_eq = du_dx_int + dv_dy_int\n",
    "\n",
    "        # X-momentum equation:\n",
    "        u_momentum_eq = (u_int * du_dx_int + v_int * du_dy_int + dp_dx_int -\n",
    "                        torch.sqrt(self.Pr / self.Ra) * (du_dxx_int + du_dyy_int))\n",
    "\n",
    "        # Y-momentum equation:\n",
    "        v_momentum_eq = (u_int * dv_dx_int + v_int * dv_dy_int + dp_dy_int -\n",
    "                        torch.sqrt(self.Pr / self.Ra) * (dv_dxx_int + dv_dyy_int) - theta_int)\n",
    "\n",
    "        # Energy equation:\n",
    "        energy_eq = (u_int * dtheta_dx_int + v_int * dtheta_dy_int -\n",
    "                    torch.sqrt(1.0 / (self.Ra * self.Pr)) * (dtheta_dxx_int + dtheta_dyy_int))\n",
    "\n",
    "        # Compute total loss\n",
    "        self.loss = (self.criterion(continuity_eq.reshape(-1), torch.zeros_like(continuity_eq).reshape(-1)) +\n",
    "                    self.criterion(u_momentum_eq.reshape(-1), torch.zeros_like(u_momentum_eq).reshape(-1)) +\n",
    "                    self.criterion(v_momentum_eq.reshape(-1), torch.zeros_like(v_momentum_eq).reshape(-1)) +\n",
    "                    self.criterion(energy_eq.reshape(-1), torch.zeros_like(energy_eq).reshape(-1)))\n",
    "\n",
    "        self.loss.backward()\n",
    "        return self.loss\n",
    "\n",
    "    def train(self, num_epochs=1):\n",
    "        self.network.train()\n",
    "        for i in range(num_epochs):\n",
    "            loss = self.loss_f()\n",
    "            self.loss_history.append(loss.item())\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Iteration {i}, Loss: {self.loss.item():.9f}\")\n",
    "            if i % 100 == 0:\n",
    "                torch.save(self.network.state_dict(), r'C:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs/model')\n",
    "            self.adam.step(self.loss_f)\n",
    "        self.optimizer.step(self.loss_f)\n",
    "        torch.save(self.network.state_dict(), r'C:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs/model')\n",
    "\n",
    "    def plot(self):\n",
    "        self.network.eval()\n",
    "        with torch.no_grad():\n",
    "            self.u = self.u_pred.cpu().numpy().T\n",
    "            self.v = self.v_pred.cpu().numpy().T\n",
    "            self.p = self.p_pred.cpu().numpy().T\n",
    "            self.theta = self.theta_pred.cpu().numpy().T\n",
    "\n",
    "        save_dir = \"C:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs\"\n",
    "        plt.rcParams.update({\n",
    "            \"font.family\": \"Times New Roman\",\n",
    "            \"font.style\": \"italic\"\n",
    "        })\n",
    "\n",
    "        # Temperature field\n",
    "        plt.figure(figsize=(4, 5))\n",
    "        contour1 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                               self.theta, levels=50, cmap=\"jet\")\n",
    "        plt.colorbar(contour1, aspect=60)\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.title(\"Temperature Field (Î¸)\", fontsize=14)\n",
    "        plt.savefig(os.path.join(save_dir, \"Temperature.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # U velocity\n",
    "        plt.figure(figsize=(4, 5))\n",
    "        contour2 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                               self.u, levels=50, cmap=\"jet\")\n",
    "        plt.colorbar(contour2, aspect=60)\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.title(\"u-velocity\", fontsize=14)\n",
    "        plt.savefig(os.path.join(save_dir, \"u-velocity.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        # V velocity\n",
    "        plt.figure(figsize=(4, 5))\n",
    "        contour3 = plt.contourf(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                               self.v, levels=50, cmap=\"jet\")\n",
    "        plt.colorbar(contour3, aspect=60)\n",
    "        plt.xlabel(\"x\", fontsize=14)\n",
    "        plt.ylabel(\"y\", fontsize=14)\n",
    "        plt.title(\"v-velocity\", fontsize=14)\n",
    "        plt.savefig(os.path.join(save_dir, \"v-velocity.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Streamlines\n",
    "        fig, ax = plt.subplots(figsize=(4, 6))\n",
    "        ax.streamplot(self.x.detach().cpu().numpy(), self.y.detach().cpu().numpy(),\n",
    "                      self.u, self.v, color='red', cmap='autumn', linewidth=0.5, density=2, arrowsize=0.6)\n",
    "        ax.set_xlabel(\"x\", fontsize=14)\n",
    "        ax.set_ylabel(\"y\", fontsize=14)\n",
    "        ax.set_title(\"Streamlines\", fontsize=14)\n",
    "        ax.set_xlim(-0.2, 0.2)\n",
    "        ax.set_ylim(-0.4, 0.4)\n",
    "        fig.savefig(os.path.join(save_dir, \"Streamlines.png\"), dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.semilogy(self.loss_history)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss (Log Scale)')\n",
    "        plt.title('Training Loss History')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        df = pd.DataFrame({\"loss\": self.loss_history})\n",
    "        df.to_csv(\"C:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs/loss_history5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53082ac5-3b80-4374-8554-187e6cf2b95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.000000008\n",
      "Iteration 10, Loss: 0.000000293\n",
      "Iteration 20, Loss: 0.000000098\n",
      "Iteration 30, Loss: 0.000000041\n",
      "Iteration 40, Loss: 0.000000020\n",
      "Iteration 50, Loss: 0.000000012\n",
      "Iteration 60, Loss: 0.000000009\n",
      "Iteration 70, Loss: 0.000000008\n",
      "Iteration 80, Loss: 0.000000008\n",
      "Iteration 90, Loss: 0.000000008\n",
      "Iteration 100, Loss: 0.000000008\n",
      "Iteration 110, Loss: 0.000000008\n",
      "Iteration 120, Loss: 0.000000008\n",
      "Iteration 130, Loss: 0.000000008\n",
      "Iteration 140, Loss: 0.000000008\n",
      "Iteration 150, Loss: 0.000000008\n",
      "Iteration 160, Loss: 0.000000008\n",
      "Iteration 170, Loss: 0.000000008\n",
      "Iteration 180, Loss: 0.000000008\n",
      "Iteration 190, Loss: 0.000000008\n",
      "Iteration 200, Loss: 0.000000008\n",
      "Iteration 210, Loss: 0.000000008\n",
      "Iteration 220, Loss: 0.000000008\n",
      "Iteration 230, Loss: 0.000000008\n",
      "Iteration 240, Loss: 0.000000008\n",
      "Iteration 250, Loss: 0.000000008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m Pinns()\n\u001b[0;32m      2\u001b[0m net\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs/model\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m net\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m      5\u001b[0m net\u001b[38;5;241m.\u001b[39mplot_loss()\n",
      "Cell \u001b[1;32mIn[11], line 183\u001b[0m, in \u001b[0;36mPinns.train\u001b[1;34m(self, num_epochs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    182\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs/model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_f)\n\u001b[0;32m    185\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs/model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Windows\\system32\\pytorch-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:124\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    123\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(opt, opt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Windows\\system32\\pytorch-env\\lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Windows\\system32\\pytorch-env\\lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mC:\\Windows\\system32\\pytorch-env\\lib\\site-packages\\torch\\optim\\adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    228\u001b[0m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[11], line 171\u001b[0m, in \u001b[0;36mPinns.loss_f\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Compute total loss\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(continuity_eq\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mzeros_like(continuity_eq)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    167\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(u_momentum_eq\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mzeros_like(u_momentum_eq)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    168\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(v_momentum_eq\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mzeros_like(v_momentum_eq)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    169\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(energy_eq\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mzeros_like(energy_eq)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mC:\\Windows\\system32\\pytorch-env\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Windows\\system32\\pytorch-env\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Windows\\system32\\pytorch-env\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Pinns()\n",
    "net.network.load_state_dict(torch.load(r'C:/Users/hossein/Result/Natural Convection/Ra=10^7/2-FF-FD-PINNs/model'))\n",
    "net.train(num_epochs=100000)\n",
    "net.plot()\n",
    "net.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d396d86-43fa-4a09-93fc-903c2d749412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
